Loaded module: cuda/12.1
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.47s/it]
  0%|          | 0/400 [00:00<?, ?it/s]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/tokenization_utils_base.py:3862: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  warnings.warn(
/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 149, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  0%|          | 1/400 [00:31<3:28:45, 31.39s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 151, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  0%|          | 2/400 [01:03<3:30:41, 31.76s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 147, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  1%|          | 3/400 [01:34<3:28:40, 31.54s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 150, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  1%|          | 4/400 [02:06<3:27:49, 31.49s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 148, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  1%|▏         | 5/400 [02:36<3:25:33, 31.22s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 145, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  2%|▏         | 6/400 [03:07<3:23:45, 31.03s/it]  2%|▏         | 7/400 [03:38<3:23:41, 31.10s/it]  2%|▏         | 8/400 [04:09<3:22:30, 31.00s/it]  2%|▏         | 9/400 [04:40<3:21:30, 30.92s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 152, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  2%|▎         | 10/400 [05:11<3:22:20, 31.13s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 153, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  3%|▎         | 11/400 [05:44<3:23:56, 31.46s/it]  3%|▎         | 12/400 [06:15<3:23:17, 31.44s/it]  3%|▎         | 13/400 [06:46<3:22:48, 31.44s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 146, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  4%|▎         | 14/400 [07:17<3:20:47, 31.21s/it]  4%|▍         | 15/400 [07:48<3:20:22, 31.23s/it]  4%|▍         | 16/400 [08:20<3:20:17, 31.30s/it]  4%|▍         | 17/400 [08:51<3:20:07, 31.35s/it]  4%|▍         | 18/400 [09:23<3:19:47, 31.38s/it]  5%|▍         | 19/400 [09:54<3:19:23, 31.40s/it]  5%|▌         | 20/400 [10:26<3:18:53, 31.40s/it]  5%|▌         | 21/400 [10:56<3:16:56, 31.18s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 144, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  6%|▌         | 22/400 [11:26<3:14:09, 30.82s/it]  6%|▌         | 23/400 [11:58<3:14:47, 31.00s/it]  6%|▌         | 24/400 [12:30<3:16:20, 31.33s/it]  6%|▋         | 25/400 [13:01<3:15:42, 31.31s/it]  6%|▋         | 26/400 [13:32<3:15:00, 31.29s/it]  7%|▋         | 27/400 [14:03<3:13:18, 31.09s/it]  7%|▋         | 28/400 [14:34<3:13:26, 31.20s/it]  7%|▋         | 29/400 [15:06<3:13:19, 31.27s/it]  8%|▊         | 30/400 [15:37<3:13:08, 31.32s/it]  8%|▊         | 31/400 [16:08<3:11:22, 31.12s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 154, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  8%|▊         | 32/400 [16:40<3:12:47, 31.43s/it]  8%|▊         | 33/400 [17:11<3:11:58, 31.39s/it]  8%|▊         | 34/400 [17:43<3:11:28, 31.39s/it]  9%|▉         | 35/400 [18:14<3:11:22, 31.46s/it]  9%|▉         | 36/400 [18:45<3:09:25, 31.22s/it]  9%|▉         | 37/400 [19:16<3:09:13, 31.28s/it] 10%|▉         | 38/400 [19:47<3:07:35, 31.09s/it] 10%|▉         | 39/400 [20:18<3:06:15, 30.96s/it] 10%|█         | 40/400 [20:48<3:04:03, 30.68s/it] 10%|█         | 41/400 [21:19<3:04:51, 30.89s/it] 10%|█         | 42/400 [21:51<3:05:16, 31.05s/it] 11%|█         | 43/400 [22:23<3:06:50, 31.40s/it] 11%|█         | 44/400 [22:54<3:05:09, 31.21s/it] 11%|█▏        | 45/400 [23:25<3:04:57, 31.26s/it] 12%|█▏        | 46/400 [23:56<3:03:33, 31.11s/it] 12%|█▏        | 47/400 [24:26<3:02:20, 30.99s/it] 12%|█▏        | 48/400 [24:58<3:02:38, 31.13s/it] 12%|█▏        | 49/400 [25:29<3:02:35, 31.21s/it] 12%|█▎        | 50/400 [26:01<3:02:31, 31.29s/it] 13%|█▎        | 51/400 [26:31<3:00:52, 31.10s/it] 13%|█▎        | 52/400 [27:03<3:01:17, 31.26s/it] 13%|█▎        | 53/400 [27:34<2:59:43, 31.08s/it] 14%|█▎        | 54/400 [28:05<3:00:13, 31.25s/it] 14%|█▍        | 55/400 [28:37<2:59:59, 31.30s/it] 14%|█▍        | 56/400 [29:08<2:59:57, 31.39s/it] 14%|█▍        | 57/400 [29:40<2:59:46, 31.45s/it] 14%|█▍        | 58/400 [30:11<2:59:11, 31.44s/it] 15%|█▍        | 59/400 [30:42<2:57:18, 31.20s/it] 15%|█▌        | 60/400 [31:13<2:56:06, 31.08s/it] 15%|█▌        | 61/400 [31:44<2:55:04, 30.99s/it] 16%|█▌        | 62/400 [32:15<2:55:35, 31.17s/it] 16%|█▌        | 63/400 [32:47<2:55:28, 31.24s/it] 16%|█▌        | 64/400 [33:18<2:55:00, 31.25s/it] 16%|█▋        | 65/400 [33:50<2:55:45, 31.48s/it] 16%|█▋        | 66/400 [34:21<2:55:20, 31.50s/it] 17%|█▋        | 67/400 [34:53<2:54:36, 31.46s/it] 17%|█▋        | 68/400 [35:24<2:53:45, 31.40s/it] 17%|█▋        | 69/400 [35:55<2:53:05, 31.38s/it] 18%|█▊        | 70/400 [36:27<2:52:43, 31.41s/it] 18%|█▊        | 71/400 [36:58<2:51:12, 31.22s/it] 18%|█▊        | 72/400 [37:28<2:49:40, 31.04s/it] 18%|█▊        | 73/400 [37:58<2:47:24, 30.72s/it] 18%|█▊        | 74/400 [38:29<2:47:48, 30.88s/it] 19%|█▉        | 75/400 [39:01<2:48:08, 31.04s/it] 19%|█▉        | 76/400 [39:32<2:48:12, 31.15s/it] 19%|█▉        | 77/400 [40:04<2:48:19, 31.27s/it] 20%|█▉        | 78/400 [40:36<2:49:14, 31.54s/it] 20%|█▉        | 79/400 [41:08<2:49:44, 31.73s/it] 20%|██        | 80/400 [41:39<2:48:27, 31.58s/it] 20%|██        | 81/400 [42:10<2:46:38, 31.34s/it] 20%|██        | 82/400 [42:42<2:47:16, 31.56s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 143, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 21%|██        | 83/400 [43:13<2:45:07, 31.25s/it] 21%|██        | 84/400 [43:44<2:45:09, 31.36s/it] 21%|██▏       | 85/400 [44:15<2:43:33, 31.15s/it] 22%|██▏       | 86/400 [44:46<2:43:27, 31.23s/it] 22%|██▏       | 87/400 [45:19<2:44:14, 31.49s/it] 22%|██▏       | 88/400 [45:51<2:44:34, 31.65s/it] 22%|██▏       | 89/400 [46:21<2:42:30, 31.35s/it] 22%|██▎       | 90/400 [46:52<2:41:03, 31.17s/it] 23%|██▎       | 91/400 [47:23<2:40:51, 31.24s/it] 23%|██▎       | 92/400 [47:55<2:41:37, 31.48s/it] 23%|██▎       | 93/400 [48:27<2:41:16, 31.52s/it] 24%|██▎       | 94/400 [48:58<2:39:25, 31.26s/it] 24%|██▍       | 95/400 [49:28<2:37:55, 31.07s/it] 24%|██▍       | 96/400 [50:00<2:38:01, 31.19s/it] 24%|██▍       | 97/400 [50:32<2:38:46, 31.44s/it] 24%|██▍       | 98/400 [51:03<2:38:13, 31.43s/it] 25%|██▍       | 99/400 [51:34<2:37:28, 31.39s/it] 25%|██▌       | 100/400 [52:05<2:35:53, 31.18s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 140, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 25%|██▌       | 101/400 [52:34<2:32:32, 30.61s/it] 26%|██▌       | 102/400 [53:05<2:31:58, 30.60s/it] 26%|██▌       | 103/400 [53:37<2:32:51, 30.88s/it] 26%|██▌       | 104/400 [54:09<2:34:07, 31.24s/it] 26%|██▋       | 105/400 [54:40<2:33:50, 31.29s/it] 26%|██▋       | 106/400 [55:12<2:34:25, 31.51s/it] 27%|██▋       | 107/400 [55:42<2:31:38, 31.05s/it] 27%|██▋       | 108/400 [56:14<2:31:43, 31.18s/it] 27%|██▋       | 109/400 [56:44<2:29:27, 30.82s/it] 28%|██▊       | 110/400 [57:15<2:29:48, 30.99s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 139, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 28%|██▊       | 111/400 [57:45<2:27:33, 30.64s/it] 28%|██▊       | 112/400 [58:14<2:25:06, 30.23s/it] 28%|██▊       | 113/400 [58:45<2:26:20, 30.59s/it] 28%|██▊       | 114/400 [59:16<2:26:07, 30.66s/it] 29%|██▉       | 115/400 [59:48<2:27:32, 31.06s/it] 29%|██▉       | 116/400 [1:00:19<2:26:26, 30.94s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 141, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 29%|██▉       | 117/400 [1:00:49<2:24:23, 30.61s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 138, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 30%|██▉       | 118/400 [1:01:18<2:21:49, 30.18s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 155, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 30%|██▉       | 119/400 [1:01:51<2:25:05, 30.98s/it] 30%|███       | 120/400 [1:02:23<2:26:07, 31.31s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 135, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 30%|███       | 121/400 [1:02:52<2:22:25, 30.63s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 137, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 30%|███       | 122/400 [1:03:21<2:19:53, 30.19s/it] 31%|███       | 123/400 [1:03:52<2:21:05, 30.56s/it] 31%|███       | 124/400 [1:04:23<2:20:48, 30.61s/it] 31%|███▏      | 125/400 [1:04:55<2:21:27, 30.86s/it] 32%|███▏      | 126/400 [1:05:27<2:22:44, 31.26s/it] 32%|███▏      | 127/400 [1:05:58<2:21:34, 31.12s/it] 32%|███▏      | 128/400 [1:06:30<2:22:35, 31.46s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 134, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 32%|███▏      | 129/400 [1:06:58<2:18:02, 30.56s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 156, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 32%|███▎      | 130/400 [1:07:31<2:19:54, 31.09s/it] 33%|███▎      | 131/400 [1:08:03<2:20:50, 31.42s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 157, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 33%|███▎      | 132/400 [1:08:36<2:22:24, 31.88s/it] 33%|███▎      | 133/400 [1:09:07<2:20:17, 31.52s/it] 34%|███▎      | 134/400 [1:09:39<2:20:38, 31.72s/it] 34%|███▍      | 135/400 [1:10:08<2:16:51, 30.99s/it] 34%|███▍      | 136/400 [1:10:39<2:16:05, 30.93s/it] 34%|███▍      | 137/400 [1:11:11<2:17:25, 31.35s/it] 34%|███▍      | 138/400 [1:11:42<2:16:49, 31.34s/it] 35%|███▍      | 139/400 [1:12:12<2:14:28, 30.91s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 131, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 35%|███▌      | 140/400 [1:12:41<2:10:34, 30.13s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 136, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 35%|███▌      | 141/400 [1:13:09<2:08:00, 29.65s/it] 36%|███▌      | 142/400 [1:13:39<2:07:39, 29.69s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 142, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 36%|███▌      | 143/400 [1:14:09<2:07:29, 29.77s/it] 36%|███▌      | 144/400 [1:14:40<2:08:04, 30.02s/it] 36%|███▋      | 145/400 [1:15:09<2:06:29, 29.76s/it] 36%|███▋      | 146/400 [1:15:39<2:06:14, 29.82s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 160, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 37%|███▋      | 147/400 [1:16:12<2:09:54, 30.81s/it] 37%|███▋      | 148/400 [1:16:43<2:10:13, 31.01s/it] 37%|███▋      | 149/400 [1:17:16<2:12:05, 31.58s/it] 38%|███▊      | 150/400 [1:17:48<2:11:28, 31.55s/it] 38%|███▊      | 151/400 [1:18:19<2:10:48, 31.52s/it] 38%|███▊      | 152/400 [1:18:51<2:10:14, 31.51s/it] 38%|███▊      | 153/400 [1:19:20<2:07:35, 30.99s/it] 38%|███▊      | 154/400 [1:19:50<2:05:52, 30.70s/it] 39%|███▉      | 155/400 [1:20:20<2:04:22, 30.46s/it] 39%|███▉      | 156/400 [1:20:50<2:03:20, 30.33s/it] 39%|███▉      | 157/400 [1:21:23<2:05:55, 31.09s/it] 40%|███▉      | 158/400 [1:21:54<2:04:57, 30.98s/it] 40%|███▉      | 159/400 [1:22:25<2:04:13, 30.93s/it] 40%|████      | 160/400 [1:22:57<2:05:06, 31.28s/it] 40%|████      | 161/400 [1:23:28<2:04:02, 31.14s/it] 40%|████      | 162/400 [1:23:56<2:00:25, 30.36s/it] 41%|████      | 163/400 [1:24:28<2:01:21, 30.72s/it] 41%|████      | 164/400 [1:24:57<1:59:07, 30.29s/it] 41%|████▏     | 165/400 [1:25:28<2:00:01, 30.65s/it] 42%|████▏     | 166/400 [1:26:00<2:00:30, 30.90s/it] 42%|████▏     | 167/400 [1:26:30<1:58:54, 30.62s/it] 42%|████▏     | 168/400 [1:27:01<1:59:13, 30.83s/it] 42%|████▏     | 169/400 [1:27:34<2:00:59, 31.43s/it] 42%|████▎     | 170/400 [1:28:03<1:57:53, 30.75s/it] 43%|████▎     | 171/400 [1:28:35<1:58:19, 31.00s/it] 43%|████▎     | 172/400 [1:29:05<1:56:34, 30.68s/it] 43%|████▎     | 173/400 [1:29:35<1:55:55, 30.64s/it] 44%|████▎     | 174/400 [1:30:04<1:53:42, 30.19s/it] 44%|████▍     | 175/400 [1:30:34<1:52:55, 30.11s/it] 44%|████▍     | 176/400 [1:31:04<1:51:30, 29.87s/it] 44%|████▍     | 177/400 [1:31:33<1:50:10, 29.64s/it] 44%|████▍     | 178/400 [1:32:04<1:51:27, 30.13s/it] 45%|████▍     | 179/400 [1:32:34<1:50:42, 30.06s/it] 45%|████▌     | 180/400 [1:33:04<1:49:54, 29.97s/it] 45%|████▌     | 181/400 [1:33:33<1:48:31, 29.73s/it] 46%|████▌     | 182/400 [1:34:03<1:48:19, 29.81s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 158, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 46%|████▌     | 183/400 [1:34:36<1:51:14, 30.76s/it] 46%|████▌     | 184/400 [1:35:04<1:48:17, 30.08s/it] 46%|████▋     | 185/400 [1:35:33<1:46:45, 29.79s/it] 46%|████▋     | 186/400 [1:36:05<1:48:39, 30.46s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 133, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 47%|████▋     | 187/400 [1:36:34<1:45:58, 29.85s/it] 47%|████▋     | 188/400 [1:37:07<1:48:44, 30.77s/it] 47%|████▋     | 189/400 [1:37:37<1:47:14, 30.49s/it] 48%|████▊     | 190/400 [1:38:09<1:48:30, 31.00s/it] 48%|████▊     | 191/400 [1:38:38<1:46:10, 30.48s/it] 48%|████▊     | 192/400 [1:39:07<1:44:18, 30.09s/it] 48%|████▊     | 193/400 [1:39:37<1:43:36, 30.03s/it] 48%|████▊     | 194/400 [1:40:10<1:45:58, 30.87s/it] 49%|████▉     | 195/400 [1:40:43<1:47:35, 31.49s/it] 49%|████▉     | 196/400 [1:41:14<1:46:12, 31.24s/it] 49%|████▉     | 197/400 [1:41:46<1:46:42, 31.54s/it] 50%|████▉     | 198/400 [1:42:16<1:44:31, 31.05s/it] 50%|████▉     | 199/400 [1:42:46<1:43:36, 30.93s/it] 50%|█████     | 200/400 [1:43:19<1:45:05, 31.53s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 367, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 50%|█████     | 201/400 [1:44:32<2:25:55, 44.00s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 541, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 50%|█████     | 202/400 [1:46:20<3:28:25, 63.16s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 393, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 51%|█████     | 203/400 [1:47:38<3:41:36, 67.50s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 540, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 51%|█████     | 204/400 [1:49:25<4:18:50, 79.24s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 458, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 51%|█████▏    | 205/400 [1:50:55<4:28:16, 82.55s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 539, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 52%|█████▏    | 206/400 [1:52:42<4:51:17, 90.09s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 536, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 52%|█████▏    | 207/400 [1:54:28<5:04:48, 94.76s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 392, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 52%|█████▏    | 208/400 [1:55:45<4:46:00, 89.38s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 348, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 52%|█████▏    | 209/400 [1:56:54<4:24:37, 83.13s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 373, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 52%|█████▎    | 210/400 [1:58:08<4:14:36, 80.40s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 399, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 53%|█████▎    | 211/400 [1:59:27<4:12:04, 80.02s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 309, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 53%|█████▎    | 212/400 [2:00:28<3:53:34, 74.54s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 307, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 53%|█████▎    | 213/400 [2:01:30<3:40:14, 70.66s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 350, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 54%|█████▎    | 214/400 [2:02:39<3:37:51, 70.28s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 491, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 54%|█████▍    | 215/400 [2:04:17<4:01:51, 78.44s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 395, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 54%|█████▍    | 216/400 [2:05:35<4:00:31, 78.43s/it] 54%|█████▍    | 217/400 [2:06:45<3:50:55, 75.72s/it] 55%|█████▍    | 218/400 [2:07:58<3:47:18, 74.94s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 349, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 55%|█████▍    | 219/400 [2:09:07<3:41:08, 73.31s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 479, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 55%|█████▌    | 220/400 [2:10:43<3:59:38, 79.88s/it] 55%|█████▌    | 221/400 [2:12:30<4:22:42, 88.06s/it] 56%|█████▌    | 222/400 [2:14:05<4:27:23, 90.13s/it] 56%|█████▌    | 223/400 [2:15:06<4:00:36, 81.56s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 301, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 56%|█████▌    | 224/400 [2:16:06<3:40:26, 75.15s/it] 56%|█████▋    | 225/400 [2:17:25<3:41:51, 76.06s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 371, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 56%|█████▋    | 226/400 [2:18:38<3:38:35, 75.37s/it] 57%|█████▋    | 227/400 [2:20:25<4:04:29, 84.80s/it] 57%|█████▋    | 228/400 [2:21:38<3:52:51, 81.23s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 480, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 57%|█████▋    | 229/400 [2:23:12<4:02:11, 84.98s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 304, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 57%|█████▊    | 230/400 [2:24:12<3:39:29, 77.47s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 422, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 58%|█████▊    | 231/400 [2:25:35<3:42:51, 79.12s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 483, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 58%|█████▊    | 232/400 [2:27:10<3:55:20, 84.05s/it] 58%|█████▊    | 233/400 [2:28:20<3:41:39, 79.64s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 413, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 58%|█████▊    | 234/400 [2:29:41<3:41:52, 80.19s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 554, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 59%|█████▉    | 235/400 [2:31:30<4:04:36, 88.95s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 489, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 59%|█████▉    | 236/400 [2:33:07<4:09:25, 91.25s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 376, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 59%|█████▉    | 237/400 [2:34:21<3:53:36, 85.99s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 300, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 60%|█████▉    | 238/400 [2:35:20<3:30:42, 78.04s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 465, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 60%|█████▉    | 239/400 [2:36:52<3:40:30, 82.18s/it] 60%|██████    | 240/400 [2:38:41<4:00:49, 90.31s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 368, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 60%|██████    | 241/400 [2:39:54<3:44:54, 84.87s/it] 60%|██████    | 242/400 [2:41:39<3:59:27, 90.94s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 474, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 61%|██████    | 243/400 [2:43:12<3:59:49, 91.65s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 418, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 61%|██████    | 244/400 [2:44:34<3:51:00, 88.85s/it] 61%|██████▏   | 245/400 [2:46:10<3:54:51, 90.91s/it] 62%|██████▏   | 246/400 [2:47:28<3:43:08, 86.94s/it] 62%|██████▏   | 247/400 [2:48:47<3:35:40, 84.58s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 347, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 62%|██████▏   | 248/400 [2:49:56<3:22:31, 79.94s/it] 62%|██████▏   | 249/400 [2:51:30<3:31:40, 84.11s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 352, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 62%|██████▎   | 250/400 [2:52:39<3:19:00, 79.60s/it] 63%|██████▎   | 251/400 [2:53:53<3:13:20, 77.86s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 354, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 63%|██████▎   | 252/400 [2:55:03<3:06:11, 75.48s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 478, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 63%|██████▎   | 253/400 [2:56:37<3:18:35, 81.06s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 351, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 64%|██████▎   | 254/400 [2:57:47<3:09:05, 77.71s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 355, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 64%|██████▍   | 255/400 [2:58:57<3:02:45, 75.62s/it]User defined signal 2
