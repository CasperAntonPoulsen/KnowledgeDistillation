Loaded module: cuda/12.1
  0%|          | 0/400 [00:00<?, ?it/s]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/tokenization_utils_base.py:3862: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  warnings.warn(
/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 167, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  0%|          | 1/400 [01:03<7:04:10, 63.79s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 170, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  0%|          | 2/400 [02:07<7:04:44, 64.03s/it]  1%|          | 3/400 [03:11<7:03:18, 63.98s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 168, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  1%|          | 4/400 [04:14<6:58:53, 63.47s/it]  1%|▏         | 5/400 [05:18<6:58:52, 63.63s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 165, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  2%|▏         | 6/400 [06:21<6:55:49, 63.32s/it]  2%|▏         | 7/400 [07:23<6:53:25, 63.12s/it]  2%|▏         | 8/400 [08:27<6:54:04, 63.38s/it]  2%|▏         | 9/400 [09:31<6:54:06, 63.55s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 173, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  2%|▎         | 10/400 [10:36<6:56:23, 64.06s/it]  3%|▎         | 11/400 [11:42<6:57:42, 64.43s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 169, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  3%|▎         | 12/400 [12:46<6:55:40, 64.28s/it]  3%|▎         | 13/400 [13:48<6:51:26, 63.79s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 166, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  4%|▎         | 14/400 [14:51<6:48:24, 63.48s/it]  4%|▍         | 15/400 [15:55<6:48:17, 63.63s/it]  4%|▍         | 16/400 [16:59<6:47:52, 63.73s/it]  4%|▍         | 17/400 [18:02<6:44:55, 63.44s/it]  4%|▍         | 18/400 [19:05<6:42:37, 63.24s/it]  5%|▍         | 19/400 [20:09<6:43:27, 63.54s/it]  5%|▌         | 20/400 [21:13<6:43:20, 63.69s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 164, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  5%|▌         | 21/400 [22:14<6:37:59, 63.01s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 163, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  6%|▌         | 22/400 [23:17<6:36:10, 62.89s/it]  6%|▌         | 23/400 [24:21<6:36:59, 63.18s/it]  6%|▌         | 24/400 [25:25<6:37:28, 63.43s/it]  6%|▋         | 25/400 [26:27<6:35:05, 63.22s/it]  6%|▋         | 26/400 [27:31<6:35:12, 63.40s/it]  7%|▋         | 27/400 [28:33<6:30:19, 62.79s/it]  7%|▋         | 28/400 [29:37<6:31:14, 63.10s/it]  7%|▋         | 29/400 [30:40<6:31:37, 63.33s/it]  8%|▊         | 30/400 [31:43<6:29:21, 63.14s/it]  8%|▊         | 31/400 [32:46<6:27:14, 62.96s/it]  8%|▊         | 32/400 [33:51<6:30:13, 63.62s/it]  8%|▊         | 33/400 [34:53<6:27:26, 63.34s/it]  8%|▊         | 34/400 [35:56<6:25:08, 63.14s/it]  9%|▉         | 35/400 [37:00<6:25:37, 63.39s/it]  9%|▉         | 36/400 [38:01<6:20:51, 62.78s/it]  9%|▉         | 37/400 [39:05<6:21:55, 63.13s/it] 10%|▉         | 38/400 [40:08<6:19:57, 62.98s/it] 10%|▉         | 39/400 [41:11<6:18:16, 62.87s/it] 10%|█         | 40/400 [42:13<6:16:44, 62.79s/it] 10%|█         | 41/400 [43:17<6:17:41, 63.12s/it] 10%|█         | 42/400 [44:21<6:17:59, 63.35s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 171, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 11%|█         | 43/400 [5:09:16<477:15:32, 4812.70s/it] 11%|█         | 44/400 [5:10:18<334:59:48, 3387.61s/it] 11%|█▏        | 45/400 [5:11:21<235:41:37, 2390.13s/it] 12%|█▏        | 46/400 [5:12:24<166:23:46, 1692.16s/it] 12%|█▏        | 47/400 [5:13:28<118:01:18, 1203.62s/it] 12%|█▏        | 48/400 [5:14:30<84:12:07, 861.16s/it]   12%|█▏        | 49/400 [5:15:33<60:37:26, 621.78s/it] 12%|█▎        | 50/400 [5:16:35<44:07:34, 453.87s/it] 13%|█▎        | 51/400 [5:17:37<32:36:08, 336.30s/it] 13%|█▎        | 52/400 [5:18:41<24:35:38, 254.42s/it] 13%|█▎        | 53/400 [5:19:41<18:55:13, 196.29s/it] 14%|█▎        | 54/400 [5:20:46<15:03:52, 156.74s/it] 14%|█▍        | 55/400 [5:21:49<12:20:06, 128.71s/it] 14%|█▍        | 56/400 [5:22:52<10:25:22, 109.08s/it] 14%|█▍        | 57/400 [5:23:56<9:05:02, 95.34s/it]   14%|█▍        | 58/400 [5:24:59<8:08:22, 85.68s/it] 15%|█▍        | 59/400 [5:26:00<7:26:09, 78.50s/it] 15%|█▌        | 60/400 [5:27:04<6:58:33, 73.86s/it] 15%|█▌        | 61/400 [5:28:05<6:37:00, 70.27s/it] 16%|█▌        | 62/400 [5:29:09<6:23:46, 68.13s/it] 16%|█▌        | 63/400 [5:30:11<6:13:52, 66.57s/it] 16%|█▌        | 64/400 [5:31:14<6:06:42, 65.48s/it] 16%|█▋        | 65/400 [5:32:18<6:01:54, 64.82s/it] 16%|█▋        | 66/400 [5:33:21<5:57:52, 64.29s/it] 17%|█▋        | 67/400 [5:34:22<5:52:27, 63.51s/it] 17%|█▋        | 68/400 [5:35:24<5:48:19, 62.95s/it] 17%|█▋        | 69/400 [7:15:09<169:07:21, 1839.40s/it] 18%|█▊        | 70/400 [7:16:08<119:40:15, 1305.50s/it] 18%|█▊        | 71/400 [7:17:08<85:09:32, 931.83s/it]   18%|█▊        | 72/400 [7:18:08<61:03:49, 670.21s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 162, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 18%|█▊        | 73/400 [7:19:07<44:12:51, 486.76s/it] 18%|█▊        | 74/400 [7:20:06<32:28:32, 358.63s/it] 19%|█▉        | 75/400 [7:21:06<24:16:42, 268.93s/it] 19%|█▉        | 76/400 [7:22:06<18:33:10, 206.14s/it] 19%|█▉        | 77/400 [7:23:08<14:37:10, 162.94s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 172, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 20%|█▉        | 78/400 [7:24:09<11:50:07, 132.32s/it] 20%|█▉        | 79/400 [7:25:11<9:55:08, 111.24s/it]  20%|██        | 80/400 [7:26:10<8:30:29, 95.72s/it]  20%|██        | 81/400 [7:27:11<7:33:07, 85.23s/it] 20%|██        | 82/400 [7:28:12<6:52:58, 77.92s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 161, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 21%|██        | 83/400 [7:29:10<6:20:17, 71.98s/it] 21%|██        | 84/400 [7:30:11<6:01:27, 68.63s/it] 21%|██▏       | 85/400 [7:31:11<5:46:30, 66.00s/it] 22%|██▏       | 86/400 [7:32:11<5:37:04, 64.41s/it] 22%|██▏       | 87/400 [7:33:12<5:30:22, 63.33s/it] 22%|██▏       | 88/400 [7:34:14<5:27:04, 62.90s/it] 22%|██▏       | 89/400 [7:35:12<5:18:51, 61.52s/it] 22%|██▎       | 90/400 [7:36:12<5:14:37, 60.89s/it] 23%|██▎       | 91/400 [7:37:12<5:13:11, 60.81s/it] 23%|██▎       | 92/400 [7:38:13<5:11:44, 60.73s/it] 23%|██▎       | 93/400 [7:39:15<5:12:29, 61.07s/it] 24%|██▎       | 94/400 [7:40:14<5:08:37, 60.51s/it] 24%|██▍       | 95/400 [7:41:13<5:05:37, 60.12s/it] 24%|██▍       | 96/400 [7:42:12<5:03:15, 59.85s/it] 24%|██▍       | 97/400 [7:43:13<5:03:11, 60.04s/it] 24%|██▍       | 98/400 [7:44:13<5:02:52, 60.17s/it] 25%|██▍       | 99/400 [7:45:14<5:02:15, 60.25s/it] 25%|██▌       | 100/400 [7:46:13<4:59:32, 59.91s/it] 25%|██▌       | 101/400 [7:47:13<4:59:27, 60.09s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 184, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 26%|██▌       | 102/400 [7:48:18<5:04:53, 61.39s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 191, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 26%|██▌       | 103/400 [7:49:26<5:13:49, 63.40s/it] 26%|██▌       | 104/400 [7:50:30<5:14:09, 63.68s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 186, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 26%|██▋       | 105/400 [7:51:36<5:15:55, 64.26s/it] 26%|██▋       | 106/400 [7:52:40<5:14:50, 64.25s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 175, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 27%|██▋       | 107/400 [7:53:43<5:11:42, 63.83s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 187, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 27%|██▋       | 108/400 [7:54:50<5:14:48, 64.69s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 179, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 27%|██▋       | 109/400 [7:55:54<5:12:55, 64.52s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 182, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 28%|██▊       | 110/400 [7:56:58<5:11:25, 64.43s/it] 28%|██▊       | 111/400 [7:57:58<5:04:22, 63.19s/it] 28%|██▊       | 112/400 [7:59:00<5:00:50, 62.67s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 180, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 28%|██▊       | 113/400 [8:00:03<4:59:58, 62.71s/it] 28%|██▊       | 114/400 [8:01:07<5:00:45, 63.10s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 181, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 29%|██▉       | 115/400 [8:02:11<5:00:58, 63.36s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 176, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 29%|██▉       | 116/400 [8:03:12<4:57:11, 62.79s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 174, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 29%|██▉       | 117/400 [8:04:13<4:54:15, 62.39s/it] 30%|██▉       | 118/400 [8:05:13<4:49:54, 61.68s/it] 30%|██▉       | 119/400 [8:06:21<4:57:33, 63.54s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 183, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 30%|███       | 120/400 [8:07:27<4:58:53, 64.05s/it] 30%|███       | 121/400 [8:08:27<4:52:08, 62.83s/it] 30%|███       | 122/400 [8:09:26<4:47:03, 61.95s/it] 31%|███       | 123/400 [8:10:30<4:48:49, 62.56s/it] 31%|███       | 124/400 [8:11:37<4:53:08, 63.73s/it] 31%|███▏      | 125/400 [8:12:42<4:54:29, 64.25s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 197, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 32%|███▏      | 126/400 [8:13:51<4:59:54, 65.67s/it] 32%|███▏      | 127/400 [8:14:55<4:56:11, 65.10s/it] 32%|███▏      | 128/400 [8:16:01<4:56:47, 65.47s/it] 32%|███▏      | 129/400 [8:17:00<4:46:26, 63.42s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 194, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 32%|███▎      | 130/400 [8:18:08<4:51:12, 64.71s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 188, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 33%|███▎      | 131/400 [8:19:13<4:50:37, 64.82s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 193, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 33%|███▎      | 132/400 [8:20:20<4:53:13, 65.65s/it] 33%|███▎      | 133/400 [8:21:23<4:47:52, 64.69s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 190, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 34%|███▎      | 134/400 [8:22:29<4:49:04, 65.20s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 178, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 34%|███▍      | 135/400 [8:23:32<4:44:24, 64.40s/it] 34%|███▍      | 136/400 [8:24:37<4:44:03, 64.56s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 189, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 34%|███▍      | 137/400 [8:25:44<4:45:59, 65.25s/it] 34%|███▍      | 138/400 [8:26:47<4:42:45, 64.75s/it] 35%|███▍      | 139/400 [8:27:48<4:36:42, 63.61s/it] 35%|███▌      | 140/400 [8:28:48<4:30:31, 62.43s/it] 35%|███▌      | 141/400 [8:29:46<4:24:24, 61.25s/it] 36%|███▌      | 142/400 [8:30:46<4:21:27, 60.80s/it] 36%|███▌      | 143/400 [8:31:47<4:20:44, 60.87s/it] 36%|███▌      | 144/400 [8:33:22<5:02:39, 70.94s/it] 36%|███▋      | 145/400 [8:34:21<4:47:12, 67.58s/it] 36%|███▋      | 146/400 [8:40:18<10:52:39, 154.17s/it] 37%|███▋      | 147/400 [8:41:25<9:00:27, 128.17s/it]  37%|███▋      | 148/400 [8:42:29<7:37:05, 108.83s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 195, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 37%|███▋      | 149/400 [8:43:38<6:45:05, 96.83s/it]  38%|███▊      | 150/400 [8:44:43<6:03:42, 87.29s/it] 38%|███▊      | 151/400 [8:45:46<5:32:51, 80.21s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 192, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 38%|███▊      | 152/400 [8:46:53<5:14:12, 76.02s/it] 38%|███▊      | 153/400 [8:47:52<4:52:56, 71.16s/it] 38%|███▊      | 154/400 [8:48:55<4:40:52, 68.51s/it] 39%|███▉      | 155/400 [8:49:57<4:32:04, 66.63s/it] 39%|███▉      | 156/400 [8:50:58<4:24:15, 64.98s/it] 39%|███▉      | 157/400 [8:52:07<4:27:43, 66.10s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 177, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 40%|███▉      | 158/400 [8:53:09<4:21:56, 64.94s/it] 40%|███▉      | 159/400 [8:54:13<4:19:09, 64.52s/it] 40%|████      | 160/400 [8:55:17<4:18:29, 64.62s/it] 40%|████      | 161/400 [8:56:24<4:19:23, 65.12s/it] 40%|████      | 162/400 [8:57:23<4:11:57, 63.52s/it] 41%|████      | 163/400 [8:58:30<4:13:57, 64.29s/it] 41%|████      | 164/400 [8:59:29<4:07:26, 62.91s/it] 41%|████▏     | 165/400 [9:00:35<4:10:13, 63.89s/it] 42%|████▏     | 166/400 [9:01:41<4:11:43, 64.55s/it] 42%|████▏     | 167/400 [9:02:42<4:06:26, 63.46s/it] 42%|████▏     | 168/400 [9:03:46<4:05:27, 63.48s/it] 42%|████▏     | 169/400 [9:04:54<4:09:10, 64.72s/it] 42%|████▎     | 170/400 [9:05:54<4:03:44, 63.58s/it] 43%|████▎     | 171/400 [9:06:59<4:04:11, 63.98s/it] 43%|████▎     | 172/400 [9:08:00<3:59:40, 63.07s/it] 43%|████▎     | 173/400 [9:09:05<4:00:39, 63.61s/it] 44%|████▎     | 174/400 [9:10:05<3:55:18, 62.47s/it] 44%|████▍     | 175/400 [9:11:05<3:51:16, 61.67s/it] 44%|████▍     | 176/400 [9:12:07<3:50:54, 61.85s/it] 44%|████▍     | 177/400 [9:13:08<3:49:00, 61.62s/it] 44%|████▍     | 178/400 [9:14:10<3:48:45, 61.83s/it] 45%|████▍     | 179/400 [9:15:13<3:48:09, 61.94s/it] 45%|████▌     | 180/400 [9:16:15<3:47:28, 62.04s/it] 45%|████▌     | 181/400 [9:17:15<3:43:53, 61.34s/it] 46%|████▌     | 182/400 [9:18:16<3:42:35, 61.27s/it] 46%|████▌     | 183/400 [9:19:22<3:46:49, 62.72s/it] 46%|████▌     | 184/400 [9:20:20<3:41:09, 61.43s/it] 46%|████▋     | 185/400 [9:21:23<3:41:00, 61.68s/it] 46%|████▋     | 186/400 [9:22:29<3:44:45, 63.02s/it] 47%|████▋     | 187/400 [9:23:27<3:38:44, 61.62s/it] 47%|████▋     | 188/400 [9:24:35<3:44:01, 63.40s/it] 47%|████▋     | 189/400 [9:25:35<3:39:15, 62.35s/it] 48%|████▊     | 190/400 [9:26:42<3:43:32, 63.87s/it] 48%|████▊     | 191/400 [9:27:44<3:40:45, 63.38s/it] 48%|████▊     | 192/400 [9:28:45<3:37:17, 62.68s/it] 48%|████▊     | 193/400 [9:29:46<3:34:25, 62.15s/it] 48%|████▊     | 194/400 [9:30:51<3:36:18, 63.00s/it] 49%|████▉     | 195/400 [9:31:57<3:38:38, 63.99s/it] 49%|████▉     | 196/400 [9:33:00<3:35:49, 63.48s/it] 49%|████▉     | 197/400 [9:34:06<3:37:31, 64.29s/it] 50%|████▉     | 198/400 [9:35:09<3:35:44, 64.08s/it] 50%|████▉     | 199/400 [9:36:12<3:33:03, 63.60s/it] 50%|█████     | 200/400 [9:37:17<3:33:20, 64.00s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 427, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 50%|█████     | 201/400 [9:39:42<4:53:26, 88.47s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 614, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 50%|█████     | 202/400 [9:43:11<6:51:08, 124.59s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 464, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 51%|█████     | 203/400 [9:45:48<7:20:20, 134.12s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 618, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 51%|█████     | 204/400 [9:49:18<8:32:22, 156.85s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 522, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 51%|█████▏    | 205/400 [9:52:15<8:49:28, 162.92s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 617, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 52%|█████▏    | 206/400 [9:55:44<9:32:10, 176.96s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 608, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 52%|█████▏    | 207/400 [9:59:10<9:56:34, 185.46s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 463, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 52%|█████▏    | 208/400 [10:01:47<9:26:51, 177.14s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 391, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 52%|█████▏    | 209/400 [10:04:01<8:41:54, 163.95s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 433, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 52%|█████▎    | 210/400 [10:06:27<8:22:48, 158.78s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 480, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
