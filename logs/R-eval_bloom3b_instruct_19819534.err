Loaded module: cuda/12.1
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 17 examples [00:00, 76.83 examples/s]Generating train split: 26 examples [00:00, 63.46 examples/s]Generating train split: 34 examples [00:00, 67.70 examples/s]Generating train split: 44 examples [00:00, 51.32 examples/s]Generating train split: 52 examples [00:01, 43.40 examples/s]Generating train split: 59 examples [00:01, 45.48 examples/s]Generating train split: 68 examples [00:01, 23.75 examples/s]Generating train split: 73 examples [00:02, 24.50 examples/s]Generating train split: 81 examples [00:02, 31.53 examples/s]Generating train split: 88 examples [00:02, 33.19 examples/s]Generating train split: 110 examples [00:02, 62.89 examples/s]Generating train split: 122 examples [00:02, 64.50 examples/s]Generating train split: 137 examples [00:02, 80.49 examples/s]Generating train split: 151 examples [00:03, 64.27 examples/s]Generating train split: 162 examples [00:03, 62.95 examples/s]Generating train split: 172 examples [00:03, 40.35 examples/s]Generating train split: 181 examples [00:03, 45.28 examples/s]Generating train split: 190 examples [00:04, 41.81 examples/s]Generating train split: 198 examples [00:04, 47.18 examples/s]Generating train split: 210 examples [00:04, 52.68 examples/s]Generating train split: 217 examples [00:04, 53.63 examples/s]Generating train split: 226 examples [00:04, 52.67 examples/s]Generating train split: 239 examples [00:04, 62.58 examples/s]Generating train split: 246 examples [00:04, 58.66 examples/s]Generating train split: 258 examples [00:05, 70.98 examples/s]Generating train split: 268 examples [00:05, 58.06 examples/s]Generating train split: 278 examples [00:05, 54.96 examples/s]Generating train split: 291 examples [00:05, 68.43 examples/s]Generating train split: 300 examples [00:05, 53.99 examples/s]Generating train split: 309 examples [00:06, 51.95 examples/s]Generating train split: 322 examples [00:06, 55.77 examples/s]Generating train split: 334 examples [00:06, 66.05 examples/s]Generating train split: 343 examples [00:06, 60.45 examples/s]Generating train split: 354 examples [00:06, 57.81 examples/s]Generating train split: 363 examples [00:07, 48.71 examples/s]Generating train split: 374 examples [00:07, 47.17 examples/s]Generating train split: 382 examples [00:07, 43.60 examples/s]Generating train split: 392 examples [00:07, 43.96 examples/s]Generating train split: 403 examples [00:07, 46.38 examples/s]Generating train split: 415 examples [00:08, 47.70 examples/s]Generating train split: 426 examples [00:08, 56.03 examples/s]Generating train split: 435 examples [00:08, 53.76 examples/s]Generating train split: 448 examples [00:08, 65.03 examples/s]Generating train split: 459 examples [00:08, 54.37 examples/s]Generating train split: 468 examples [00:09, 54.10 examples/s]Generating train split: 477 examples [00:09, 60.20 examples/s]Generating train split: 489 examples [00:09, 52.47 examples/s]Generating train split: 499 examples [00:09, 53.25 examples/s]Generating train split: 515 examples [00:09, 71.45 examples/s]Generating train split: 525 examples [00:09, 64.74 examples/s]Generating train split: 537 examples [00:10, 64.61 examples/s]Generating train split: 548 examples [00:10, 64.17 examples/s]Generating train split: 550 examples [00:10, 52.82 examples/s]
Generating validation split: 0 examples [00:00, ? examples/s]Generating validation split: 426 examples [00:00, 4041.05 examples/s]Generating validation split: 878 examples [00:00, 871.59 examples/s] Generating validation split: 1178 examples [00:01, 1160.70 examples/s]Generating validation split: 1624 examples [00:01, 1711.91 examples/s]Generating validation split: 2000 examples [00:01, 1546.46 examples/s]Generating validation split: 2425 examples [00:01, 2000.49 examples/s]Generating validation split: 2778 examples [00:01, 1943.33 examples/s]Generating validation split: 3236 examples [00:01, 2392.44 examples/s]Generating validation split: 3654 examples [00:01, 2766.77 examples/s]Generating validation split: 4032 examples [00:01, 2998.94 examples/s]Generating validation split: 4639 examples [00:02, 2691.41 examples/s]Generating validation split: 5000 examples [00:02, 2782.13 examples/s]Generating validation split: 5429 examples [00:02, 3090.40 examples/s]Generating validation split: 5934 examples [00:02, 3551.64 examples/s]Generating validation split: 6378 examples [00:02, 2806.57 examples/s]Generating validation split: 6791 examples [00:02, 3085.32 examples/s]Generating validation split: 7285 examples [00:03, 2463.12 examples/s]Generating validation split: 7778 examples [00:03, 2863.91 examples/s]Generating validation split: 8302 examples [00:03, 3025.71 examples/s]Generating validation split: 8749 examples [00:03, 2663.09 examples/s]Generating validation split: 9128 examples [00:03, 2881.69 examples/s]Generating validation split: 9647 examples [00:04, 2412.66 examples/s]Generating validation split: 10059 examples [00:04, 2721.75 examples/s]Generating validation split: 10447 examples [00:04, 2898.20 examples/s]Generating validation split: 11000 examples [00:04, 2520.17 examples/s]Generating validation split: 11373 examples [00:04, 2746.04 examples/s]Generating validation split: 11747 examples [00:04, 2923.03 examples/s]Generating validation split: 12147 examples [00:04, 2447.58 examples/s]Generating validation split: 12547 examples [00:05, 2342.09 examples/s]Generating validation split: 13000 examples [00:05, 2534.82 examples/s]Generating validation split: 13447 examples [00:05, 2925.61 examples/s]Generating validation split: 13985 examples [00:05, 2636.01 examples/s]Generating validation split: 14399 examples [00:05, 2930.92 examples/s]Generating validation split: 14905 examples [00:05, 3396.98 examples/s]Generating validation split: 15476 examples [00:06, 2777.93 examples/s]Generating validation split: 15919 examples [00:06, 3096.46 examples/s]Generating validation split: 16434 examples [00:06, 2602.31 examples/s]Generating validation split: 16981 examples [00:06, 2486.98 examples/s]Generating validation split: 17338 examples [00:06, 2674.22 examples/s]Generating validation split: 17753 examples [00:07, 2451.96 examples/s]Generating validation split: 18055 examples [00:07, 2505.82 examples/s]Generating validation split: 18381 examples [00:07, 2647.18 examples/s]Generating validation split: 18681 examples [00:07, 1999.48 examples/s]Generating validation split: 19007 examples [00:07, 2239.34 examples/s]Generating validation split: 19481 examples [00:07, 2725.00 examples/s]Generating validation split: 19971 examples [00:07, 3229.39 examples/s]Generating validation split: 20380 examples [00:08, 2547.70 examples/s]Generating validation split: 20380 examples [00:08, 2387.79 examples/s]
Generating test split: 0 examples [00:00, ? examples/s]Generating test split: 400 examples [00:00, 1604.87 examples/s]
  0%|          | 0/400 [00:00<?, ?it/s]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/tokenization_utils_base.py:3862: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  warnings.warn(
/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 149, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  0%|          | 1/400 [00:12<1:26:03, 12.94s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 151, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  0%|          | 2/400 [00:26<1:26:39, 13.07s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 147, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  1%|          | 3/400 [00:38<1:25:49, 12.97s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 150, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  1%|          | 4/400 [00:51<1:25:24, 12.94s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 148, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  1%|▏         | 5/400 [01:04<1:24:27, 12.83s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 145, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  2%|▏         | 6/400 [01:17<1:23:42, 12.75s/it]  2%|▏         | 7/400 [01:29<1:23:45, 12.79s/it]  2%|▏         | 8/400 [01:42<1:23:10, 12.73s/it]  2%|▏         | 9/400 [01:55<1:22:43, 12.69s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 152, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  2%|▎         | 10/400 [02:08<1:22:58, 12.77s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 153, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  3%|▎         | 11/400 [02:21<1:23:39, 12.90s/it]  3%|▎         | 12/400 [02:34<1:23:27, 12.91s/it]  3%|▎         | 13/400 [02:47<1:23:14, 12.91s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 146, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  4%|▎         | 14/400 [02:59<1:22:30, 12.82s/it]  4%|▍         | 15/400 [03:12<1:22:22, 12.84s/it]  4%|▍         | 16/400 [03:25<1:22:16, 12.86s/it]  4%|▍         | 17/400 [03:38<1:22:08, 12.87s/it]  4%|▍         | 18/400 [03:51<1:21:59, 12.88s/it]  5%|▍         | 19/400 [04:04<1:21:50, 12.89s/it]  5%|▌         | 20/400 [04:17<1:21:39, 12.89s/it]  5%|▌         | 21/400 [04:29<1:20:54, 12.81s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 144, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  6%|▌         | 22/400 [04:42<1:19:42, 12.65s/it]  6%|▌         | 23/400 [04:54<1:19:58, 12.73s/it]  6%|▌         | 24/400 [05:08<1:20:36, 12.86s/it]  6%|▋         | 25/400 [05:20<1:20:25, 12.87s/it]  6%|▋         | 26/400 [05:33<1:20:10, 12.86s/it]  7%|▋         | 27/400 [05:46<1:19:27, 12.78s/it]  7%|▋         | 28/400 [05:59<1:19:27, 12.82s/it]  7%|▋         | 29/400 [06:12<1:19:24, 12.84s/it]  8%|▊         | 30/400 [06:25<1:19:17, 12.86s/it]  8%|▊         | 31/400 [06:37<1:18:34, 12.78s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 154, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
  8%|▊         | 32/400 [06:50<1:19:09, 12.91s/it]  8%|▊         | 33/400 [07:03<1:18:54, 12.90s/it]  8%|▊         | 34/400 [07:16<1:18:43, 12.91s/it]  9%|▉         | 35/400 [07:29<1:18:30, 12.91s/it]  9%|▉         | 36/400 [07:42<1:17:44, 12.81s/it]  9%|▉         | 37/400 [07:55<1:17:43, 12.85s/it] 10%|▉         | 38/400 [08:07<1:17:03, 12.77s/it] 10%|▉         | 39/400 [08:20<1:16:31, 12.72s/it] 10%|█         | 40/400 [08:32<1:15:32, 12.59s/it] 10%|█         | 41/400 [08:45<1:15:52, 12.68s/it] 10%|█         | 42/400 [08:58<1:16:04, 12.75s/it] 11%|█         | 43/400 [09:11<1:16:38, 12.88s/it] 11%|█         | 44/400 [09:24<1:15:55, 12.80s/it] 11%|█▏        | 45/400 [09:37<1:15:54, 12.83s/it] 12%|█▏        | 46/400 [09:49<1:15:17, 12.76s/it] 12%|█▏        | 47/400 [10:02<1:14:50, 12.72s/it] 12%|█▏        | 48/400 [10:15<1:14:56, 12.77s/it] 12%|█▏        | 49/400 [10:28<1:14:56, 12.81s/it] 12%|█▎        | 50/400 [10:41<1:14:51, 12.83s/it] 13%|█▎        | 51/400 [10:53<1:14:15, 12.77s/it] 13%|█▎        | 52/400 [11:06<1:14:16, 12.81s/it] 13%|█▎        | 53/400 [11:19<1:13:40, 12.74s/it] 14%|█▎        | 54/400 [11:32<1:13:43, 12.78s/it] 14%|█▍        | 55/400 [11:44<1:13:40, 12.81s/it] 14%|█▍        | 56/400 [11:57<1:13:36, 12.84s/it] 14%|█▍        | 57/400 [12:10<1:13:29, 12.86s/it] 14%|█▍        | 58/400 [12:23<1:13:20, 12.87s/it] 15%|█▍        | 59/400 [12:36<1:12:38, 12.78s/it] 15%|█▌        | 60/400 [12:48<1:12:07, 12.73s/it] 15%|█▌        | 61/400 [13:01<1:11:42, 12.69s/it] 16%|█▌        | 62/400 [13:14<1:11:50, 12.75s/it] 16%|█▌        | 63/400 [13:27<1:11:51, 12.80s/it] 16%|█▌        | 64/400 [13:40<1:11:46, 12.82s/it] 16%|█▋        | 65/400 [13:53<1:12:07, 12.92s/it] 16%|█▋        | 66/400 [14:06<1:11:52, 12.91s/it] 17%|█▋        | 67/400 [14:18<1:11:39, 12.91s/it] 17%|█▋        | 68/400 [14:31<1:11:21, 12.90s/it] 17%|█▋        | 69/400 [14:44<1:11:04, 12.88s/it] 18%|█▊        | 70/400 [14:57<1:10:52, 12.89s/it] 18%|█▊        | 71/400 [15:10<1:10:11, 12.80s/it] 18%|█▊        | 72/400 [15:22<1:09:37, 12.74s/it] 18%|█▊        | 73/400 [15:35<1:08:39, 12.60s/it] 18%|█▊        | 74/400 [15:47<1:08:51, 12.67s/it] 19%|█▉        | 75/400 [16:00<1:09:04, 12.75s/it] 19%|█▉        | 76/400 [16:13<1:09:06, 12.80s/it] 19%|█▉        | 77/400 [16:26<1:09:03, 12.83s/it] 20%|█▉        | 78/400 [16:39<1:09:25, 12.94s/it] 20%|█▉        | 79/400 [16:53<1:09:38, 13.02s/it] 20%|██        | 80/400 [17:05<1:09:11, 12.97s/it] 20%|██        | 81/400 [17:18<1:08:24, 12.87s/it] 20%|██        | 82/400 [17:31<1:08:40, 12.96s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 143, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 21%|██        | 83/400 [17:44<1:07:48, 12.84s/it] 21%|██        | 84/400 [17:57<1:07:42, 12.86s/it] 21%|██▏       | 85/400 [18:09<1:07:07, 12.79s/it] 22%|██▏       | 86/400 [18:22<1:07:07, 12.83s/it] 22%|██▏       | 87/400 [18:35<1:07:26, 12.93s/it] 22%|██▏       | 88/400 [18:49<1:07:37, 13.00s/it] 22%|██▏       | 89/400 [19:01<1:06:45, 12.88s/it] 22%|██▎       | 90/400 [19:14<1:06:07, 12.80s/it] 23%|██▎       | 91/400 [19:27<1:06:04, 12.83s/it] 23%|██▎       | 92/400 [19:40<1:06:22, 12.93s/it] 23%|██▎       | 93/400 [19:53<1:06:07, 12.93s/it] 24%|██▎       | 94/400 [20:05<1:05:24, 12.83s/it] 24%|██▍       | 95/400 [20:18<1:04:50, 12.76s/it] 24%|██▍       | 96/400 [20:31<1:04:50, 12.80s/it] 24%|██▍       | 97/400 [20:44<1:05:12, 12.91s/it] 24%|██▍       | 98/400 [20:57<1:04:59, 12.91s/it] 25%|██▍       | 99/400 [21:10<1:04:43, 12.90s/it] 25%|██▌       | 100/400 [21:22<1:04:03, 12.81s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 140, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 25%|██▌       | 101/400 [21:34<1:02:37, 12.57s/it] 26%|██▌       | 102/400 [21:47<1:02:23, 12.56s/it] 26%|██▌       | 103/400 [22:00<1:02:42, 12.67s/it] 26%|██▌       | 104/400 [22:13<1:03:14, 12.82s/it] 26%|██▋       | 105/400 [22:26<1:03:08, 12.84s/it] 26%|██▋       | 106/400 [22:39<1:03:24, 12.94s/it] 27%|██▋       | 107/400 [22:51<1:02:12, 12.74s/it] 27%|██▋       | 108/400 [23:04<1:02:14, 12.79s/it] 27%|██▋       | 109/400 [23:17<1:01:18, 12.64s/it] 28%|██▊       | 110/400 [23:29<1:01:30, 12.73s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 139, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 28%|██▊       | 111/400 [23:42<1:00:35, 12.58s/it] 28%|██▊       | 112/400 [23:54<59:31, 12.40s/it]   28%|██▊       | 113/400 [24:07<1:00:02, 12.55s/it] 28%|██▊       | 114/400 [24:19<59:55, 12.57s/it]   29%|██▉       | 115/400 [24:32<1:00:33, 12.75s/it] 29%|██▉       | 116/400 [24:45<1:00:08, 12.70s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 141, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 29%|██▉       | 117/400 [24:57<59:19, 12.58s/it]  /dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 138, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 30%|██▉       | 118/400 [25:09<58:15, 12.39s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 155, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 30%|██▉       | 119/400 [25:23<59:32, 12.71s/it] 30%|███       | 120/400 [25:36<59:57, 12.85s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 135, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 30%|███       | 121/400 [25:48<58:27, 12.57s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 137, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 30%|███       | 122/400 [26:00<57:22, 12.38s/it] 31%|███       | 123/400 [26:13<57:51, 12.53s/it] 31%|███       | 124/400 [26:25<57:42, 12.55s/it] 31%|███▏      | 125/400 [26:38<57:58, 12.65s/it] 32%|███▏      | 126/400 [26:51<58:30, 12.81s/it] 32%|███▏      | 127/400 [27:04<57:59, 12.75s/it] 32%|███▏      | 128/400 [27:17<58:24, 12.89s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 134, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 32%|███▏      | 129/400 [27:29<56:29, 12.51s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 156, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 32%|███▎      | 130/400 [27:42<57:15, 12.72s/it] 33%|███▎      | 131/400 [27:55<57:39, 12.86s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 157, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 33%|███▎      | 132/400 [28:09<58:19, 13.06s/it] 33%|███▎      | 133/400 [28:21<57:27, 12.91s/it] 34%|███▎      | 134/400 [28:34<57:36, 13.00s/it] 34%|███▍      | 135/400 [28:46<56:02, 12.69s/it] 34%|███▍      | 136/400 [28:59<55:41, 12.66s/it] 34%|███▍      | 137/400 [29:12<56:12, 12.82s/it] 34%|███▍      | 138/400 [29:25<56:00, 12.83s/it] 35%|███▍      | 139/400 [29:37<55:02, 12.65s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 131, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 35%|███▌      | 140/400 [29:49<53:29, 12.34s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 136, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 35%|███▌      | 141/400 [30:00<52:21, 12.13s/it] 36%|███▌      | 142/400 [30:13<52:15, 12.15s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 142, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 36%|███▌      | 143/400 [30:25<52:11, 12.18s/it] 36%|███▌      | 144/400 [30:37<52:25, 12.29s/it] 36%|███▋      | 145/400 [30:49<51:45, 12.18s/it] 36%|███▋      | 146/400 [31:02<51:40, 12.21s/it]/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py:1365: UserWarning: Input length of input_ids is 160, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.
  warnings.warn(
 37%|███▋      | 147/400 [31:15<53:06, 12.59s/it] 37%|███▋      | 148/400 [31:28<53:14, 12.68s/it] 37%|███▋      | 149/400 [31:41<54:00, 12.91s/it] 38%|███▊      | 150/400 [31:54<53:46, 12.90s/it] 38%|███▊      | 151/400 [32:07<53:31, 12.90s/it] 38%|███▊      | 152/400 [32:20<53:17, 12.89s/it] 38%|███▊      | 153/400 [32:32<52:14, 12.69s/it] 38%|███▊      | 154/400 [32:45<51:29, 12.56s/it] 39%|███▉      | 155/400 [32:57<50:55, 12.47s/it] 39%|███▉      | 156/400 [33:09<50:28, 12.41s/it] 39%|███▉      | 157/400 [33:23<51:31, 12.72s/it] 40%|███▉      | 158/400 [33:35<51:07, 12.67s/it] 40%|███▉      | 159/400 [33:48<50:47, 12.64s/it] 40%|████      | 160/400 [34:01<51:11, 12.80s/it] 40%|████      | 160/400 [34:13<51:20, 12.84s/it]
Traceback (most recent call last):
  File "/dtu/p1/johlau/Tk-Instruct/src/run_bloom.py", line 74, in <module>
    response = model.generate(
  File "/zhome/4e/b/208805/.local/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py", line 1759, in generate
    return self.greedy_search(
  File "/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/generation/utils.py", line 2622, in greedy_search
    outputs = self(
  File "/zhome/4e/b/208805/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/4e/b/208805/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/dtu/p1/johlau/LMOps/minillm/transformers/src/transformers/models/bloom/modeling_bloom.py", line 886, in forward
    lm_logits = self.lm_head(hidden_states)
  File "/zhome/4e/b/208805/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/4e/b/208805/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/4e/b/208805/.local/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
KeyboardInterrupt
usage: compute_metrics.py [-h] --predictions PREDICTIONS
                          [--track {default,xlingual}]
                          [--compute_per_category_metrics]
                          [--compute_per_task_metrics]
compute_metrics.py: error: argument --track: invalid choice: 'english' (choose from 'default', 'xlingual')
/dtu/p1/johlau/Tk-Instruct/scripts/run_bloom.sh: line 23: syntax error near unexpected token `done'
/dtu/p1/johlau/Tk-Instruct/scripts/run_bloom.sh: line 23: `done'
