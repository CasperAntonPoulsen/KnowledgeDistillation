Wed Dec 13 14:14:46 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA H100 PCIe               On  | 00000000:41:00.0 Off |                    0 |
| N/A   24C    P0              45W / 350W |      4MiB / 81559MiB |      0%   E. Process |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
python3 -m torch.distributed.run --nproc_per_node 1 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 3013 /dtu/p1/johlau/LMOps/minillm/train_minillm.py --base-path /dtu/p1/johlau/LMOps/minillm --model-path /dtu/p1/johlau/LMOps/minillm/results/llama/train/minillm_init/llama-7B --teacher-model-path /dtu/p1/johlau/LMOps/minillm/results/llama/train/sft/llama-13B --ckpt-name 7B-init --teacher-ckpt-name 13B-sft --n-gpu 1 --n-nodes 1 --model-type llama --teacher-model-fp16 --gradient-checkpointing --prompt-data-dir /dtu/p1/johlau/LMOps/minillm/processed_data/dolly_both/prompt/llama/ --lm-data-dir /dtu/p1/johlau/LMOps/minillm/processed_data/roberta_both/llama/256/20M/ --dev-num 1000 --num-workers 0 --epochs 10 --total-iters 5000 --kd-ratio 0.5 --batch-size 2 --eval-batch-size 4 --lr 5e-6 --lr-min 5e-6 --gradient-accumulation-steps 2 --max-length 256 --max-prompt-length 128 --warmup-iters 100 --scheduler-name cosine_trm --save /dtu/p1/johlau/LMOps/minillm/results/llama/train/minillm_both/ --seed 10 --seed-ppo 42 --seed-lm 7 --save-interval 500 --eval-interval 100 --log-interval 16 --mid-log-num 1 --type minillm --ppo-epochs 4 --num-rollouts 64 --chunk-size 2 --length-norm --single-step-reg --teacher-mixed-alpha 0.2 --reward-scaling 0.5 --cliprange-reward 100 --do-sample --top-k 0 --top-p 1.0 --temperature 1.0 --deepspeed --deepspeed_config /dtu/p1/johlau/LMOps/minillm/configs/deepspeed/ds_config_zero2_offload.json /dtu/p1/johlau/LMOps/minillm 3013
PYTHONPATH=/dtu/p1/johlau/LMOps/minillm
[2023-12-13 14:14:51,518] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
[2023-12-13 14:14:53,059] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-12-13 14:14:53,059] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_path ................... /dtu/p1/johlau/LMOps/minillm/results/llama/train/minillm_init/llama-7B
  ckpt_name .................... 7B-init
  model_type ................... llama
  teacher_model_type ........... None
  n_gpu ........................ 1
  n_nodes ...................... 1
  teacher_model_path ........... /dtu/p1/johlau/LMOps/minillm/results/llama/train/sft/llama-13B
  teacher_ckpt_name ............ 13B-sft
  teacher_model_fp16 ........... True
  model_parallel ............... False
  model_parallel_size .......... None
  no_value ..................... False
  dropout_path_rate ............ None
  fp32 ......................... False
  type ......................... minillm
  do_train ..................... False
  do_valid ..................... False
  do_eval ...................... False
  base_path .................... /dtu/p1/johlau/LMOps/minillm
  load ......................... None
  save ......................... /dtu/p1/johlau/LMOps/minillm/results/llama/train/minillm_both/bs2-lr5e-06-G2-N1-NN1-lm1-len256/pe4_rs0.5_nr64_ln_sr_tm0.2
  log_interval ................. 16
  mid_log_num .................. 1
  save_interval ................ 500
  eval_interval ................ 100
  local_rank ................... 0
  save_additional_suffix ....... 
  save_rollout ................. False
  eb_sample_times .............. 3
  data_dir ..................... None
  processed_data_dir ........... None
  force_process ................ False
  force_process_demo ........... False
  data_process_workers ......... -1
  train_num .................... -1
  train_ratio .................. 1
  dev_num ...................... 1000
  dev_ratio .................... 1
  gen_num ...................... -1
  data_names ................... None
  prompt_type .................. None
  num_workers .................. 0
  max_prompt_length ............ 128
  min_prompt_length ............ 64
  json_data .................... False
  bin_data ..................... False
  txt_data ..................... False
  prompt_data_dir .............. /dtu/p1/johlau/LMOps/minillm/processed_data/dolly_both/prompt/llama/
  lm_data_dir .................. /dtu/p1/johlau/LMOps/minillm/processed_data/roberta_both/llama/256/20M/
  eval_ppl ..................... False
  eval_rw ...................... False
  eval_gen ..................... False
  only_prompt .................. False
  batch_size ................... 2
  eval_batch_size .............. 4
  clip_grad .................... 1.0
  total_iters .................. 5000
  train_iters_per_epoch ........ -1
  max_length ................... 256
  seed ......................... 10
  seed_order ................... 42
  seed_data .................... 42
  seed_ppo ..................... 42
  seed_lm ...................... 7
  epochs ....................... 10
  training_epochs .............. 10000
  gradient_accumulation_steps .. 2
  gradient_checkpointing ....... True
  attn_dtype ................... None
  lr ........................... 5e-06
  lr_min ....................... 5e-06
  weight_decay ................. 0.01
  loss_scale ................... 65536
  kd_ratio ..................... 0.5
  warmup_iters ................. 100
  lr_decay_iters ............... None
  lr_decay_style ............... noam
  scheduler_name ............... cosine_trm
  reward_scaling ............... 0.5
  cliprange_reward ............. 100.0
  ppo_epochs ................... 4
  num_rollouts ................. 64
  num_rollouts_per_device ...... 64
  cliprange .................... 0.2
  chunk_size ................... 2
  gamma ........................ 0.95
  length_norm .................. True
  single_step_reg .............. True
  teacher_mixed_alpha .......... 0.2
  lm_coef ...................... 1
  top_k ........................ 0
  top_p ........................ 1.0
  do_sample .................... True
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  num_beams .................... 1
  temperature .................. 1.0
  peft ......................... None
  peft_lora_r .................. 8
  peft_lora_alpha .............. 32
  peft_lora_dropout ............ 0.1
  peft_name .................... None
  peft_path .................... None
  teacher_peft_name ............ None
  teacher_peft_path ............ None
  deepspeed .................... True
  deepspeed_config ............. /dtu/p1/johlau/LMOps/minillm/configs/deepspeed/ds_config_zero2_offload.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  rank ......................... 0
  world_size ................... 1
 > number of parameters: 13015864320
 > number of parameters: 6738415616
Model load time: 7.466050386428833s
 > number of parameters: 6738M
[2023-12-13 14:15:15,045] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.1, git-hash=unknown, git-branch=unknown
[2023-12-13 14:15:15,970] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-12-13 14:15:15,971] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-12-13 14:15:15,971] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2023-12-13 14:15:15,983] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2023-12-13 14:15:15,983] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2023-12-13 14:15:15,983] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer
[2023-12-13 14:15:15,983] [INFO] [stage_1_and_2.py:147:__init__] Reduce bucket size 200000000
[2023-12-13 14:15:15,983] [INFO] [stage_1_and_2.py:148:__init__] Allgather bucket size 200000000
[2023-12-13 14:15:15,983] [INFO] [stage_1_and_2.py:149:__init__] CPU Offload: True
[2023-12-13 14:15:15,983] [INFO] [stage_1_and_2.py:150:__init__] Round robin gradient partitioning: False
[2023-12-13 14:15:27,840] [INFO] [utils.py:802:see_memory_usage] Before initializing optimizer states
[2023-12-13 14:15:27,841] [INFO] [utils.py:803:see_memory_usage] MA 37.23 GB         Max_MA 37.23 GB         CA 37.23 GB         Max_CA 37 GB 
[2023-12-13 14:15:27,841] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 142.42 GB, percent = 18.9%
[2023-12-13 14:16:16,138] [INFO] [utils.py:802:see_memory_usage] After initializing optimizer states
[2023-12-13 14:16:16,139] [INFO] [utils.py:803:see_memory_usage] MA 37.23 GB         Max_MA 37.23 GB         CA 37.23 GB         Max_CA 37 GB 
[2023-12-13 14:16:16,139] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 213.07 GB, percent = 28.2%
[2023-12-13 14:16:16,139] [INFO] [stage_1_and_2.py:514:__init__] optimizer state initialized
[2023-12-13 14:16:16,231] [INFO] [utils.py:802:see_memory_usage] After initializing ZeRO optimizer
[2023-12-13 14:16:16,232] [INFO] [utils.py:803:see_memory_usage] MA 37.23 GB         Max_MA 37.23 GB         CA 37.23 GB         Max_CA 37 GB 
[2023-12-13 14:16:16,232] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 213.07 GB, percent = 28.2%
[2023-12-13 14:16:16,240] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = AdamW
[2023-12-13 14:16:16,240] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-12-13 14:16:16,240] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7f055029efd0>
[2023-12-13 14:16:16,240] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[[0.9, 0.95]]
[2023-12-13 14:16:16,241] [INFO] [config.py:972:print] DeepSpeedEngine configuration:
[2023-12-13 14:16:16,241] [INFO] [config.py:976:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-12-13 14:16:16,241] [INFO] [config.py:976:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-12-13 14:16:16,241] [INFO] [config.py:976:print]   amp_enabled .................. False
[2023-12-13 14:16:16,241] [INFO] [config.py:976:print]   amp_params ................... False
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   bfloat16_enabled ............. False
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   checkpoint_parallel_write_pipeline  False
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   checkpoint_tag_validation_enabled  True
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   checkpoint_tag_validation_fail  False
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f055029e850>
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   communication_data_type ...... None
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   curriculum_enabled_legacy .... False
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   curriculum_params_legacy ..... False
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   data_efficiency_enabled ...... False
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   dataloader_drop_last ......... False
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   disable_allgather ............ False
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   dump_state ................... False
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 5000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   eigenvalue_enabled ........... False
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   eigenvalue_gas_boundary_resolution  1
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   eigenvalue_layer_num ......... 0
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   eigenvalue_max_iter .......... 100
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   eigenvalue_stability ......... 1e-06
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   eigenvalue_tol ............... 0.01
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   eigenvalue_verbose ........... False
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   elasticity_enabled ........... False
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   fp16_auto_cast ............... False
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   fp16_enabled ................. True
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   fp16_master_weights_and_gradients  False
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   global_rank .................. 0
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   grad_accum_dtype ............. None
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   gradient_accumulation_steps .. 2
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   gradient_clipping ............ 1.0
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   gradient_predivide_factor .... 1.0
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   initial_dynamic_scale ........ 2048
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   load_universal_checkpoint .... False
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   loss_scale ................... 0
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   memory_breakdown ............. False
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   mics_hierarchial_params_gather  False
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   mics_shard_size .............. -1
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   optimizer_legacy_fusion ...... False
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   optimizer_name ............... None
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   optimizer_params ............. None
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   pld_enabled .................. False
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   pld_params ................... False
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   prescale_gradients ........... False
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   scheduler_name ............... None
[2023-12-13 14:16:16,242] [INFO] [config.py:976:print]   scheduler_params ............. None
[2023-12-13 14:16:16,243] [INFO] [config.py:976:print]   seq_parallel_communication_data_type  torch.float32
[2023-12-13 14:16:16,243] [INFO] [config.py:976:print]   sparse_attention ............. None
[2023-12-13 14:16:16,243] [INFO] [config.py:976:print]   sparse_gradients_enabled ..... False
[2023-12-13 14:16:16,243] [INFO] [config.py:976:print]   steps_per_print .............. 10000000
[2023-12-13 14:16:16,243] [INFO] [config.py:976:print]   train_batch_size ............. 4
[2023-12-13 14:16:16,243] [INFO] [config.py:976:print]   train_micro_batch_size_per_gpu  2
[2023-12-13 14:16:16,243] [INFO] [config.py:976:print]   use_node_local_storage ....... False
[2023-12-13 14:16:16,243] [INFO] [config.py:976:print]   wall_clock_breakdown ......... False
[2023-12-13 14:16:16,243] [INFO] [config.py:976:print]   weight_quantization_config ... None
[2023-12-13 14:16:16,243] [INFO] [config.py:976:print]   world_size ................... 1
[2023-12-13 14:16:16,243] [INFO] [config.py:976:print]   zero_allow_untested_optimizer  True
[2023-12-13 14:16:16,243] [INFO] [config.py:976:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2023-12-13 14:16:16,243] [INFO] [config.py:976:print]   zero_enabled ................. True
[2023-12-13 14:16:16,243] [INFO] [config.py:976:print]   zero_force_ds_cpu_optimizer .. False
[2023-12-13 14:16:16,243] [INFO] [config.py:976:print]   zero_optimization_stage ...... 2
[2023-12-13 14:16:16,243] [INFO] [config.py:962:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 2, 
    "gradient_accumulation_steps": 2, 
    "zero_optimization": {
        "stage": 2, 
        "offload_optimizer": {
            "device": "cpu"
        }, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 2.000000e+08, 
        "contiguous_gradients": true
    }, 
    "zero_force_ds_cpu_optimizer": false, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 5.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1.000000e+07
}
Probing Dataset
Probing end. Max data state 1, total length 36562
Num PPO instances: 36562
Probing Dataset
Probing end. Max data state 1, total length 968
Num PPO instances: 968
Probing Dataset
Probing end. Max data state 1, total length 20000000
Num LM instances: 20000000
Probing Dataset
Probing end. Max data state 1, total length 10000
Num LM instances: 10000
                                 Evaluation #0                                  
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ prompts                               ┃ samples                              ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ Below is an instruction that          │ Below is an instruction that         │
│ describes a task. Write a response    │ describes a task. Write a response   │
│ that appropriately completes the      │ that appropriately completes the     │
│ request.                              │ request.                             │
│                                       │                                      │
│ ### Instruction:                      │ ### Instruction:                     │
│ That sounds boring. I want to create  │ That sounds boring. I want to create │
│ something new.                        │ something new.                       │
│                                       │                                      │
│ ### Response:                         │ ### Response:                        │
│                                       │ It sounds boring, but this is        │
│                                       │ actually a question on a scientific  │
│                                       │ structured interview. The point      │
│                                       │ behind this question is to figure    │
│                                       │ out how you will react in those rare │
│                                       │ situations when you will experience  │
│                                       │ something new. Most people fall back │
│                                       │ to the safe zone, considering this   │
│                                       │ situation as a boring one, but       │
│                                       │ that's is not the best answer.       │
│                                       │ Instead answer with the one that     │
│                                       │ actually depicts what you will do    │
│                                       │ when that occurs.                    │
├───────────────────────────────────────┼──────────────────────────────────────┤
│ Below is an instruction that          │ Below is an instruction that         │
│ describes a task. Write a response    │ describes a task. Write a response   │
│ that appropriately completes the      │ that appropriately completes the     │
│ request.                              │ request.                             │
│                                       │                                      │
│ ### Instruction:                      │ ### Instruction:                     │
│ That sounds boring. I want to create  │ That sounds boring. I want to create │
│ something new.                        │ something new.                       │
│                                       │                                      │
│ ### Response:                         │ ### Response:                        │
│                                       │ You said what you do not to enjoy,   │
│                                       │ it seems that making something new   │
│                                       │ makes you depressed. But there are   │
│                                       │ always people who come up with great │
│                                       │ ideas, such as Steven Spielberg's    │
│                                       │ creation by combining parts of       │
│                                       │ Gremlins and Jaws or Adele Adkins is │
│                                       │ widely credited by the public for    │
│                                       │ being "the breaker of 2000/2010."    │
│                                       │                                      │
│                                       │ If you put yourself in a positive    │
│                                       │ head space and want to let yourself  │
│                                       │ feel relaxed and enthusiastic about  │
│                                       │ the project, sprinkle in these four  │
│                                       │ steps.                               │
│                                       │                                      │
│                                       │ First, you need to have a good       │
│                                       │ foundation of                        │
├───────────────────────────────────────┼──────────────────────────────────────┤
│ Below is an instruction that          │ Below is an instruction that         │
│ describes a task. Write a response    │ describes a task. Write a response   │
│ that appropriately completes the      │ that appropriately completes the     │
│ request.                              │ request.                             │
│                                       │                                      │
│ ### Instruction:                      │ ### Instruction:                     │
│ That sounds boring. I want to create  │ That sounds boring. I want to create │
│ something new.                        │ something new.                       │
│                                       │                                      │
│ ### Response:                         │ ### Response:                        │
│                                       │ I can help you in that.              │
└───────────────────────────────────────┴──────────────────────────────────────┘
eval | rougeL: 11.379 | exact_match: 0.103 | rev_kl: 1.932 | lens: 76.589 | pt_loss: 1.161 | lm_loss: 1.274 | kd_loss: 1.048 
Total Steps: 5000 Data Epochs: 10
train | data_epochs  0/10 | inner iter:   1/ 32 | ppo epoch:  0/ 4 | global iter:      2/  5000| tot_loss: 3.9759 | rl_loss: 2.1047 | pt_loss: 1.8711 | pg_loss: 0.3036 | reg_loss: 1.8011 | reward: -0.4820 | rev_kl: 2.0385 | stu_lens: 66.0000 | mixed_lens: 106.5000 | lr: 5.0000e-08 | scale: 2048.00 | time: 25.952 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/ 32 | ppo epoch:  0/ 4 | global iter:      3/  5000| tot_loss: 3.9605 | rl_loss: 2.2314 | pt_loss: 1.7291 | pg_loss: 0.1326 | reg_loss: 2.0988 | reward: -1.9394 | rev_kl: 1.6580 | stu_lens: 39.5000 | mixed_lens: 15.5000 | lr: 1.0000e-07 | scale: 2048.00 | time: 26.465 | step time: 0.000
train | data_epochs  0/10 | inner iter:   5/ 32 | ppo epoch:  0/ 4 | global iter:      4/  5000| tot_loss: 3.2326 | rl_loss: 1.3657 | pt_loss: 1.8669 | pg_loss: 0.0401 | reg_loss: 1.3256 | reward: -0.3455 | rev_kl: 1.6920 | stu_lens: 122.0000 | mixed_lens: 128.0000 | lr: 1.5000e-07 | scale: 2048.00 | time: 26.400 | step time: 0.000
train | data_epochs  0/10 | inner iter:   7/ 32 | ppo epoch:  0/ 4 | global iter:      5/  5000| tot_loss: 3.6779 | rl_loss: 1.9798 | pt_loss: 1.6981 | pg_loss: 0.3928 | reg_loss: 1.5870 | reward: -0.4746 | rev_kl: 1.7700 | stu_lens: 81.5000 | mixed_lens: 88.0000 | lr: 2.0000e-07 | scale: 2048.00 | time: 26.462 | step time: 0.000
train | data_epochs  0/10 | inner iter:   9/ 32 | ppo epoch:  0/ 4 | global iter:      6/  5000| tot_loss: 3.5863 | rl_loss: 1.5702 | pt_loss: 2.0161 | pg_loss: 0.2766 | reg_loss: 1.2936 | reward: -6.4882 | rev_kl: 1.7520 | stu_lens: 31.5000 | mixed_lens: 66.0000 | lr: 2.5000e-07 | scale: 2048.00 | time: 26.452 | step time: 0.000
train | data_epochs  0/10 | inner iter:  11/ 32 | ppo epoch:  0/ 4 | global iter:      7/  5000| tot_loss: 4.7110 | rl_loss: 2.7204 | pt_loss: 1.9905 | pg_loss: 0.3403 | reg_loss: 2.3801 | reward: -0.6012 | rev_kl: 2.7109 | stu_lens: 77.0000 | mixed_lens: 101.0000 | lr: 3.0000e-07 | scale: 2048.00 | time: 26.447 | step time: 0.000
train | data_epochs  0/10 | inner iter:  13/ 32 | ppo epoch:  0/ 4 | global iter:      8/  5000| tot_loss: 6.9285 | rl_loss: 4.9442 | pt_loss: 1.9844 | pg_loss: 1.8140 | reg_loss: 3.1302 | reward: -4.6650 | rev_kl: 1.0152 | stu_lens: 50.0000 | mixed_lens: 24.5000 | lr: 3.5000e-07 | scale: 2048.00 | time: 26.392 | step time: 0.000
train | data_epochs  0/10 | inner iter:  15/ 32 | ppo epoch:  0/ 4 | global iter:      9/  5000| tot_loss: 5.9482 | rl_loss: 4.1043 | pt_loss: 1.8439 | pg_loss: 1.1780 | reg_loss: 2.9263 | reward: -3.2792 | rev_kl: 1.0944 | stu_lens: 12.5000 | mixed_lens: 30.5000 | lr: 4.0000e-07 | scale: 2048.00 | time: 26.444 | step time: 0.000
train | data_epochs  0/10 | inner iter:  17/ 32 | ppo epoch:  0/ 4 | global iter:     10/  5000| tot_loss: 3.7728 | rl_loss: 2.1392 | pt_loss: 1.6337 | pg_loss: 0.3052 | reg_loss: 1.8340 | reward: -0.7481 | rev_kl: 1.8829 | stu_lens: 43.5000 | mixed_lens: 88.0000 | lr: 4.5000e-07 | scale: 2048.00 | time: 26.401 | step time: 0.000
train | data_epochs  0/10 | inner iter:  19/ 32 | ppo epoch:  0/ 4 | global iter:     11/  5000| tot_loss: 7.1793 | rl_loss: 5.6493 | pt_loss: 1.5299 | pg_loss: 2.9390 | reg_loss: 2.7103 | reward: -1.4368 | rev_kl: 1.7042 | stu_lens: 8.5000 | mixed_lens: 8.5000 | lr: 5.0000e-07 | scale: 2048.00 | time: 26.431 | step time: 0.000
train | data_epochs  0/10 | inner iter:  21/ 32 | ppo epoch:  0/ 4 | global iter:     12/  5000| tot_loss: 4.2910 | rl_loss: 2.3168 | pt_loss: 1.9742 | pg_loss: 0.7207 | reg_loss: 1.5960 | reward: -0.2692 | rev_kl: 1.2351 | stu_lens: 20.5000 | mixed_lens: 65.5000 | lr: 5.5000e-07 | scale: 2048.00 | time: 26.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:  23/ 32 | ppo epoch:  0/ 4 | global iter:     13/  5000| tot_loss: 3.6740 | rl_loss: 2.0140 | pt_loss: 1.6600 | pg_loss: 0.6224 | reg_loss: 1.3916 | reward: -0.9847 | rev_kl: 0.4495 | stu_lens: 39.0000 | mixed_lens: 76.5000 | lr: 6.0000e-07 | scale: 2048.00 | time: 26.429 | step time: 0.000
train | data_epochs  0/10 | inner iter:  25/ 32 | ppo epoch:  0/ 4 | global iter:     14/  5000| tot_loss: 4.3087 | rl_loss: 2.1786 | pt_loss: 2.1300 | pg_loss: 0.3165 | reg_loss: 1.8621 | reward: -0.6628 | rev_kl: 1.1501 | stu_lens: 90.0000 | mixed_lens: 96.5000 | lr: 6.5000e-07 | scale: 2048.00 | time: 26.389 | step time: 0.000
train | data_epochs  0/10 | inner iter:  27/ 32 | ppo epoch:  0/ 4 | global iter:     15/  5000| tot_loss: 3.8135 | rl_loss: 2.1221 | pt_loss: 1.6914 | pg_loss: 0.5718 | reg_loss: 1.5503 | reward: -0.2751 | rev_kl: 1.3768 | stu_lens: 35.0000 | mixed_lens: 72.5000 | lr: 7.0000e-07 | scale: 2048.00 | time: 26.421 | step time: 0.000
train | data_epochs  0/10 | inner iter:  29/ 32 | ppo epoch:  0/ 4 | global iter:     16/  5000| tot_loss: 3.4175 | rl_loss: 2.0499 | pt_loss: 1.3676 | pg_loss: 0.5290 | reg_loss: 1.5209 | reward: 0.1896 | rev_kl: 1.6933 | stu_lens: 77.5000 | mixed_lens: 65.5000 | lr: 7.5000e-07 | scale: 2048.00 | time: 26.382 | step time: 0.000
****************************************************************************************************
train | data_epochs  0/10 | inner iter:  29/ 32 | ppo epoch:  0/ 4 | global iter:     16/  5000| tot_loss: 4.0221 | rl_loss: 2.3603 | pt_loss: 1.6618 | pg_loss: 0.5974 | reg_loss: 1.7629 | reward: -1.1183 | rev_kl: 1.5840 | stu_lens: 64.0469 | mixed_lens: 68.1406 | lr: 7.5000e-07 | scale: 2048.00 | time: 26.382 | step time: 26.064
/dtu/p1/johlau/LMOps/minillm/results/llama/train/minillm_both/bs2-lr5e-06-G2-N1-NN1-lm1-len256/pe4_rs0.5_nr64_ln_sr_tm0.2
****************************************************************************************************
train | data_epochs  0/10 | inner iter:  31/ 32 | ppo epoch:  0/ 4 | global iter:     17/  5000| tot_loss: 4.2858 | rl_loss: 2.6029 | pt_loss: 1.6830 | pg_loss: 0.4297 | reg_loss: 2.1731 | reward: -1.6248 | rev_kl: 2.6924 | stu_lens: 48.0000 | mixed_lens: 77.5000 | lr: 8.0000e-07 | scale: 2048.00 | time: 26.447 | step time: 0.000
train | data_epochs  0/10 | inner iter:   1/ 32 | ppo epoch:  1/ 4 | global iter:     18/  5000| tot_loss: 3.7247 | rl_loss: 2.3395 | pt_loss: 1.3852 | pg_loss: 0.7780 | reg_loss: 1.5615 | reward: -0.6861 | rev_kl: 1.2703 | stu_lens: 73.5000 | mixed_lens: 30.5000 | lr: 8.5000e-07 | scale: 2048.00 | time: 26.381 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/ 32 | ppo epoch:  1/ 4 | global iter:     19/  5000| tot_loss: 6.0031 | rl_loss: 4.1653 | pt_loss: 1.8378 | pg_loss: 2.3134 | reg_loss: 1.8519 | reward: -2.2836 | rev_kl: 2.4295 | stu_lens: 58.0000 | mixed_lens: 11.5000 | lr: 9.0000e-07 | scale: 2048.00 | time: 26.409 | step time: 0.000
train | data_epochs  0/10 | inner iter:   5/ 32 | ppo epoch:  1/ 4 | global iter:     20/  5000| tot_loss: 5.7042 | rl_loss: 3.8595 | pt_loss: 1.8447 | pg_loss: 0.7864 | reg_loss: 3.0731 | reward: -1.3777 | rev_kl: 1.6573 | stu_lens: 29.0000 | mixed_lens: 47.0000 | lr: 9.5000e-07 | scale: 2048.00 | time: 26.375 | step time: 0.000
train | data_epochs  0/10 | inner iter:   7/ 32 | ppo epoch:  1/ 4 | global iter:     21/  5000| tot_loss: 4.0547 | rl_loss: 1.9383 | pt_loss: 2.1164 | pg_loss: 0.4931 | reg_loss: 1.4452 | reward: -0.5707 | rev_kl: 1.3514 | stu_lens: 102.0000 | mixed_lens: 65.5000 | lr: 1.0000e-06 | scale: 2048.00 | time: 26.400 | step time: 0.000
train | data_epochs  0/10 | inner iter:   9/ 32 | ppo epoch:  1/ 4 | global iter:     22/  5000| tot_loss: 3.3259 | rl_loss: 1.7643 | pt_loss: 1.5617 | pg_loss: 0.2699 | reg_loss: 1.4943 | reward: -0.6289 | rev_kl: 1.4350 | stu_lens: 90.5000 | mixed_lens: 76.0000 | lr: 1.0500e-06 | scale: 2048.00 | time: 26.369 | step time: 0.000
train | data_epochs  0/10 | inner iter:  11/ 32 | ppo epoch:  1/ 4 | global iter:     23/  5000| tot_loss: 4.3559 | rl_loss: 2.8258 | pt_loss: 1.5301 | pg_loss: 1.2190 | reg_loss: 1.6068 | reward: -0.9662 | rev_kl: 1.0472 | stu_lens: 8.0000 | mixed_lens: 40.0000 | lr: 1.1000e-06 | scale: 2048.00 | time: 26.401 | step time: 0.000
train | data_epochs  0/10 | inner iter:  13/ 32 | ppo epoch:  1/ 4 | global iter:     24/  5000| tot_loss: 3.5836 | rl_loss: 2.0389 | pt_loss: 1.5447 | pg_loss: 0.5798 | reg_loss: 1.4591 | reward: -0.4580 | rev_kl: 2.3014 | stu_lens: 61.5000 | mixed_lens: 68.0000 | lr: 1.1500e-06 | scale: 2048.00 | time: 26.365 | step time: 0.000
train | data_epochs  0/10 | inner iter:  15/ 32 | ppo epoch:  1/ 4 | global iter:     25/  5000| tot_loss: 4.5659 | rl_loss: 2.7337 | pt_loss: 1.8321 | pg_loss: 0.6184 | reg_loss: 2.1153 | reward: -1.6362 | rev_kl: 2.6902 | stu_lens: 65.5000 | mixed_lens: 63.0000 | lr: 1.2000e-06 | scale: 2048.00 | time: 26.397 | step time: 0.000
train | data_epochs  0/10 | inner iter:  17/ 32 | ppo epoch:  1/ 4 | global iter:     26/  5000| tot_loss: 3.7811 | rl_loss: 1.9251 | pt_loss: 1.8561 | pg_loss: 0.2440 | reg_loss: 1.6810 | reward: -0.6858 | rev_kl: 1.2990 | stu_lens: 109.0000 | mixed_lens: 103.5000 | lr: 1.2500e-06 | scale: 2048.00 | time: 26.358 | step time: 0.000
train | data_epochs  0/10 | inner iter:  19/ 32 | ppo epoch:  1/ 4 | global iter:     27/  5000| tot_loss: 3.3033 | rl_loss: 1.5017 | pt_loss: 1.8016 | pg_loss: 0.2606 | reg_loss: 1.2410 | reward: -0.5660 | rev_kl: 1.8400 | stu_lens: 75.5000 | mixed_lens: 88.0000 | lr: 1.3000e-06 | scale: 2048.00 | time: 26.390 | step time: 0.000
train | data_epochs  0/10 | inner iter:  21/ 32 | ppo epoch:  1/ 4 | global iter:     28/  5000| tot_loss: 2.9776 | rl_loss: 1.5917 | pt_loss: 1.3860 | pg_loss: 0.4227 | reg_loss: 1.1690 | reward: -0.3823 | rev_kl: 1.4500 | stu_lens: 84.0000 | mixed_lens: 72.5000 | lr: 1.3500e-06 | scale: 2048.00 | time: 26.369 | step time: 0.000
train | data_epochs  0/10 | inner iter:  23/ 32 | ppo epoch:  1/ 4 | global iter:     29/  5000| tot_loss: 3.3349 | rl_loss: 1.8141 | pt_loss: 1.5208 | pg_loss: 0.5143 | reg_loss: 1.2998 | reward: -2.6630 | rev_kl: 1.4823 | stu_lens: 22.5000 | mixed_lens: 48.5000 | lr: 1.4000e-06 | scale: 2048.00 | time: 26.390 | step time: 0.000
train | data_epochs  0/10 | inner iter:  25/ 32 | ppo epoch:  1/ 4 | global iter:     30/  5000| tot_loss: 5.4507 | rl_loss: 4.0308 | pt_loss: 1.4198 | pg_loss: 1.4104 | reg_loss: 2.6204 | reward: -2.2618 | rev_kl: 2.1563 | stu_lens: 31.0000 | mixed_lens: 26.5000 | lr: 1.4500e-06 | scale: 2048.00 | time: 26.348 | step time: 0.000
train | data_epochs  0/10 | inner iter:  27/ 32 | ppo epoch:  1/ 4 | global iter:     31/  5000| tot_loss: 3.4700 | rl_loss: 1.7877 | pt_loss: 1.6823 | pg_loss: 0.0258 | reg_loss: 1.7618 | reward: -0.4005 | rev_kl: 1.7785 | stu_lens: 76.0000 | mixed_lens: 128.0000 | lr: 1.5000e-06 | scale: 2048.00 | time: 26.380 | step time: 0.000
train | data_epochs  0/10 | inner iter:  29/ 32 | ppo epoch:  1/ 4 | global iter:     32/  5000| tot_loss: 4.9730 | rl_loss: 3.3918 | pt_loss: 1.5813 | pg_loss: 1.2224 | reg_loss: 2.1694 | reward: -6.9684 | rev_kl: 2.1298 | stu_lens: 65.5000 | mixed_lens: 25.0000 | lr: 1.5500e-06 | scale: 2048.00 | time: 26.349 | step time: 0.000
****************************************************************************************************
train | data_epochs  0/10 | inner iter:  29/ 32 | ppo epoch:  1/ 4 | global iter:     32/  5000| tot_loss: 3.9524 | rl_loss: 2.2310 | pt_loss: 1.7214 | pg_loss: 0.5449 | reg_loss: 1.6861 | reward: -1.2342 | rev_kl: 1.8086 | stu_lens: 66.8281 | mixed_lens: 72.0781 | lr: 1.5500e-06 | scale: 2048.00 | time: 26.349 | step time: 27.634
/dtu/p1/johlau/LMOps/minillm/results/llama/train/minillm_both/bs2-lr5e-06-G2-N1-NN1-lm1-len256/pe4_rs0.5_nr64_ln_sr_tm0.2
****************************************************************************************************
train | data_epochs  0/10 | inner iter:  31/ 32 | ppo epoch:  1/ 4 | global iter:     33/  5000| tot_loss: 2.9304 | rl_loss: 1.4156 | pt_loss: 1.5148 | pg_loss: 0.0072 | reg_loss: 1.4084 | reward: -0.3843 | rev_kl: 1.7577 | stu_lens: 84.0000 | mixed_lens: 128.0000 | lr: 1.6000e-06 | scale: 2048.00 | time: 26.359 | step time: 0.000
train | data_epochs  0/10 | inner iter:   1/ 32 | ppo epoch:  2/ 4 | global iter:     34/  5000| tot_loss: 2.4043 | rl_loss: 0.7539 | pt_loss: 1.6503 | pg_loss: -0.0050 | reg_loss: 0.7589 | reward: -0.4765 | rev_kl: 1.8104 | stu_lens: 88.0000 | mixed_lens: 128.0000 | lr: 1.6500e-06 | scale: 2048.00 | time: 26.347 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/ 32 | ppo epoch:  2/ 4 | global iter:     35/  5000| tot_loss: 3.5896 | rl_loss: 1.5541 | pt_loss: 2.0356 | pg_loss: 0.4164 | reg_loss: 1.1377 | reward: -1.4091 | rev_kl: 1.9875 | stu_lens: 38.0000 | mixed_lens: 63.5000 | lr: 1.7000e-06 | scale: 2048.00 | time: 26.375 | step time: 0.000
train | data_epochs  0/10 | inner iter:   5/ 32 | ppo epoch:  2/ 4 | global iter:     36/  5000| tot_loss: 4.2078 | rl_loss: 2.1756 | pt_loss: 2.0322 | pg_loss: 0.3063 | reg_loss: 1.8693 | reward: -0.6754 | rev_kl: 2.3096 | stu_lens: 66.0000 | mixed_lens: 76.5000 | lr: 1.7500e-06 | scale: 2048.00 | time: 26.346 | step time: 0.000
train | data_epochs  0/10 | inner iter:   7/ 32 | ppo epoch:  2/ 4 | global iter:     37/  5000| tot_loss: 3.4400 | rl_loss: 1.7157 | pt_loss: 1.7243 | pg_loss: 0.4277 | reg_loss: 1.2880 | reward: -0.9128 | rev_kl: 0.7370 | stu_lens: 28.5000 | mixed_lens: 53.5000 | lr: 1.8000e-06 | scale: 2048.00 | time: 26.366 | step time: 0.000
train | data_epochs  0/10 | inner iter:   9/ 32 | ppo epoch:  2/ 4 | global iter:     38/  5000| tot_loss: 3.7249 | rl_loss: 1.9156 | pt_loss: 1.8093 | pg_loss: 0.2860 | reg_loss: 1.6296 | reward: -0.6884 | rev_kl: 1.6063 | stu_lens: 128.0000 | mixed_lens: 96.5000 | lr: 1.8500e-06 | scale: 2048.00 | time: 26.367 | step time: 0.000
train | data_epochs  0/10 | inner iter:  11/ 32 | ppo epoch:  2/ 4 | global iter:     39/  5000| tot_loss: 2.9479 | rl_loss: 1.0261 | pt_loss: 1.9218 | pg_loss: 0.1537 | reg_loss: 0.8724 | reward: -0.3591 | rev_kl: 1.4020 | stu_lens: 79.5000 | mixed_lens: 104.5000 | lr: 1.9000e-06 | scale: 2048.00 | time: 26.379 | step time: 0.000
train | data_epochs  0/10 | inner iter:  13/ 32 | ppo epoch:  2/ 4 | global iter:     40/  5000| tot_loss: 2.7679 | rl_loss: 1.8796 | pt_loss: 0.8883 | pg_loss: 0.5980 | reg_loss: 1.2816 | reward: -1.7041 | rev_kl: 1.6695 | stu_lens: 77.0000 | mixed_lens: 67.0000 | lr: 1.9500e-06 | scale: 2048.00 | time: 26.301 | step time: 0.000
train | data_epochs  0/10 | inner iter:  15/ 32 | ppo epoch:  2/ 4 | global iter:     41/  5000| tot_loss: 2.9666 | rl_loss: 1.4831 | pt_loss: 1.4835 | pg_loss: 0.3458 | reg_loss: 1.1373 | reward: -0.9018 | rev_kl: 1.9494 | stu_lens: 84.0000 | mixed_lens: 87.0000 | lr: 2.0000e-06 | scale: 2048.00 | time: 26.372 | step time: 0.000
train | data_epochs  0/10 | inner iter:  17/ 32 | ppo epoch:  2/ 4 | global iter:     42/  5000| tot_loss: 4.8196 | rl_loss: 3.0835 | pt_loss: 1.7361 | pg_loss: 1.7579 | reg_loss: 1.3256 | reward: -1.2798 | rev_kl: 2.4027 | stu_lens: 70.5000 | mixed_lens: 22.0000 | lr: 2.0500e-06 | scale: 2048.00 | time: 26.334 | step time: 0.000
train | data_epochs  0/10 | inner iter:  19/ 32 | ppo epoch:  2/ 4 | global iter:     43/  5000| tot_loss: 3.2769 | rl_loss: 1.3673 | pt_loss: 1.9096 | pg_loss: 0.3052 | reg_loss: 1.0621 | reward: -0.4232 | rev_kl: 1.6811 | stu_lens: 34.0000 | mixed_lens: 74.5000 | lr: 2.1000e-06 | scale: 2048.00 | time: 26.362 | step time: 0.000
train | data_epochs  0/10 | inner iter:  21/ 32 | ppo epoch:  2/ 4 | global iter:     44/  5000| tot_loss: 2.7515 | rl_loss: 0.8568 | pt_loss: 1.8947 | pg_loss: 0.0184 | reg_loss: 0.8384 | reward: -0.2643 | rev_kl: 1.7287 | stu_lens: 76.0000 | mixed_lens: 128.0000 | lr: 2.1500e-06 | scale: 2048.00 | time: 26.337 | step time: 0.000
train | data_epochs  0/10 | inner iter:  23/ 32 | ppo epoch:  2/ 4 | global iter:     45/  5000| tot_loss: 3.3602 | rl_loss: 1.7171 | pt_loss: 1.6431 | pg_loss: 0.7506 | reg_loss: 0.9665 | reward: -0.7707 | rev_kl: 1.6553 | stu_lens: 74.5000 | mixed_lens: 44.5000 | lr: 2.2000e-06 | scale: 2048.00 | time: 26.369 | step time: 0.000
train | data_epochs  0/10 | inner iter:  25/ 32 | ppo epoch:  2/ 4 | global iter:     46/  5000| tot_loss: 5.0418 | rl_loss: 3.2480 | pt_loss: 1.7939 | pg_loss: 1.2184 | reg_loss: 2.0296 | reward: -3.9321 | rev_kl: 2.1622 | stu_lens: 70.5000 | mixed_lens: 27.0000 | lr: 2.2500e-06 | scale: 2048.00 | time: 26.330 | step time: 0.000
train | data_epochs  0/10 | inner iter:  27/ 32 | ppo epoch:  2/ 4 | global iter:     47/  5000| tot_loss: 3.0058 | rl_loss: 1.4130 | pt_loss: 1.5927 | pg_loss: 1.1820 | reg_loss: 0.2310 | reward: 0.0646 | rev_kl: 1.0812 | stu_lens: 44.0000 | mixed_lens: 5.5000 | lr: 2.3000e-06 | scale: 2048.00 | time: 26.346 | step time: 0.000
train | data_epochs  0/10 | inner iter:  29/ 32 | ppo epoch:  2/ 4 | global iter:     48/  5000| tot_loss: 3.6053 | rl_loss: 1.5490 | pt_loss: 2.0563 | pg_loss: 0.4264 | reg_loss: 1.1225 | reward: -2.7205 | rev_kl: 2.0370 | stu_lens: 47.0000 | mixed_lens: 71.5000 | lr: 2.3500e-06 | scale: 2048.00 | time: 26.331 | step time: 0.000
****************************************************************************************************
train | data_epochs  0/10 | inner iter:  29/ 32 | ppo epoch:  2/ 4 | global iter:     48/  5000| tot_loss: 3.3906 | rl_loss: 1.6513 | pt_loss: 1.7393 | pg_loss: 0.4946 | reg_loss: 1.1567 | reward: -1.1219 | rev_kl: 1.6666 | stu_lens: 72.5781 | mixed_lens: 77.5938 | lr: 2.3500e-06 | scale: 2048.00 | time: 26.331 | step time: 27.603
/dtu/p1/johlau/LMOps/minillm/results/llama/train/minillm_both/bs2-lr5e-06-G2-N1-NN1-lm1-len256/pe4_rs0.5_nr64_ln_sr_tm0.2
****************************************************************************************************
train | data_epochs  0/10 | inner iter:  31/ 32 | ppo epoch:  2/ 4 | global iter:     49/  5000| tot_loss: 4.7803 | rl_loss: 3.2087 | pt_loss: 1.5716 | pg_loss: 2.1915 | reg_loss: 1.0172 | reward: -2.2008 | rev_kl: 3.2130 | stu_lens: 6.5000 | mixed_lens: 16.5000 | lr: 2.4000e-06 | scale: 2048.00 | time: 26.336 | step time: 0.000
train | data_epochs  0/10 | inner iter:   1/ 32 | ppo epoch:  3/ 4 | global iter:     50/  5000| tot_loss: 2.8922 | rl_loss: 1.2884 | pt_loss: 1.6037 | pg_loss: 0.5817 | reg_loss: 0.7067 | reward: 0.1421 | rev_kl: 2.0121 | stu_lens: 39.5000 | mixed_lens: 66.0000 | lr: 2.4500e-06 | scale: 2048.00 | time: 26.367 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/ 32 | ppo epoch:  3/ 4 | global iter:     51/  5000| tot_loss: 3.4093 | rl_loss: 1.2612 | pt_loss: 2.1481 | pg_loss: 0.5547 | reg_loss: 0.7065 | reward: -0.8847 | rev_kl: 1.1720 | stu_lens: 102.0000 | mixed_lens: 64.0000 | lr: 2.5000e-06 | scale: 2048.00 | time: 26.368 | step time: 0.000
train | data_epochs  0/10 | inner iter:   5/ 32 | ppo epoch:  3/ 4 | global iter:     52/  5000| tot_loss: 3.4447 | rl_loss: 1.7933 | pt_loss: 1.6514 | pg_loss: 0.4151 | reg_loss: 1.3782 | reward: -3.7680 | rev_kl: 2.4879 | stu_lens: 60.0000 | mixed_lens: 67.0000 | lr: 2.5500e-06 | scale: 2048.00 | time: 26.333 | step time: 0.000
train | data_epochs  0/10 | inner iter:   7/ 32 | ppo epoch:  3/ 4 | global iter:     53/  5000| tot_loss: 3.5204 | rl_loss: 1.8248 | pt_loss: 1.6957 | pg_loss: 1.2205 | reg_loss: 0.6043 | reward: -1.9794 | rev_kl: 2.7799 | stu_lens: 60.5000 | mixed_lens: 36.5000 | lr: 2.6000e-06 | scale: 2048.00 | time: 26.358 | step time: 0.000
train | data_epochs  0/10 | inner iter:   9/ 32 | ppo epoch:  3/ 4 | global iter:     54/  5000| tot_loss: 4.8505 | rl_loss: 3.4605 | pt_loss: 1.3900 | pg_loss: 2.2827 | reg_loss: 1.1778 | reward: -2.1728 | rev_kl: 2.4849 | stu_lens: 19.5000 | mixed_lens: 5.0000 | lr: 2.6500e-06 | scale: 2048.00 | time: 26.329 | step time: 0.000
train | data_epochs  0/10 | inner iter:  11/ 32 | ppo epoch:  3/ 4 | global iter:     55/  5000| tot_loss: 3.1424 | rl_loss: 1.2369 | pt_loss: 1.9054 | pg_loss: 0.4587 | reg_loss: 0.7782 | reward: -0.1191 | rev_kl: 1.6929 | stu_lens: 57.5000 | mixed_lens: 68.0000 | lr: 2.7000e-06 | scale: 2048.00 | time: 26.359 | step time: 0.000
train | data_epochs  0/10 | inner iter:  13/ 32 | ppo epoch:  3/ 4 | global iter:     56/  5000| tot_loss: 2.4730 | rl_loss: 0.6862 | pt_loss: 1.7868 | pg_loss: 0.1903 | reg_loss: 0.4959 | reward: -0.2323 | rev_kl: 1.1001 | stu_lens: 73.5000 | mixed_lens: 74.5000 | lr: 2.7500e-06 | scale: 2048.00 | time: 26.311 | step time: 0.000
train | data_epochs  0/10 | inner iter:  15/ 32 | ppo epoch:  3/ 4 | global iter:     57/  5000| tot_loss: 2.9162 | rl_loss: 1.2955 | pt_loss: 1.6206 | pg_loss: 0.5842 | reg_loss: 0.7114 | reward: 0.0007 | rev_kl: 1.0619 | stu_lens: 65.5000 | mixed_lens: 65.5000 | lr: 2.8000e-06 | scale: 2048.00 | time: 26.352 | step time: 0.000
train | data_epochs  0/10 | inner iter:  17/ 32 | ppo epoch:  3/ 4 | global iter:     58/  5000| tot_loss: 2.0318 | rl_loss: 0.6866 | pt_loss: 1.3451 | pg_loss: 0.2034 | reg_loss: 0.4833 | reward: -0.9071 | rev_kl: 1.1678 | stu_lens: 65.0000 | mixed_lens: 96.5000 | lr: 2.8500e-06 | scale: 2048.00 | time: 26.324 | step time: 0.000
train | data_epochs  0/10 | inner iter:  19/ 32 | ppo epoch:  3/ 4 | global iter:     59/  5000| tot_loss: 2.9386 | rl_loss: 1.3598 | pt_loss: 1.5788 | pg_loss: 0.3239 | reg_loss: 1.0359 | reward: -0.6754 | rev_kl: 2.3096 | stu_lens: 66.0000 | mixed_lens: 76.5000 | lr: 2.9000e-06 | scale: 2048.00 | time: 26.363 | step time: 0.000
train | data_epochs  0/10 | inner iter:  21/ 32 | ppo epoch:  3/ 4 | global iter:     60/  5000| tot_loss: 2.6788 | rl_loss: 0.9932 | pt_loss: 1.6856 | pg_loss: 0.4598 | reg_loss: 0.5333 | reward: -1.3336 | rev_kl: 1.3149 | stu_lens: 21.5000 | mixed_lens: 65.0000 | lr: 2.9500e-06 | scale: 2048.00 | time: 26.337 | step time: 0.000
train | data_epochs  0/10 | inner iter:  23/ 32 | ppo epoch:  3/ 4 | global iter:     61/  5000| tot_loss: 2.6322 | rl_loss: 0.7189 | pt_loss: 1.9134 | pg_loss: 0.0162 | reg_loss: 0.7027 | reward: -0.1654 | rev_kl: 1.0769 | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 3.0000e-06 | scale: 2048.00 | time: 26.368 | step time: 0.000
train | data_epochs  0/10 | inner iter:  25/ 32 | ppo epoch:  3/ 4 | global iter:     62/  5000| tot_loss: 3.0952 | rl_loss: 1.2270 | pt_loss: 1.8682 | pg_loss: 0.4297 | reg_loss: 0.7973 | reward: -1.0816 | rev_kl: 1.2689 | stu_lens: 69.5000 | mixed_lens: 87.0000 | lr: 3.0500e-06 | scale: 2048.00 | time: 26.320 | step time: 0.000
train | data_epochs  0/10 | inner iter:  27/ 32 | ppo epoch:  3/ 4 | global iter:     63/  5000| tot_loss: 3.6656 | rl_loss: 1.7431 | pt_loss: 1.9225 | pg_loss: 1.3375 | reg_loss: 0.4056 | reward: -2.6947 | rev_kl: 1.5922 | stu_lens: 71.0000 | mixed_lens: 29.0000 | lr: 3.1000e-06 | scale: 2048.00 | time: 26.338 | step time: 0.000
train | data_epochs  0/10 | inner iter:  29/ 32 | ppo epoch:  3/ 4 | global iter:     64/  5000| tot_loss: 4.9178 | rl_loss: 3.1400 | pt_loss: 1.7778 | pg_loss: 2.0154 | reg_loss: 1.1246 | reward: -1.4392 | rev_kl: 1.9379 | stu_lens: 21.0000 | mixed_lens: 15.5000 | lr: 3.1500e-06 | scale: 2048.00 | time: 26.317 | step time: 0.000
****************************************************************************************************
train | data_epochs  0/10 | inner iter:  29/ 32 | ppo epoch:  3/ 4 | global iter:     64/  5000| tot_loss: 3.1353 | rl_loss: 1.3796 | pt_loss: 1.7557 | pg_loss: 0.6144 | reg_loss: 0.7652 | reward: -1.2318 | rev_kl: 1.8079 | stu_lens: 68.9219 | mixed_lens: 73.1875 | lr: 3.1500e-06 | scale: 2048.00 | time: 26.317 | step time: 27.594
/dtu/p1/johlau/LMOps/minillm/results/llama/train/minillm_both/bs2-lr5e-06-G2-N1-NN1-lm1-len256/pe4_rs0.5_nr64_ln_sr_tm0.2
****************************************************************************************************
train | data_epochs  0/10 | inner iter:  31/ 32 | ppo epoch:  3/ 4 | global iter:     65/  5000| tot_loss: 2.8488 | rl_loss: 1.0986 | pt_loss: 1.7502 | pg_loss: 0.3749 | reg_loss: 0.7237 | reward: -0.8275 | rev_kl: 1.9752 | stu_lens: 44.5000 | mixed_lens: 69.0000 | lr: 3.2000e-06 | scale: 2048.00 | time: 26.343 | step time: 0.000
[2023-12-13 15:18:49,621] [INFO] [loss_scaler.py:190:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2048, but hysteresis is 4. Reducing hysteresis to 3
train | data_epochs  0/10 | inner iter:   1/ 32 | ppo epoch:  0/ 4 | global iter:     66/  5000| tot_loss: 3.0275 | rl_loss: 1.1333 | pt_loss: 1.8943 | pg_loss: 0.1550 | reg_loss: 0.9782 | reward: -0.3009 | rev_kl: 1.1314 | stu_lens: 98.0000 | mixed_lens: 114.5000 | lr: 3.2000e-06 | scale: 2048.00 | time: 2.853 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/ 32 | ppo epoch:  0/ 4 | global iter:     67/  5000| tot_loss: 3.1871 | rl_loss: 0.9758 | pt_loss: 2.2113 | pg_loss: 0.1022 | reg_loss: 0.8736 | reward: -0.0460 | rev_kl: 0.5472 | stu_lens: 128.0000 | mixed_lens: 113.5000 | lr: 3.2500e-06 | scale: 2048.00 | time: 26.314 | step time: 0.000
train | data_epochs  0/10 | inner iter:   5/ 32 | ppo epoch:  0/ 4 | global iter:     68/  5000| tot_loss: 3.4825 | rl_loss: 1.7867 | pt_loss: 1.6958 | pg_loss: 0.3744 | reg_loss: 1.4123 | reward: -0.9519 | rev_kl: 1.7375 | stu_lens: 92.0000 | mixed_lens: 80.0000 | lr: 3.3000e-06 | scale: 2048.00 | time: 26.288 | step time: 0.000
train | data_epochs  0/10 | inner iter:   7/ 32 | ppo epoch:  0/ 4 | global iter:     69/  5000| tot_loss: 4.2115 | rl_loss: 2.4641 | pt_loss: 1.7474 | pg_loss: 0.7215 | reg_loss: 1.7425 | reward: -1.5270 | rev_kl: 1.5642 | stu_lens: 128.0000 | mixed_lens: 50.5000 | lr: 3.3500e-06 | scale: 2048.00 | time: 26.349 | step time: 0.000
train | data_epochs  0/10 | inner iter:   9/ 32 | ppo epoch:  0/ 4 | global iter:     70/  5000| tot_loss: 3.6732 | rl_loss: 1.9764 | pt_loss: 1.6968 | pg_loss: 0.4120 | reg_loss: 1.5644 | reward: -0.5509 | rev_kl: 1.0368 | stu_lens: 128.0000 | mixed_lens: 77.5000 | lr: 3.4000e-06 | scale: 2048.00 | time: 26.324 | step time: 0.000
train | data_epochs  0/10 | inner iter:  11/ 32 | ppo epoch:  0/ 4 | global iter:     71/  5000| tot_loss: 3.1511 | rl_loss: 1.4859 | pt_loss: 1.6652 | pg_loss: 0.0464 | reg_loss: 1.4396 | reward: -0.2745 | rev_kl: 1.4604 | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 3.4500e-06 | scale: 2048.00 | time: 26.345 | step time: 0.000
train | data_epochs  0/10 | inner iter:  13/ 32 | ppo epoch:  0/ 4 | global iter:     72/  5000| tot_loss: 2.5158 | rl_loss: 1.2014 | pt_loss: 1.3144 | pg_loss: 0.0294 | reg_loss: 1.1720 | reward: -0.3790 | rev_kl: 1.0348 | stu_lens: 101.0000 | mixed_lens: 128.0000 | lr: 3.5000e-06 | scale: 2048.00 | time: 26.311 | step time: 0.000
train | data_epochs  0/10 | inner iter:  15/ 32 | ppo epoch:  0/ 4 | global iter:     73/  5000| tot_loss: 3.8803 | rl_loss: 1.7866 | pt_loss: 2.0937 | pg_loss: 0.0592 | reg_loss: 1.7274 | reward: -0.2519 | rev_kl: 1.3170 | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 3.5500e-06 | scale: 2048.00 | time: 26.349 | step time: 0.000
train | data_epochs  0/10 | inner iter:  17/ 32 | ppo epoch:  0/ 4 | global iter:     74/  5000| tot_loss: 3.8417 | rl_loss: 2.2976 | pt_loss: 1.5440 | pg_loss: 0.7119 | reg_loss: 1.5857 | reward: -0.7386 | rev_kl: 1.4457 | stu_lens: 92.5000 | mixed_lens: 63.5000 | lr: 3.6000e-06 | scale: 2048.00 | time: 26.310 | step time: 0.000
train | data_epochs  0/10 | inner iter:  19/ 32 | ppo epoch:  0/ 4 | global iter:     75/  5000| tot_loss: 2.3251 | rl_loss: 0.9985 | pt_loss: 1.3265 | pg_loss: 0.0426 | reg_loss: 0.9560 | reward: -0.1578 | rev_kl: 1.1856 | stu_lens: 99.5000 | mixed_lens: 128.0000 | lr: 3.6500e-06 | scale: 2048.00 | time: 26.343 | step time: 0.000
train | data_epochs  0/10 | inner iter:  21/ 32 | ppo epoch:  0/ 4 | global iter:     76/  5000| tot_loss: 3.4535 | rl_loss: 1.5566 | pt_loss: 1.8968 | pg_loss: 0.1935 | reg_loss: 1.3632 | reward: -0.3476 | rev_kl: 1.2841 | stu_lens: 101.5000 | mixed_lens: 114.0000 | lr: 3.7000e-06 | scale: 2048.00 | time: 26.310 | step time: 0.000
train | data_epochs  0/10 | inner iter:  23/ 32 | ppo epoch:  0/ 4 | global iter:     77/  5000| tot_loss: 4.8323 | rl_loss: 3.4212 | pt_loss: 1.4111 | pg_loss: 1.6928 | reg_loss: 1.7283 | reward: -1.5888 | rev_kl: 1.8432 | stu_lens: 38.5000 | mixed_lens: 25.0000 | lr: 3.7500e-06 | scale: 2048.00 | time: 26.331 | step time: 0.000
train | data_epochs  0/10 | inner iter:  25/ 32 | ppo epoch:  0/ 4 | global iter:     78/  5000| tot_loss: 2.9096 | rl_loss: 1.3207 | pt_loss: 1.5889 | pg_loss: 0.2754 | reg_loss: 1.0453 | reward: -0.4501 | rev_kl: 0.8102 | stu_lens: 61.0000 | mixed_lens: 86.0000 | lr: 3.8000e-06 | scale: 2048.00 | time: 26.310 | step time: 0.000
train | data_epochs  0/10 | inner iter:  27/ 32 | ppo epoch:  0/ 4 | global iter:     79/  5000| tot_loss: 3.9212 | rl_loss: 2.3959 | pt_loss: 1.5252 | pg_loss: 0.7242 | reg_loss: 1.6717 | reward: -0.8537 | rev_kl: 1.5944 | stu_lens: 61.0000 | mixed_lens: 68.0000 | lr: 3.8500e-06 | scale: 2048.00 | time: 26.336 | step time: 0.000
train | data_epochs  0/10 | inner iter:  29/ 32 | ppo epoch:  0/ 4 | global iter:     80/  5000| tot_loss: 3.7337 | rl_loss: 1.9804 | pt_loss: 1.7532 | pg_loss: 0.6578 | reg_loss: 1.3227 | reward: -2.5999 | rev_kl: 1.2817 | stu_lens: 68.0000 | mixed_lens: 62.5000 | lr: 3.9000e-06 | scale: 2048.00 | time: 26.300 | step time: 0.000
****************************************************************************************************
train | data_epochs  0/10 | inner iter:  29/ 32 | ppo epoch:  0/ 4 | global iter:     80/  5000| tot_loss: 3.4909 | rl_loss: 1.7621 | pt_loss: 1.7288 | pg_loss: 0.4351 | reg_loss: 1.3271 | reward: -0.7558 | rev_kl: 1.3589 | stu_lens: 79.4219 | mixed_lens: 85.1719 | lr: 3.9000e-06 | scale: 2048.00 | time: 26.300 | step time: 26.107
/dtu/p1/johlau/LMOps/minillm/results/llama/train/minillm_both/bs2-lr5e-06-G2-N1-NN1-lm1-len256/pe4_rs0.5_nr64_ln_sr_tm0.2
****************************************************************************************************
train | data_epochs  0/10 | inner iter:  31/ 32 | ppo epoch:  0/ 4 | global iter:     81/  5000| tot_loss: 3.8913 | rl_loss: 2.1199 | pt_loss: 1.7714 | pg_loss: 0.7241 | reg_loss: 1.3958 | reward: -0.6836 | rev_kl: 3.3805 | stu_lens: 78.0000 | mixed_lens: 61.5000 | lr: 3.9500e-06 | scale: 2048.00 | time: 26.380 | step time: 0.000
train | data_epochs  0/10 | inner iter:   1/ 32 | ppo epoch:  1/ 4 | global iter:     82/  5000| tot_loss: 2.9217 | rl_loss: 1.0728 | pt_loss: 1.8490 | pg_loss: 0.3882 | reg_loss: 0.6846 | reward: -0.3778 | rev_kl: 0.7606 | stu_lens: 71.0000 | mixed_lens: 86.0000 | lr: 4.0000e-06 | scale: 2048.00 | time: 26.303 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/ 32 | ppo epoch:  1/ 4 | global iter:     83/  5000| tot_loss: 2.6349 | rl_loss: 0.7348 | pt_loss: 1.9001 | pg_loss: -0.0141 | reg_loss: 0.7489 | reward: -0.2903 | rev_kl: 1.2591 | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.0500e-06 | scale: 2048.00 | time: 26.336 | step time: 0.000
train | data_epochs  0/10 | inner iter:   5/ 32 | ppo epoch:  1/ 4 | global iter:     84/  5000| tot_loss: 4.9319 | rl_loss: 3.1678 | pt_loss: 1.7641 | pg_loss: 2.1051 | reg_loss: 1.0627 | reward: -0.6730 | rev_kl: 3.3198 | stu_lens: 15.5000 | mixed_lens: 11.5000 | lr: 4.1000e-06 | scale: 2048.00 | time: 26.300 | step time: 0.000
train | data_epochs  0/10 | inner iter:   7/ 32 | ppo epoch:  1/ 4 | global iter:     85/  5000| tot_loss: 2.4495 | rl_loss: 0.9658 | pt_loss: 1.4837 | pg_loss: 0.0017 | reg_loss: 0.9641 | reward: -0.3091 | rev_kl: 1.6977 | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.1500e-06 | scale: 2048.00 | time: 26.335 | step time: 0.000
train | data_epochs  0/10 | inner iter:   9/ 32 | ppo epoch:  1/ 4 | global iter:     86/  5000| tot_loss: 2.1749 | rl_loss: 0.5697 | pt_loss: 1.6051 | pg_loss: 0.2408 | reg_loss: 0.3289 | reward: -0.9440 | rev_kl: 1.2277 | stu_lens: 72.5000 | mixed_lens: 72.5000 | lr: 4.2000e-06 | scale: 2048.00 | time: 26.301 | step time: 0.000
train | data_epochs  0/10 | inner iter:  11/ 32 | ppo epoch:  1/ 4 | global iter:     87/  5000| tot_loss: 3.3769 | rl_loss: 1.7315 | pt_loss: 1.6454 | pg_loss: 0.8267 | reg_loss: 0.9048 | reward: -0.7498 | rev_kl: 1.1934 | stu_lens: 89.5000 | mixed_lens: 58.5000 | lr: 4.2500e-06 | scale: 2048.00 | time: 26.336 | step time: 0.000
train | data_epochs  0/10 | inner iter:  13/ 32 | ppo epoch:  1/ 4 | global iter:     88/  5000| tot_loss: 3.0169 | rl_loss: 1.0131 | pt_loss: 2.0038 | pg_loss: 0.1945 | reg_loss: 0.8186 | reward: -1.1152 | rev_kl: 1.1099 | stu_lens: 89.5000 | mixed_lens: 82.0000 | lr: 4.3000e-06 | scale: 2048.00 | time: 26.293 | step time: 0.000
train | data_epochs  0/10 | inner iter:  15/ 32 | ppo epoch:  1/ 4 | global iter:     89/  5000| tot_loss: 2.8956 | rl_loss: 1.0389 | pt_loss: 1.8567 | pg_loss: 0.0217 | reg_loss: 1.0172 | reward: -0.2519 | rev_kl: 1.3170 | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.3500e-06 | scale: 2048.00 | time: 26.336 | step time: 0.000
train | data_epochs  0/10 | inner iter:  17/ 32 | ppo epoch:  1/ 4 | global iter:     90/  5000| tot_loss: 2.7656 | rl_loss: 0.8320 | pt_loss: 1.9336 | pg_loss: 0.3000 | reg_loss: 0.5321 | reward: -0.7495 | rev_kl: 1.3086 | stu_lens: 41.0000 | mixed_lens: 90.5000 | lr: 4.4000e-06 | scale: 2048.00 | time: 26.305 | step time: 0.000
train | data_epochs  0/10 | inner iter:  19/ 32 | ppo epoch:  1/ 4 | global iter:     91/  5000| tot_loss: 2.9590 | rl_loss: 1.4957 | pt_loss: 1.4632 | pg_loss: 0.2852 | reg_loss: 1.2105 | reward: -0.4394 | rev_kl: 1.2058 | stu_lens: 92.5000 | mixed_lens: 83.5000 | lr: 4.4500e-06 | scale: 2048.00 | time: 26.322 | step time: 0.000
train | data_epochs  0/10 | inner iter:  21/ 32 | ppo epoch:  1/ 4 | global iter:     92/  5000| tot_loss: 2.3196 | rl_loss: 1.0379 | pt_loss: 1.2817 | pg_loss: 0.3456 | reg_loss: 0.6923 | reward: 0.8947 | rev_kl: 1.1386 | stu_lens: 68.0000 | mixed_lens: 68.5000 | lr: 4.5000e-06 | scale: 2048.00 | time: 26.304 | step time: 0.000
train | data_epochs  0/10 | inner iter:  23/ 32 | ppo epoch:  1/ 4 | global iter:     93/  5000| tot_loss: 2.5961 | rl_loss: 0.9794 | pt_loss: 1.6167 | pg_loss: 0.2192 | reg_loss: 0.7602 | reward: -0.2705 | rev_kl: 1.1224 | stu_lens: 124.0000 | mixed_lens: 86.5000 | lr: 4.5500e-06 | scale: 2048.00 | time: 26.320 | step time: 0.000
train | data_epochs  0/10 | inner iter:  25/ 32 | ppo epoch:  1/ 4 | global iter:     94/  5000| tot_loss: 2.9982 | rl_loss: 1.2961 | pt_loss: 1.7020 | pg_loss: 0.4110 | reg_loss: 0.8851 | reward: -3.8716 | rev_kl: 0.4669 | stu_lens: 69.0000 | mixed_lens: 66.0000 | lr: 4.6000e-06 | scale: 2048.00 | time: 26.281 | step time: 0.000
train | data_epochs  0/10 | inner iter:  27/ 32 | ppo epoch:  1/ 4 | global iter:     95/  5000| tot_loss: 2.6734 | rl_loss: 0.9734 | pt_loss: 1.6999 | pg_loss: 0.2866 | reg_loss: 0.6869 | reward: -0.4890 | rev_kl: 1.0904 | stu_lens: 65.5000 | mixed_lens: 92.5000 | lr: 4.6500e-06 | scale: 2048.00 | time: 26.316 | step time: 0.000
train | data_epochs  0/10 | inner iter:  29/ 32 | ppo epoch:  1/ 4 | global iter:     96/  5000| tot_loss: 2.8322 | rl_loss: 1.1251 | pt_loss: 1.7070 | pg_loss: 0.2214 | reg_loss: 0.9037 | reward: -0.7894 | rev_kl: 1.4159 | stu_lens: 128.0000 | mixed_lens: 96.5000 | lr: 4.7000e-06 | scale: 2048.00 | time: 26.274 | step time: 0.000
****************************************************************************************************
train | data_epochs  0/10 | inner iter:  29/ 32 | ppo epoch:  1/ 4 | global iter:     96/  5000| tot_loss: 3.0823 | rl_loss: 1.3553 | pt_loss: 1.7271 | pg_loss: 0.4622 | reg_loss: 0.8931 | reward: -0.7475 | rev_kl: 1.4369 | stu_lens: 84.1875 | mixed_lens: 84.4688 | lr: 4.7000e-06 | scale: 2048.00 | time: 26.274 | step time: 27.565
/dtu/p1/johlau/LMOps/minillm/results/llama/train/minillm_both/bs2-lr5e-06-G2-N1-NN1-lm1-len256/pe4_rs0.5_nr64_ln_sr_tm0.2
****************************************************************************************************
train | data_epochs  0/10 | inner iter:  31/ 32 | ppo epoch:  1/ 4 | global iter:     97/  5000| tot_loss: 3.4050 | rl_loss: 1.4659 | pt_loss: 1.9391 | pg_loss: 0.6334 | reg_loss: 0.8325 | reward: -0.6310 | rev_kl: 1.3430 | stu_lens: 62.5000 | mixed_lens: 67.0000 | lr: 4.7500e-06 | scale: 2048.00 | time: 26.305 | step time: 0.000
train | data_epochs  0/10 | inner iter:   1/ 32 | ppo epoch:  2/ 4 | global iter:     98/  5000| tot_loss: 2.4945 | rl_loss: 0.9333 | pt_loss: 1.5613 | pg_loss: 0.4547 | reg_loss: 0.4786 | reward: -0.1142 | rev_kl: 0.7166 | stu_lens: 53.0000 | mixed_lens: 69.5000 | lr: 4.8000e-06 | scale: 2048.00 | time: 26.262 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/ 32 | ppo epoch:  2/ 4 | global iter:     99/  5000| tot_loss: 2.5906 | rl_loss: 0.6005 | pt_loss: 1.9901 | pg_loss: -0.0056 | reg_loss: 0.6061 | reward: -0.2435 | rev_kl: 1.3766 | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.8500e-06 | scale: 2048.00 | time: 26.309 | step time: 0.000
                                 Evaluation #1                                  
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ prompts                               ┃ samples                              ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ Below is an instruction that          │ Below is an instruction that         │
│ describes a task. Write a response    │ describes a task. Write a response   │
│ that appropriately completes the      │ that appropriately completes the     │
│ request.                              │ request.                             │
│                                       │                                      │
│ ### Instruction:                      │ ### Instruction:                     │
│ That sounds boring. I want to create  │ That sounds boring. I want to create │
│ something new.                        │ something new.                       │
│                                       │                                      │
│ ### Response:                         │ ### Response:                        │
│                                       │ I understand. If you want to create  │
│                                       │ something new, you might be          │
│                                       │ interested in artificial             │
│                                       │ intelligence. Artificial             │
│                                       │ intelligence is a popular area of    │
│                                       │ research that focuses on creating    │
│                                       │ algorithms that can learn and make   │
│                                       │ decisions like humans. There are     │
│                                       │ many applications of AI, such as     │
│                                       │ self-driving cars, recommendations   │
│                                       │ systems, and machine translation.    │
├───────────────────────────────────────┼──────────────────────────────────────┤
│ Below is an instruction that          │ Below is an instruction that         │
│ describes a task. Write a response    │ describes a task. Write a response   │
│ that appropriately completes the      │ that appropriately completes the     │
│ request.                              │ request.                             │
│                                       │                                      │
│ ### Instruction:                      │ ### Instruction:                     │
│ That sounds boring. I want to create  │ That sounds boring. I want to create │
│ something new.                        │ something new.                       │
│                                       │                                      │
│ ### Response:                         │ ### Response:                        │
│                                       │ That's totally fine. Machine         │
│                                       │ learning is still a young field, and │
│                                       │ there is a lot of room for           │
│                                       │ innovation. There are also many      │
│                                       │ other areas within machine learning, │
│                                       │ such as computer vision, natural     │
│                                       │ language processing, and recommender │
│                                       │ systems. You can also apply machine  │
│                                       │ learning to other domains, such as   │
│                                       │ finance, transportation, sports, or  │
│                                       │ healthcare.                          │
├───────────────────────────────────────┼──────────────────────────────────────┤
│ Below is an instruction that          │ Below is an instruction that         │
│ describes a task. Write a response    │ describes a task. Write a response   │
│ that appropriately completes the      │ that appropriately completes the     │
│ request.                              │ request.                             │
│                                       │                                      │
│ ### Instruction:                      │ ### Instruction:                     │
│ That sounds boring. I want to create  │ That sounds boring. I want to create │
│ something new.                        │ something new.                       │
│                                       │                                      │
│ ### Response:                         │ ### Response:                        │
│                                       │ Follow your passion. But build on    │
│                                       │ something that already exists. It    │
│                                       │ will be a lot easier for you to find │
│                                       │ mentors and get started. Also, there │
│                                       │ is a higher chance of your idea      │
│                                       │ being successful if it is based on   │
│                                       │ an existing idea.                    │
└───────────────────────────────────────┴──────────────────────────────────────┘
eval | rougeL: 15.564 | exact_match: 0.000 | rev_kl: 1.133 | lens: 97.404 | pt_loss: 1.124 | lm_loss: 1.232 | kd_loss: 1.016 
train | data_epochs  0/10 | inner iter:   5/ 32 | ppo epoch:  2/ 4 | global iter:    100/  5000| tot_loss: 2.4226 | rl_loss: 1.2476 | pt_loss: 1.1750 | pg_loss: 0.5127 | reg_loss: 0.7349 | reward: -0.5354 | rev_kl: 1.7453 | stu_lens: 47.0000 | mixed_lens: 72.0000 | lr: 4.9000e-06 | scale: 2048.00 | time: 26.275 | step time: 0.000
train | data_epochs  0/10 | inner iter:   7/ 32 | ppo epoch:  2/ 4 | global iter:    101/  5000| tot_loss: 4.6540 | rl_loss: 3.1462 | pt_loss: 1.5077 | pg_loss: 2.4152 | reg_loss: 0.7311 | reward: -0.9528 | rev_kl: 3.5062 | stu_lens: 10.0000 | mixed_lens: 10.5000 | lr: 4.9500e-06 | scale: 2048.00 | time: 26.312 | step time: 0.000
train | data_epochs  0/10 | inner iter:   9/ 32 | ppo epoch:  2/ 4 | global iter:    102/  5000| tot_loss: 3.3315 | rl_loss: 1.7837 | pt_loss: 1.5479 | pg_loss: 0.9673 | reg_loss: 0.8164 | reward: -1.0633 | rev_kl: 1.6798 | stu_lens: 58.5000 | mixed_lens: 45.0000 | lr: 5.0000e-06 | scale: 2048.00 | time: 26.284 | step time: 0.000
train | data_epochs  0/10 | inner iter:  11/ 32 | ppo epoch:  2/ 4 | global iter:    103/  5000| tot_loss: 2.9839 | rl_loss: 1.1769 | pt_loss: 1.8071 | pg_loss: 0.5699 | reg_loss: 0.6070 | reward: -1.5270 | rev_kl: 1.5642 | stu_lens: 128.0000 | mixed_lens: 50.5000 | lr: 5.0000e-06 | scale: 2048.00 | time: 26.249 | step time: 0.000
train | data_epochs  0/10 | inner iter:  13/ 32 | ppo epoch:  2/ 4 | global iter:    104/  5000| tot_loss: 2.4495 | rl_loss: 0.8373 | pt_loss: 1.6122 | pg_loss: 0.1507 | reg_loss: 0.6865 | reward: -0.2965 | rev_kl: 1.6417 | stu_lens: 128.0000 | mixed_lens: 108.0000 | lr: 5.0000e-06 | scale: 2048.00 | time: 26.351 | step time: 0.000
train | data_epochs  0/10 | inner iter:  15/ 32 | ppo epoch:  2/ 4 | global iter:    105/  5000| tot_loss: 2.6390 | rl_loss: 0.6138 | pt_loss: 2.0252 | pg_loss: 0.0646 | reg_loss: 0.5492 | reward: -0.2280 | rev_kl: 2.9874 | stu_lens: 89.5000 | mixed_lens: 116.0000 | lr: 5.0000e-06 | scale: 2048.00 | time: 26.301 | step time: 0.000
train | data_epochs  0/10 | inner iter:  17/ 32 | ppo epoch:  2/ 4 | global iter:    106/  5000| tot_loss: 2.3691 | rl_loss: 0.9220 | pt_loss: 1.4471 | pg_loss: 0.2868 | reg_loss: 0.6351 | reward: -0.3789 | rev_kl: 1.2491 | stu_lens: 99.5000 | mixed_lens: 86.0000 | lr: 5.0000e-06 | scale: 2048.00 | time: 26.340 | step time: 0.000
train | data_epochs  0/10 | inner iter:  19/ 32 | ppo epoch:  2/ 4 | global iter:    107/  5000| tot_loss: 2.2949 | rl_loss: 0.6137 | pt_loss: 1.6812 | pg_loss: -0.0090 | reg_loss: 0.6227 | reward: -0.2820 | rev_kl: 1.4550 | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 5.0000e-06 | scale: 2048.00 | time: 26.276 | step time: 0.000
train | data_epochs  0/10 | inner iter:  21/ 32 | ppo epoch:  2/ 4 | global iter:    108/  5000| tot_loss: 2.9697 | rl_loss: 1.3104 | pt_loss: 1.6593 | pg_loss: 0.4850 | reg_loss: 0.8254 | reward: -0.8203 | rev_kl: 1.3767 | stu_lens: 75.5000 | mixed_lens: 84.0000 | lr: 5.0000e-06 | scale: 2048.00 | time: 26.335 | step time: 0.000
