Tue Dec 12 14:07:19 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA H100 PCIe               On  | 00000000:41:00.0 Off |                    0 |
| N/A   25C    P0              46W / 350W |      4MiB / 81559MiB |      0%   E. Process |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
python3 -m torch.distributed.run --nproc_per_node 1 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 3012 /dtu/p1/johlau/LMOps/minillm/train_minillm.py --base-path /dtu/p1/johlau/LMOps/minillm --model-path bigscience/bloom-560m --teacher-model-path bigscience/bloom-1b1 --ckpt-name bloom-560m --teacher-ckpt-name bloom-1b1 --n-gpu 1 --n-nodes 1 --model-type bloom --teacher-model-fp16 --gradient-checkpointing --prompt-data-dir /dtu/p1/johlau/LMOps/minillm/processed_data/dolly/prompt/bloom/ --lm-data-dir /dtu/p1/johlau/LMOps/minillm/processed_data/roberta/bloom/512/20M/ --dev-num 1000 --num-workers 0 --epochs 10 --total-iters 5000 --kd-ratio 0.5 --batch-size 8 --lr 5e-6 --lr-min 5e-6 --gradient-accumulation-steps 16 --max-length 256 --max-prompt-length 128 --warmup-iters 100 --scheduler-name cosine_trm --save /dtu/p1/johlau/LMOps/minillm/results/bloom/train/minillm/ --seed 10 --seed-ppo 42 --seed-lm 7 --save-interval 500 --eval-interval 100 --log-interval 16 --mid-log-num 1 --type minillm --ppo-epochs 4 --num-rollouts 32 --chunk-size 8 --length-norm --single-step-reg --teacher-mixed-alpha 0.2 --reward-scaling 0.5 --cliprange-reward 100 --do-sample --top-k 0 --top-p 1.0 --temperature 1.0 --deepspeed --deepspeed_config /dtu/p1/johlau/LMOps/minillm/configs/deepspeed/ds_config.json /dtu/p1/johlau/LMOps/minillm
PYTHONPATH=/dtu/p1/johlau/LMOps/minillm
[2023-12-12 14:07:30,640] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
using world size: 1
[2023-12-12 14:07:33,674] [INFO] [comm.py:637:init_distributed] cdb=None
[2023-12-12 14:07:33,675] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
arguments:
  model_path ................... bigscience/bloom-560m
  ckpt_name .................... bloom-560m
  model_type ................... bloom
  teacher_model_type ........... None
  n_gpu ........................ 1
  n_nodes ...................... 1
  teacher_model_path ........... bigscience/bloom-1b1
  teacher_ckpt_name ............ bloom-1b1
  teacher_model_fp16 ........... True
  model_parallel ............... False
  model_parallel_size .......... None
  no_value ..................... False
  dropout_path_rate ............ None
  fp32 ......................... False
  type ......................... minillm
  do_train ..................... False
  do_valid ..................... False
  do_eval ...................... False
  base_path .................... /dtu/p1/johlau/LMOps/minillm
  load ......................... None
  save ......................... /dtu/p1/johlau/LMOps/minillm/results/bloom/train/minillm/bs8-lr5e-06-G16-N1-NN1-lm1-len256/pe4_rs0.5_nr32_ln_sr_tm0.2
  log_interval ................. 16
  mid_log_num .................. 1
  save_interval ................ 500
  eval_interval ................ 100
  local_rank ................... 0
  save_additional_suffix ....... 
  save_rollout ................. False
  eb_sample_times .............. 3
  data_dir ..................... None
  processed_data_dir ........... None
  force_process ................ False
  force_process_demo ........... False
  data_process_workers ......... -1
  train_num .................... -1
  train_ratio .................. 1
  dev_num ...................... 1000
  dev_ratio .................... 1
  gen_num ...................... -1
  data_names ................... None
  prompt_type .................. None
  num_workers .................. 0
  max_prompt_length ............ 128
  min_prompt_length ............ 128
  json_data .................... False
  bin_data ..................... False
  txt_data ..................... False
  prompt_data_dir .............. /dtu/p1/johlau/LMOps/minillm/processed_data/dolly/prompt/bloom/
  lm_data_dir .................. /dtu/p1/johlau/LMOps/minillm/processed_data/roberta/bloom/512/20M/
  eval_ppl ..................... False
  eval_rw ...................... False
  eval_gen ..................... False
  only_prompt .................. False
  batch_size ................... 8
  eval_batch_size .............. 32
  clip_grad .................... 1.0
  total_iters .................. 5000
  train_iters_per_epoch ........ -1
  max_length ................... 256
  seed ......................... 10
  seed_order ................... 42
  seed_data .................... 42
  seed_ppo ..................... 42
  seed_lm ...................... 7
  epochs ....................... 10
  training_epochs .............. 10000
  gradient_accumulation_steps .. 16
  gradient_checkpointing ....... True
  attn_dtype ................... None
  lr ........................... 5e-06
  lr_min ....................... 5e-06
  weight_decay ................. 0.01
  loss_scale ................... 65536
  kd_ratio ..................... 0.5
  warmup_iters ................. 100
  lr_decay_iters ............... None
  lr_decay_style ............... noam
  scheduler_name ............... cosine_trm
  reward_scaling ............... 0.5
  cliprange_reward ............. 100.0
  ppo_epochs ................... 4
  num_rollouts ................. 32
  num_rollouts_per_device ...... 32
  cliprange .................... 0.2
  chunk_size ................... 8
  gamma ........................ 0.95
  length_norm .................. True
  single_step_reg .............. True
  teacher_mixed_alpha .......... 0.2
  lm_coef ...................... 1
  top_k ........................ 0
  top_p ........................ 1.0
  do_sample .................... True
  no_repeat_ngram_size ......... 6
  repetition_penalty ........... None
  num_beams .................... 1
  temperature .................. 1.0
  peft ......................... None
  peft_lora_r .................. 8
  peft_lora_alpha .............. 32
  peft_lora_dropout ............ 0.1
  peft_name .................... None
  peft_path .................... None
  teacher_peft_name ............ None
  teacher_peft_path ............ None
  deepspeed .................... True
  deepspeed_config ............. /dtu/p1/johlau/LMOps/minillm/configs/deepspeed/ds_config.json
  deepscale .................... False
  deepscale_config ............. None
  deepspeed_mpi ................ False
  rank ......................... 0
  world_size ................... 1
 > number of parameters: 1065314304
 > number of parameters: 559214592
Model load time: 3.26141619682312s
 > number of parameters: 559M
[2023-12-12 14:07:44,919] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.1, git-hash=unknown, git-branch=unknown
[2023-12-12 14:07:45,855] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-12-12 14:07:45,856] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-12-12 14:07:45,856] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2023-12-12 14:07:45,869] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2023-12-12 14:07:45,869] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2023-12-12 14:07:45,869] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 1 optimizer
[2023-12-12 14:07:45,869] [INFO] [stage_1_and_2.py:147:__init__] Reduce bucket size 500,000,000
[2023-12-12 14:07:45,869] [INFO] [stage_1_and_2.py:148:__init__] Allgather bucket size 500,000,000
[2023-12-12 14:07:45,869] [INFO] [stage_1_and_2.py:149:__init__] CPU Offload: False
[2023-12-12 14:07:45,869] [INFO] [stage_1_and_2.py:150:__init__] Round robin gradient partitioning: False
[2023-12-12 14:07:46,463] [INFO] [utils.py:802:see_memory_usage] Before initializing optimizer states
[2023-12-12 14:07:46,464] [INFO] [utils.py:803:see_memory_usage] MA 5.11 GB         Max_MA 6.15 GB         CA 6.2 GB         Max_CA 6 GB 
[2023-12-12 14:07:46,465] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 11.55 GB, percent = 1.5%
[2023-12-12 14:07:46,657] [INFO] [utils.py:802:see_memory_usage] After initializing optimizer states
[2023-12-12 14:07:46,658] [INFO] [utils.py:803:see_memory_usage] MA 9.28 GB         Max_MA 13.45 GB         CA 14.54 GB         Max_CA 15 GB 
[2023-12-12 14:07:46,658] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 11.55 GB, percent = 1.5%
[2023-12-12 14:07:46,658] [INFO] [stage_1_and_2.py:514:__init__] optimizer state initialized
[2023-12-12 14:07:46,746] [INFO] [utils.py:802:see_memory_usage] After initializing ZeRO optimizer
[2023-12-12 14:07:46,747] [INFO] [utils.py:803:see_memory_usage] MA 9.28 GB         Max_MA 9.28 GB         CA 14.54 GB         Max_CA 15 GB 
[2023-12-12 14:07:46,747] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 11.55 GB, percent = 1.5%
[2023-12-12 14:07:46,753] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = AdamW
[2023-12-12 14:07:46,753] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-12-12 14:07:46,754] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7f4bd0d4acd0>
[2023-12-12 14:07:46,754] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[[0.9, 0.95]]
[2023-12-12 14:07:46,754] [INFO] [config.py:972:print] DeepSpeedEngine configuration:
[2023-12-12 14:07:46,754] [INFO] [config.py:976:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-12-12 14:07:46,754] [INFO] [config.py:976:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-12-12 14:07:46,754] [INFO] [config.py:976:print]   amp_enabled .................. False
[2023-12-12 14:07:46,754] [INFO] [config.py:976:print]   amp_params ................... False
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   bfloat16_enabled ............. False
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   checkpoint_parallel_write_pipeline  False
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   checkpoint_tag_validation_enabled  True
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   checkpoint_tag_validation_fail  False
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f4bd00a1730>
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   communication_data_type ...... None
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   curriculum_enabled_legacy .... False
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   curriculum_params_legacy ..... False
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   data_efficiency_enabled ...... False
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   dataloader_drop_last ......... False
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   disable_allgather ............ False
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   dump_state ................... False
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   dynamic_loss_scale_args ...... {'init_scale': 2048, 'scale_window': 2000, 'delayed_shift': 4, 'consecutive_hysteresis': False, 'min_scale': 1}
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   eigenvalue_enabled ........... False
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   eigenvalue_gas_boundary_resolution  1
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   eigenvalue_layer_num ......... 0
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   eigenvalue_max_iter .......... 100
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   eigenvalue_stability ......... 1e-06
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   eigenvalue_tol ............... 0.01
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   eigenvalue_verbose ........... False
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   elasticity_enabled ........... False
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   fp16_auto_cast ............... False
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   fp16_enabled ................. True
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   fp16_master_weights_and_gradients  False
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   global_rank .................. 0
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   grad_accum_dtype ............. None
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   gradient_accumulation_steps .. 16
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   gradient_clipping ............ 1.0
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   gradient_predivide_factor .... 1.0
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   initial_dynamic_scale ........ 2048
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   load_universal_checkpoint .... False
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   loss_scale ................... 0
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   memory_breakdown ............. False
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   mics_hierarchial_params_gather  False
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   mics_shard_size .............. -1
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   optimizer_legacy_fusion ...... False
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   optimizer_name ............... None
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   optimizer_params ............. None
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-12-12 14:07:46,755] [INFO] [config.py:976:print]   pld_enabled .................. False
[2023-12-12 14:07:46,756] [INFO] [config.py:976:print]   pld_params ................... False
[2023-12-12 14:07:46,756] [INFO] [config.py:976:print]   prescale_gradients ........... False
[2023-12-12 14:07:46,756] [INFO] [config.py:976:print]   scheduler_name ............... None
[2023-12-12 14:07:46,756] [INFO] [config.py:976:print]   scheduler_params ............. None
[2023-12-12 14:07:46,756] [INFO] [config.py:976:print]   seq_parallel_communication_data_type  torch.float32
[2023-12-12 14:07:46,756] [INFO] [config.py:976:print]   sparse_attention ............. None
[2023-12-12 14:07:46,756] [INFO] [config.py:976:print]   sparse_gradients_enabled ..... False
[2023-12-12 14:07:46,756] [INFO] [config.py:976:print]   steps_per_print .............. 10000000
[2023-12-12 14:07:46,756] [INFO] [config.py:976:print]   train_batch_size ............. 128
[2023-12-12 14:07:46,756] [INFO] [config.py:976:print]   train_micro_batch_size_per_gpu  8
[2023-12-12 14:07:46,756] [INFO] [config.py:976:print]   use_node_local_storage ....... False
[2023-12-12 14:07:46,756] [INFO] [config.py:976:print]   wall_clock_breakdown ......... False
[2023-12-12 14:07:46,756] [INFO] [config.py:976:print]   weight_quantization_config ... None
[2023-12-12 14:07:46,756] [INFO] [config.py:976:print]   world_size ................... 1
[2023-12-12 14:07:46,756] [INFO] [config.py:976:print]   zero_allow_untested_optimizer  True
[2023-12-12 14:07:46,756] [INFO] [config.py:976:print]   zero_config .................. stage=1 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2023-12-12 14:07:46,756] [INFO] [config.py:976:print]   zero_enabled ................. True
[2023-12-12 14:07:46,756] [INFO] [config.py:976:print]   zero_force_ds_cpu_optimizer .. True
[2023-12-12 14:07:46,756] [INFO] [config.py:976:print]   zero_optimization_stage ...... 1
[2023-12-12 14:07:46,756] [INFO] [config.py:962:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 8, 
    "gradient_accumulation_steps": 16, 
    "zero_optimization": {
        "stage": 1
    }, 
    "zero_allow_untested_optimizer": true, 
    "fp16": {
        "enabled": true, 
        "loss_scale": 0, 
        "initial_scale_power": 11, 
        "loss_scale_window": 2.000000e+03, 
        "hysteresis": 4
    }, 
    "wall_clock_breakdown": false, 
    "gradient_clipping": 1.0, 
    "steps_per_print": 1.000000e+07
}
Probing Dataset
Probing end. Max data state 1, total length 14003
Num PPO instances: 14003
Probing Dataset
Probing end. Max data state 1, total length 989
Num PPO instances: 989
Probing Dataset
Probing end. Max data state 1, total length 2536398
Num LM instances: 2536398
Probing Dataset
Probing end. Max data state 1, total length 10000
Num LM instances: 10000
                                 Evaluation #0                                  
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ prompts                               ┃ samples                              ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ Debajo hay unaयस que describe una്മ.   │ Debajo hay unaयस que describe una്മ.  │
│ Escribe una respuesta que completeعية │ Escribe una respuesta que            │
│ la标准.                               │ completeعية la标准.                  │
│                                       │                                      │
│ Channel सकता:                         │ Channel सकता:                        │
│ dime un chiste acerca de la situacion │ dime un chiste acerca de la          │
│ actual de la economia, de modo que    │ situacion actual de la economia, de  │
│ los niños comprendan el mal estado de │ modo que los niños comprendan el mal │
│ la misma.                             │ estado de la misma.                  │
│                                       │                                      │
│ Channel Respuesta:                    │ Channel Respuesta:                   │
│                                       │ this is what things look like now,   │
│                                       │ the earnings are not enough. I think │
│                                       │ the government should give it extra  │
│                                       │ in a little while,                   │
│                                       │                                      │
│                                       │ channel People:                      │
│                                       │ What do you mean?                    │
│                                       │                                      │
│                                       │ channel People:                      │
│                                       │  Don't think so.                     │
│                                       │  I mean that school fees would be    │
│                                       │ not enough to pay it in the month.   │
│                                       │                                      │
│                                       │ channel People:                      │
│                                       │  We can give them extra up to junior │
│                                       │ high. But I don't think it's right.  │
│                                       │                                      │
│                                       │ channel People:                      │
│                                       │  You want us to get hostage?         │
│                                       │  We want to represent the sick,      │
│                                       │ weak, and needy.                     │
│                                       │                                      │
│                                       │ channel People:                      │
│                                       │  Is that what we're looking to       │
│                                       │ benefit the most from?               │
│                                       │  Can we do better?                   │
│                                       │                                      │
│                                       │                                      │
│                                       │ As for                               │
├───────────────────────────────────────┼──────────────────────────────────────┤
│ Debajo hay unaयस que describe una്മ.   │ Debajo hay unaयस que describe una്മ.  │
│ Escribe una respuesta que completeعية │ Escribe una respuesta que            │
│ la标准.                               │ completeعية la标准.                  │
│                                       │                                      │
│ Channel सकता:                         │ Channel सकता:                        │
│ Noiapkan laحِ de este chiste. ¿ Court  │ Noiapkan laحِ de este chiste. ¿ Court │
│ contar otro?                          │ contar otro?                         │
│                                       │                                      │
│ Channel Respuesta:                    │ Channel Respuesta:                   │
│                                       │ على تقصencia unऔरb conallis. रिस     │
│                                       │ نشره conastacionesfilters            │
│                                       │                                      │
│                                       │ AfterGame :                          │
│                                       │ @SconeraChakra: Welcome to a_com.    │
│                                       │ :)@monarchsei: Me cardila que as_mae │
│                                       │ 100,000 in_Dlanss a that game. De    │
│                                       │ 分_se online                         │
│                                       │         @SconeraChakra: Scone        │
│                                       │ rative! The_Score is %_valid value   │
│                                       │ and 5 in MEP is %_non_valid          │
│                                       │ value.自定义. Current                │
│                                       │ @monarchsei: info Vous recevez_M_en  │
│                                       │ un, eton a le_charnal pour COM!      │
├───────────────────────────────────────┼──────────────────────────────────────┤
│ Debajo hay unaयस que describe una്മ.   │ Debajo hay unaयस que describe una്മ.  │
│ Escribe una respuesta que completeعية │ Escribe una respuesta que            │
│ la标准.                               │ completeعية la标准.                  │
│                                       │                                      │
│ Channel सकता:                         │ Channel सकता:                        │
│ Noiapkan laحِ de este chiste. ¿ Court  │ Noiapkan laحِ de este chiste. ¿ Court │
│ contar otro?                          │ contar otro?                         │
│                                       │                                      │
│ Channel Respuesta:                    │ Channel Respuesta:                   │
│                                       │ Si                                   │
│                                       │                                      │
│                                       │ Cancaila seem: apparaideo un مجموعب  │
│                                       │ من مار, maybe it fail, or Sometimes, │
│                                       │ very many times, aTransfer de los    │
│                                       │ amigos, no Meet a gentleman, and in  │
│                                       │ thewhelming photos with some people. │
│                                       │ कि الرجل इले कमामा वाले المُصور En los  │
│                                       │ contactos SPOAM, unaprofileuse       │
│                                       │ unaobsolutme de avanzo en lasربides, │
│                                       │ فاروق, a Emmanuel de فترة टिप्पणी من  │
│                                       │ واتست/ او راغ کرکےست Denver ডि Ann   │
│                                       │ Beeleza撰写 ਹਾਲ در في لا'  espoirs   │
│                                       │ on تبلش ف وكسب الانلوال من إحدى      │
│                                       │ شركاتأرام، खासيص                     │
└───────────────────────────────────────┴──────────────────────────────────────┘
eval | rougeL: 5.333 | exact_match: 0.000 | rev_kl: inf | lens: 122.578 | pt_loss: 7.581 | lm_loss: 8.808 | kd_loss: 6.354 
Total Steps: 5000 Data Epochs: 10
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:      2/  5000| tot_loss: 8.3991 | rl_loss: 0.8803 | pt_loss: 7.5188 | pg_loss: 0.0575 | reg_loss: 0.8229 | reward: 0.0927 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 5.0000e-08 | scale: 2048.00 | time: 0.383 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:      3/  5000| tot_loss: 9.2694 | rl_loss: 0.9152 | pt_loss: 8.3542 | pg_loss: 0.0511 | reg_loss: 0.8641 | reward: 0.1052 | rev_kl: inf | stu_lens: 117.1250 | mixed_lens: 124.8750 | lr: 1.0000e-07 | scale: 2048.00 | time: 0.362 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:      4/  5000| tot_loss: 9.1612 | rl_loss: 0.9612 | pt_loss: 8.2000 | pg_loss: 0.0314 | reg_loss: 0.9298 | reward: 0.1637 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 111.3750 | lr: 1.5000e-07 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:      5/  5000| tot_loss: 8.6537 | rl_loss: 0.8747 | pt_loss: 7.7791 | pg_loss: 0.0624 | reg_loss: 0.8122 | reward: 0.2805 | rev_kl: inf | stu_lens: 123.7500 | mixed_lens: 128.0000 | lr: 2.0000e-07 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:      6/  5000| tot_loss: 8.3156 | rl_loss: 0.8958 | pt_loss: 7.4198 | pg_loss: 0.0763 | reg_loss: 0.8195 | reward: 0.0974 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 2.5000e-07 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:      7/  5000| tot_loss: 8.1691 | rl_loss: 0.8795 | pt_loss: 7.2896 | pg_loss: 0.0774 | reg_loss: 0.8022 | reward: 0.0058 | rev_kl: inf | stu_lens: 109.1250 | mixed_lens: 116.1250 | lr: 3.0000e-07 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:      8/  5000| tot_loss: 8.5452 | rl_loss: 1.0227 | pt_loss: 7.5225 | pg_loss: 0.0498 | reg_loss: 0.9730 | reward: -0.0718 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 3.5000e-07 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:      9/  5000| tot_loss: 7.8832 | rl_loss: 1.0315 | pt_loss: 6.8516 | pg_loss: 0.0595 | reg_loss: 0.9721 | reward: 0.0201 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.0000e-07 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     10/  5000| tot_loss: 8.7048 | rl_loss: 1.1360 | pt_loss: 7.5688 | pg_loss: 0.0760 | reg_loss: 1.0600 | reward: 0.1246 | rev_kl: inf | stu_lens: 103.1250 | mixed_lens: 128.0000 | lr: 4.5000e-07 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     11/  5000| tot_loss: 9.1006 | rl_loss: 1.0619 | pt_loss: 8.0388 | pg_loss: 0.0869 | reg_loss: 0.9749 | reward: 0.2362 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 5.0000e-07 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     12/  5000| tot_loss: 8.8845 | rl_loss: 1.1633 | pt_loss: 7.7212 | pg_loss: 0.1016 | reg_loss: 1.0617 | reward: 0.2959 | rev_kl: inf | stu_lens: 108.2500 | mixed_lens: 117.5000 | lr: 5.5000e-07 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     13/  5000| tot_loss: 8.3925 | rl_loss: 0.8755 | pt_loss: 7.5170 | pg_loss: 0.0349 | reg_loss: 0.8406 | reward: 0.0601 | rev_kl: inf | stu_lens: 114.6250 | mixed_lens: 128.0000 | lr: 6.0000e-07 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     14/  5000| tot_loss: 8.2166 | rl_loss: 1.0473 | pt_loss: 7.1692 | pg_loss: 0.0866 | reg_loss: 0.9608 | reward: 0.0858 | rev_kl: inf | stu_lens: 127.2500 | mixed_lens: 113.7500 | lr: 6.5000e-07 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     15/  5000| tot_loss: 8.1315 | rl_loss: 0.9393 | pt_loss: 7.1922 | pg_loss: 0.0684 | reg_loss: 0.8709 | reward: 0.1084 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 123.3750 | lr: 7.0000e-07 | scale: 2048.00 | time: 0.397 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     16/  5000| tot_loss: 7.8577 | rl_loss: 0.8298 | pt_loss: 7.0278 | pg_loss: 0.0364 | reg_loss: 0.7934 | reward: 0.0246 | rev_kl: inf | stu_lens: 116.1250 | mixed_lens: 121.1250 | lr: 7.5000e-07 | scale: 2048.00 | time: 0.395 | step time: 0.000
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     16/  5000| tot_loss: 8.0278 | rl_loss: 0.9105 | pt_loss: 7.1173 | pg_loss: 0.0638 | reg_loss: 0.8467 | reward: 0.1270 | rev_kl: inf | stu_lens: 114.4082 | mixed_lens: 112.3184 | lr: 7.5000e-07 | scale: 2048.00 | time: 0.395 | step time: 4.964
/dtu/p1/johlau/LMOps/minillm/results/bloom/train/minillm/bs8-lr5e-06-G16-N1-NN1-lm1-len256/pe4_rs0.5_nr32_ln_sr_tm0.2
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     17/  5000| tot_loss: 7.5172 | rl_loss: 0.7217 | pt_loss: 6.7955 | pg_loss: 0.0429 | reg_loss: 0.6789 | reward: 0.0283 | rev_kl: 1982773232746364928.0000 | stu_lens: 128.0000 | mixed_lens: 127.2500 | lr: 8.0000e-07 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     18/  5000| tot_loss: 7.9063 | rl_loss: 0.8644 | pt_loss: 7.0419 | pg_loss: 0.0781 | reg_loss: 0.7863 | reward: 0.1262 | rev_kl: inf | stu_lens: 118.7500 | mixed_lens: 128.0000 | lr: 8.5000e-07 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     19/  5000| tot_loss: 7.9747 | rl_loss: 0.9440 | pt_loss: 7.0307 | pg_loss: 0.0735 | reg_loss: 0.8705 | reward: 0.0501 | rev_kl: inf | stu_lens: 99.5000 | mixed_lens: 128.0000 | lr: 9.0000e-07 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     20/  5000| tot_loss: 7.5381 | rl_loss: 0.8476 | pt_loss: 6.6905 | pg_loss: 0.0511 | reg_loss: 0.7965 | reward: -0.0735 | rev_kl: inf | stu_lens: 122.7500 | mixed_lens: 128.0000 | lr: 9.5000e-07 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     21/  5000| tot_loss: 7.9177 | rl_loss: 0.8892 | pt_loss: 7.0285 | pg_loss: 0.0455 | reg_loss: 0.8437 | reward: -0.0495 | rev_kl: 0.8625 | stu_lens: 128.0000 | mixed_lens: 120.7500 | lr: 1.0000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     22/  5000| tot_loss: 7.6702 | rl_loss: 0.9181 | pt_loss: 6.7520 | pg_loss: 0.1266 | reg_loss: 0.7915 | reward: 0.0951 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 114.8750 | lr: 1.0500e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     23/  5000| tot_loss: 7.5405 | rl_loss: 0.9972 | pt_loss: 6.5433 | pg_loss: 0.1329 | reg_loss: 0.8643 | reward: -0.2081 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 116.6250 | lr: 1.1000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     24/  5000| tot_loss: 7.4559 | rl_loss: 0.8117 | pt_loss: 6.6442 | pg_loss: 0.0499 | reg_loss: 0.7618 | reward: -0.0880 | rev_kl: 470241560688913809408.0000 | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 1.1500e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     25/  5000| tot_loss: 7.6804 | rl_loss: 0.7636 | pt_loss: 6.9168 | pg_loss: 0.0426 | reg_loss: 0.7210 | reward: -0.0987 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 126.1250 | lr: 1.2000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     26/  5000| tot_loss: 7.9114 | rl_loss: 0.8067 | pt_loss: 7.1048 | pg_loss: 0.0499 | reg_loss: 0.7568 | reward: 0.0101 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 1.2500e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     27/  5000| tot_loss: 7.1843 | rl_loss: 0.7321 | pt_loss: 6.4522 | pg_loss: 0.0346 | reg_loss: 0.6974 | reward: 0.1038 | rev_kl: inf | stu_lens: 103.3750 | mixed_lens: 127.8750 | lr: 1.3000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     28/  5000| tot_loss: 7.5159 | rl_loss: 0.7803 | pt_loss: 6.7356 | pg_loss: 0.0684 | reg_loss: 0.7119 | reward: -0.0231 | rev_kl: inf | stu_lens: 118.0000 | mixed_lens: 123.2500 | lr: 1.3500e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     29/  5000| tot_loss: 7.3870 | rl_loss: 0.7663 | pt_loss: 6.6206 | pg_loss: 0.0451 | reg_loss: 0.7212 | reward: -0.0673 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 1.4000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     30/  5000| tot_loss: 7.2071 | rl_loss: 0.7072 | pt_loss: 6.4999 | pg_loss: 0.0426 | reg_loss: 0.6646 | reward: 0.0001 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 124.6250 | lr: 1.4500e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     31/  5000| tot_loss: 7.3240 | rl_loss: 0.7596 | pt_loss: 6.5644 | pg_loss: 0.0665 | reg_loss: 0.6931 | reward: 0.0355 | rev_kl: inf | stu_lens: 70.3750 | mixed_lens: 108.6250 | lr: 1.5000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     32/  5000| tot_loss: 7.4880 | rl_loss: 0.6553 | pt_loss: 6.8327 | pg_loss: 0.0283 | reg_loss: 0.6270 | reward: 0.0797 | rev_kl: 749184995763195503601254400.0000 | stu_lens: 128.0000 | mixed_lens: 120.2500 | lr: 1.5500e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     32/  5000| tot_loss: 7.7177 | rl_loss: 0.8251 | pt_loss: 6.8926 | pg_loss: 0.0670 | reg_loss: 0.7581 | reward: 0.0159 | rev_kl: inf | stu_lens: 119.9844 | mixed_lens: 122.1367 | lr: 1.5500e-06 | scale: 2048.00 | time: 0.396 | step time: 5.356
/dtu/p1/johlau/LMOps/minillm/results/bloom/train/minillm/bs8-lr5e-06-G16-N1-NN1-lm1-len256/pe4_rs0.5_nr32_ln_sr_tm0.2
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     33/  5000| tot_loss: 7.3093 | rl_loss: 0.6979 | pt_loss: 6.6114 | pg_loss: 0.0370 | reg_loss: 0.6609 | reward: -0.0798 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 1.6000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     34/  5000| tot_loss: 7.2584 | rl_loss: 0.5908 | pt_loss: 6.6676 | pg_loss: 0.0345 | reg_loss: 0.5563 | reward: -0.0200 | rev_kl: inf | stu_lens: 112.6250 | mixed_lens: 118.3750 | lr: 1.6500e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     35/  5000| tot_loss: 6.9584 | rl_loss: 0.6436 | pt_loss: 6.3148 | pg_loss: 0.0299 | reg_loss: 0.6137 | reward: 0.1998 | rev_kl: inf | stu_lens: 120.1250 | mixed_lens: 119.0000 | lr: 1.7000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     36/  5000| tot_loss: 7.3339 | rl_loss: 0.6502 | pt_loss: 6.6837 | pg_loss: 0.0336 | reg_loss: 0.6166 | reward: 0.1735 | rev_kl: inf | stu_lens: 114.1250 | mixed_lens: 119.6250 | lr: 1.7500e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     37/  5000| tot_loss: 6.9446 | rl_loss: 0.5866 | pt_loss: 6.3579 | pg_loss: 0.0317 | reg_loss: 0.5549 | reward: 0.1740 | rev_kl: inf | stu_lens: 116.3750 | mixed_lens: 122.1250 | lr: 1.8000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     38/  5000| tot_loss: 7.5767 | rl_loss: 0.7079 | pt_loss: 6.8689 | pg_loss: 0.1021 | reg_loss: 0.6058 | reward: -0.0006 | rev_kl: 31760396529259587813489046827565056.0000 | stu_lens: 117.1250 | mixed_lens: 115.0000 | lr: 1.8500e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     39/  5000| tot_loss: 7.1140 | rl_loss: 0.7616 | pt_loss: 6.3525 | pg_loss: 0.0714 | reg_loss: 0.6902 | reward: 0.0339 | rev_kl: inf | stu_lens: 119.7500 | mixed_lens: 124.0000 | lr: 1.9000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     40/  5000| tot_loss: 7.1960 | rl_loss: 0.7763 | pt_loss: 6.4198 | pg_loss: 0.0684 | reg_loss: 0.7078 | reward: 0.1050 | rev_kl: inf | stu_lens: 110.5000 | mixed_lens: 126.3750 | lr: 1.9500e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     41/  5000| tot_loss: 7.1474 | rl_loss: 0.7305 | pt_loss: 6.4169 | pg_loss: 0.0862 | reg_loss: 0.6443 | reward: 0.1085 | rev_kl: 1231484259351759472101792472367104.0000 | stu_lens: 114.8750 | mixed_lens: 109.2500 | lr: 2.0000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     42/  5000| tot_loss: 7.3306 | rl_loss: 0.7486 | pt_loss: 6.5820 | pg_loss: 0.0977 | reg_loss: 0.6509 | reward: -0.0679 | rev_kl: 1056923000504320.0000 | stu_lens: 100.2500 | mixed_lens: 115.8750 | lr: 2.0500e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     43/  5000| tot_loss: 7.3985 | rl_loss: 0.6881 | pt_loss: 6.7104 | pg_loss: 0.0391 | reg_loss: 0.6490 | reward: 0.1017 | rev_kl: inf | stu_lens: 113.7500 | mixed_lens: 104.1250 | lr: 2.1000e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     44/  5000| tot_loss: 6.6497 | rl_loss: 0.7161 | pt_loss: 5.9336 | pg_loss: 0.0656 | reg_loss: 0.6505 | reward: 0.0541 | rev_kl: 1757710848.0000 | stu_lens: 113.6250 | mixed_lens: 128.0000 | lr: 2.1500e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     45/  5000| tot_loss: 6.8472 | rl_loss: 0.7197 | pt_loss: 6.1275 | pg_loss: 0.0426 | reg_loss: 0.6771 | reward: -0.1592 | rev_kl: inf | stu_lens: 117.1250 | mixed_lens: 107.0000 | lr: 2.2000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     46/  5000| tot_loss: 6.6215 | rl_loss: 0.7564 | pt_loss: 5.8651 | pg_loss: 0.0931 | reg_loss: 0.6633 | reward: 0.0008 | rev_kl: inf | stu_lens: 109.3750 | mixed_lens: 118.8750 | lr: 2.2500e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     47/  5000| tot_loss: 7.2858 | rl_loss: 0.6557 | pt_loss: 6.6301 | pg_loss: 0.0936 | reg_loss: 0.5621 | reward: 0.0441 | rev_kl: 39585995492490881731785201287168.0000 | stu_lens: 108.1250 | mixed_lens: 112.6250 | lr: 2.3000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     48/  5000| tot_loss: 6.7691 | rl_loss: 0.7395 | pt_loss: 6.0297 | pg_loss: 0.0607 | reg_loss: 0.6787 | reward: -0.0560 | rev_kl: 1813506688.0000 | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 2.3500e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     48/  5000| tot_loss: 7.0492 | rl_loss: 0.7059 | pt_loss: 6.3434 | pg_loss: 0.0664 | reg_loss: 0.6395 | reward: 0.0288 | rev_kl: inf | stu_lens: 112.1777 | mixed_lens: 113.1562 | lr: 2.3500e-06 | scale: 2048.00 | time: 0.396 | step time: 5.353
/dtu/p1/johlau/LMOps/minillm/results/bloom/train/minillm/bs8-lr5e-06-G16-N1-NN1-lm1-len256/pe4_rs0.5_nr32_ln_sr_tm0.2
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     49/  5000| tot_loss: 6.9246 | rl_loss: 0.6313 | pt_loss: 6.2933 | pg_loss: 0.0514 | reg_loss: 0.5799 | reward: -0.0541 | rev_kl: inf | stu_lens: 109.8750 | mixed_lens: 125.3750 | lr: 2.4000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     50/  5000| tot_loss: 6.5480 | rl_loss: 0.6546 | pt_loss: 5.8933 | pg_loss: 0.0381 | reg_loss: 0.6165 | reward: 0.0762 | rev_kl: 3302.0554 | stu_lens: 123.7500 | mixed_lens: 125.8750 | lr: 2.4500e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     51/  5000| tot_loss: 6.2981 | rl_loss: 0.5761 | pt_loss: 5.7220 | pg_loss: 0.0620 | reg_loss: 0.5141 | reward: 0.1018 | rev_kl: 637.9532 | stu_lens: 128.0000 | mixed_lens: 114.2500 | lr: 2.5000e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     52/  5000| tot_loss: 6.8780 | rl_loss: 0.6798 | pt_loss: 6.1983 | pg_loss: 0.0579 | reg_loss: 0.6218 | reward: 0.0194 | rev_kl: 135336239104.0000 | stu_lens: 113.3750 | mixed_lens: 118.3750 | lr: 2.5500e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     53/  5000| tot_loss: 6.7314 | rl_loss: 0.6597 | pt_loss: 6.0718 | pg_loss: 0.0841 | reg_loss: 0.5756 | reward: -0.0215 | rev_kl: inf | stu_lens: 122.0000 | mixed_lens: 113.7500 | lr: 2.6000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     54/  5000| tot_loss: 6.4418 | rl_loss: 0.6733 | pt_loss: 5.7685 | pg_loss: 0.0669 | reg_loss: 0.6064 | reward: 0.0570 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 110.8750 | lr: 2.6500e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     55/  5000| tot_loss: 6.7145 | rl_loss: 0.5808 | pt_loss: 6.1337 | pg_loss: 0.0537 | reg_loss: 0.5271 | reward: 0.0047 | rev_kl: 870241856.0000 | stu_lens: 113.3750 | mixed_lens: 126.2500 | lr: 2.7000e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     56/  5000| tot_loss: 6.3602 | rl_loss: 0.6533 | pt_loss: 5.7069 | pg_loss: 0.1118 | reg_loss: 0.5415 | reward: -0.0772 | rev_kl: 69685061437201763591520256.0000 | stu_lens: 128.0000 | mixed_lens: 114.8750 | lr: 2.7500e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     57/  5000| tot_loss: 5.9994 | rl_loss: 0.5766 | pt_loss: 5.4228 | pg_loss: 0.0872 | reg_loss: 0.4893 | reward: 0.0287 | rev_kl: 1297.3486 | stu_lens: 116.8750 | mixed_lens: 108.7500 | lr: 2.8000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     58/  5000| tot_loss: 6.3604 | rl_loss: 0.5291 | pt_loss: 5.8313 | pg_loss: 0.0667 | reg_loss: 0.4623 | reward: 0.0000 | rev_kl: 9685.8418 | stu_lens: 117.7500 | mixed_lens: 111.2500 | lr: 2.8500e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     59/  5000| tot_loss: 6.4130 | rl_loss: 0.5694 | pt_loss: 5.8437 | pg_loss: 0.0568 | reg_loss: 0.5125 | reward: 0.0281 | rev_kl: inf | stu_lens: 97.5000 | mixed_lens: 119.7500 | lr: 2.9000e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     60/  5000| tot_loss: 6.3885 | rl_loss: 0.5373 | pt_loss: 5.8512 | pg_loss: 0.0664 | reg_loss: 0.4709 | reward: 0.1543 | rev_kl: 10765210624.0000 | stu_lens: 116.3750 | mixed_lens: 122.6250 | lr: 2.9500e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     61/  5000| tot_loss: 6.4174 | rl_loss: 0.6944 | pt_loss: 5.7230 | pg_loss: 0.0930 | reg_loss: 0.6015 | reward: 0.0865 | rev_kl: inf | stu_lens: 110.8750 | mixed_lens: 116.8750 | lr: 3.0000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     62/  5000| tot_loss: 6.4820 | rl_loss: 0.5873 | pt_loss: 5.8947 | pg_loss: 0.0438 | reg_loss: 0.5435 | reward: 0.3655 | rev_kl: 1844236160.0000 | stu_lens: 105.0000 | mixed_lens: 95.6250 | lr: 3.0500e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     63/  5000| tot_loss: 6.4926 | rl_loss: 0.6061 | pt_loss: 5.8866 | pg_loss: 0.0794 | reg_loss: 0.5267 | reward: 0.0667 | rev_kl: inf | stu_lens: 120.1250 | mixed_lens: 103.7500 | lr: 3.1000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     64/  5000| tot_loss: 6.5685 | rl_loss: 0.6443 | pt_loss: 5.9242 | pg_loss: 0.0724 | reg_loss: 0.5719 | reward: 0.1978 | rev_kl: 1.8879 | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 3.1500e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     64/  5000| tot_loss: 6.4202 | rl_loss: 0.6174 | pt_loss: 5.8029 | pg_loss: 0.0685 | reg_loss: 0.5489 | reward: 0.0345 | rev_kl: inf | stu_lens: 116.1855 | mixed_lens: 116.4648 | lr: 3.1500e-06 | scale: 2048.00 | time: 0.395 | step time: 5.351
/dtu/p1/johlau/LMOps/minillm/results/bloom/train/minillm/bs8-lr5e-06-G16-N1-NN1-lm1-len256/pe4_rs0.5_nr32_ln_sr_tm0.2
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     65/  5000| tot_loss: 6.0534 | rl_loss: 0.5949 | pt_loss: 5.4585 | pg_loss: 0.0297 | reg_loss: 0.5653 | reward: -0.0071 | rev_kl: 10448254533632.0000 | stu_lens: 128.0000 | mixed_lens: 127.6250 | lr: 3.2000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     66/  5000| tot_loss: 6.1852 | rl_loss: 0.5259 | pt_loss: 5.6593 | pg_loss: 0.0695 | reg_loss: 0.4564 | reward: 0.0821 | rev_kl: inf | stu_lens: 118.8750 | mixed_lens: 116.1250 | lr: 3.2500e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     67/  5000| tot_loss: 6.3854 | rl_loss: 0.5394 | pt_loss: 5.8460 | pg_loss: 0.0569 | reg_loss: 0.4825 | reward: 0.1443 | rev_kl: inf | stu_lens: 113.3750 | mixed_lens: 124.2500 | lr: 3.3000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     68/  5000| tot_loss: 6.3372 | rl_loss: 0.4668 | pt_loss: 5.8704 | pg_loss: 0.0281 | reg_loss: 0.4387 | reward: 0.0046 | rev_kl: inf | stu_lens: 100.3750 | mixed_lens: 103.0000 | lr: 3.3500e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     69/  5000| tot_loss: 6.3700 | rl_loss: 0.6282 | pt_loss: 5.7418 | pg_loss: 0.0600 | reg_loss: 0.5682 | reward: 0.0593 | rev_kl: 749184995763195503601254400.0000 | stu_lens: 128.0000 | mixed_lens: 115.1250 | lr: 3.4000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     70/  5000| tot_loss: 6.3257 | rl_loss: 0.5611 | pt_loss: 5.7646 | pg_loss: 0.0569 | reg_loss: 0.5042 | reward: 0.1530 | rev_kl: 342485964613730312278616571904.0000 | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 3.4500e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     71/  5000| tot_loss: 5.9965 | rl_loss: 0.4812 | pt_loss: 5.5153 | pg_loss: 0.0950 | reg_loss: 0.3861 | reward: 0.4651 | rev_kl: 1976812902741767031357440.0000 | stu_lens: 128.0000 | mixed_lens: 104.0000 | lr: 3.5000e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     72/  5000| tot_loss: 6.2483 | rl_loss: 0.5754 | pt_loss: 5.6729 | pg_loss: 0.0793 | reg_loss: 0.4961 | reward: 0.0202 | rev_kl: inf | stu_lens: 114.2500 | mixed_lens: 122.6250 | lr: 3.5500e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     73/  5000| tot_loss: 6.1634 | rl_loss: 0.5086 | pt_loss: 5.6547 | pg_loss: 0.0363 | reg_loss: 0.4723 | reward: -0.0238 | rev_kl: 9404805772694878069638979125248.0000 | stu_lens: 127.8750 | mixed_lens: 116.3750 | lr: 3.6000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     74/  5000| tot_loss: 6.2383 | rl_loss: 0.5247 | pt_loss: 5.7136 | pg_loss: 0.0505 | reg_loss: 0.4742 | reward: -0.0046 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 120.3750 | lr: 3.6500e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     75/  5000| tot_loss: 6.0793 | rl_loss: 0.4972 | pt_loss: 5.5820 | pg_loss: 0.0441 | reg_loss: 0.4532 | reward: -0.0024 | rev_kl: 50982742336036984565268480.0000 | stu_lens: 105.7500 | mixed_lens: 128.0000 | lr: 3.7000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     76/  5000| tot_loss: 5.9663 | rl_loss: 0.5825 | pt_loss: 5.3838 | pg_loss: 0.0513 | reg_loss: 0.5312 | reward: 0.0291 | rev_kl: inf | stu_lens: 123.5000 | mixed_lens: 128.0000 | lr: 3.7500e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     77/  5000| tot_loss: 5.9899 | rl_loss: 0.4900 | pt_loss: 5.4999 | pg_loss: 0.0364 | reg_loss: 0.4536 | reward: 0.0221 | rev_kl: 1808057885523968.0000 | stu_lens: 128.0000 | mixed_lens: 123.3750 | lr: 3.8000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     78/  5000| tot_loss: 6.0770 | rl_loss: 0.5472 | pt_loss: 5.5298 | pg_loss: 0.0470 | reg_loss: 0.5002 | reward: 0.0085 | rev_kl: inf | stu_lens: 115.6250 | mixed_lens: 124.8750 | lr: 3.8500e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     79/  5000| tot_loss: 5.9788 | rl_loss: 0.4962 | pt_loss: 5.4827 | pg_loss: 0.0836 | reg_loss: 0.4125 | reward: -0.0235 | rev_kl: 4240565151997119238392293653217280.0000 | stu_lens: 108.3750 | mixed_lens: 110.7500 | lr: 3.9000e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     80/  5000| tot_loss: 6.3131 | rl_loss: 0.5221 | pt_loss: 5.7910 | pg_loss: 0.1502 | reg_loss: 0.3719 | reward: 0.0083 | rev_kl: inf | stu_lens: 105.2500 | mixed_lens: 105.2500 | lr: 3.9500e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     80/  5000| tot_loss: 6.1815 | rl_loss: 0.5411 | pt_loss: 5.6404 | pg_loss: 0.0620 | reg_loss: 0.4792 | reward: 0.0573 | rev_kl: inf | stu_lens: 120.2441 | mixed_lens: 118.0352 | lr: 3.9500e-06 | scale: 2048.00 | time: 0.396 | step time: 5.348
/dtu/p1/johlau/LMOps/minillm/results/bloom/train/minillm/bs8-lr5e-06-G16-N1-NN1-lm1-len256/pe4_rs0.5_nr32_ln_sr_tm0.2
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     81/  5000| tot_loss: 6.2108 | rl_loss: 0.5065 | pt_loss: 5.7042 | pg_loss: 0.0361 | reg_loss: 0.4704 | reward: -0.0215 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.0000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     82/  5000| tot_loss: 6.0809 | rl_loss: 0.4640 | pt_loss: 5.6169 | pg_loss: 0.0495 | reg_loss: 0.4145 | reward: 0.1277 | rev_kl: 179291389952.0000 | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.0500e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     83/  5000| tot_loss: 5.8604 | rl_loss: 0.4706 | pt_loss: 5.3898 | pg_loss: 0.0506 | reg_loss: 0.4200 | reward: 0.0461 | rev_kl: inf | stu_lens: 124.3750 | mixed_lens: 128.0000 | lr: 4.1000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     84/  5000| tot_loss: 6.5217 | rl_loss: 0.5286 | pt_loss: 5.9931 | pg_loss: 0.0698 | reg_loss: 0.4589 | reward: 0.0021 | rev_kl: 6717740094062592.0000 | stu_lens: 103.8750 | mixed_lens: 116.7500 | lr: 4.1500e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     85/  5000| tot_loss: 6.2639 | rl_loss: 0.4586 | pt_loss: 5.8053 | pg_loss: 0.0320 | reg_loss: 0.4266 | reward: 0.1047 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 121.6250 | lr: 4.2000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     86/  5000| tot_loss: 5.9596 | rl_loss: 0.5211 | pt_loss: 5.4385 | pg_loss: 0.0639 | reg_loss: 0.4572 | reward: -0.0325 | rev_kl: 337735.0000 | stu_lens: 128.0000 | mixed_lens: 122.8750 | lr: 4.2500e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     87/  5000| tot_loss: 6.1921 | rl_loss: 0.4552 | pt_loss: 5.7369 | pg_loss: 0.0593 | reg_loss: 0.3959 | reward: 0.0972 | rev_kl: 162266694172393523380224.0000 | stu_lens: 124.1250 | mixed_lens: 128.0000 | lr: 4.3000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     88/  5000| tot_loss: 6.2090 | rl_loss: 0.4237 | pt_loss: 5.7853 | pg_loss: 0.0332 | reg_loss: 0.3904 | reward: 0.1622 | rev_kl: inf | stu_lens: 106.5000 | mixed_lens: 111.6250 | lr: 4.3500e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     89/  5000| tot_loss: 5.8494 | rl_loss: 0.4643 | pt_loss: 5.3851 | pg_loss: 0.0536 | reg_loss: 0.4107 | reward: -0.0534 | rev_kl: 72222589501571072.0000 | stu_lens: 128.0000 | mixed_lens: 113.6250 | lr: 4.4000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     90/  5000| tot_loss: 6.2844 | rl_loss: 0.5493 | pt_loss: 5.7350 | pg_loss: 0.0743 | reg_loss: 0.4750 | reward: -0.0112 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.4500e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     91/  5000| tot_loss: 5.9305 | rl_loss: 0.5336 | pt_loss: 5.3970 | pg_loss: 0.0872 | reg_loss: 0.4463 | reward: -0.1247 | rev_kl: inf | stu_lens: 127.1250 | mixed_lens: 93.5000 | lr: 4.5000e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     92/  5000| tot_loss: 6.3092 | rl_loss: 0.4858 | pt_loss: 5.8235 | pg_loss: 0.0556 | reg_loss: 0.4302 | reward: 0.0610 | rev_kl: 7610255833824608911360.0000 | stu_lens: 107.3750 | mixed_lens: 120.0000 | lr: 4.5500e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     93/  5000| tot_loss: 6.1387 | rl_loss: 0.6595 | pt_loss: 5.4792 | pg_loss: 0.0789 | reg_loss: 0.5807 | reward: 0.0130 | rev_kl: 625968021504.0000 | stu_lens: 118.2500 | mixed_lens: 112.7500 | lr: 4.6000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     94/  5000| tot_loss: 6.0094 | rl_loss: 0.5517 | pt_loss: 5.4576 | pg_loss: 0.0635 | reg_loss: 0.4883 | reward: 0.0087 | rev_kl: 1066839488.0000 | stu_lens: 113.6250 | mixed_lens: 108.7500 | lr: 4.6500e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     95/  5000| tot_loss: 6.0958 | rl_loss: 0.5377 | pt_loss: 5.5582 | pg_loss: 0.0627 | reg_loss: 0.4749 | reward: 0.0844 | rev_kl: 98865172709376.0000 | stu_lens: 115.7500 | mixed_lens: 112.0000 | lr: 4.7000e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     96/  5000| tot_loss: 5.8273 | rl_loss: 0.5017 | pt_loss: 5.3257 | pg_loss: 0.1043 | reg_loss: 0.3974 | reward: -0.0493 | rev_kl: inf | stu_lens: 119.7500 | mixed_lens: 106.5000 | lr: 4.7500e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     96/  5000| tot_loss: 6.0800 | rl_loss: 0.5158 | pt_loss: 5.5642 | pg_loss: 0.0606 | reg_loss: 0.4552 | reward: 0.0800 | rev_kl: inf | stu_lens: 118.8438 | mixed_lens: 117.4316 | lr: 4.7500e-06 | scale: 2048.00 | time: 0.395 | step time: 5.349
/dtu/p1/johlau/LMOps/minillm/results/bloom/train/minillm/bs8-lr5e-06-G16-N1-NN1-lm1-len256/pe4_rs0.5_nr32_ln_sr_tm0.2
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     97/  5000| tot_loss: 6.2582 | rl_loss: 0.4643 | pt_loss: 5.7939 | pg_loss: 0.0857 | reg_loss: 0.3786 | reward: 0.1980 | rev_kl: 13319660484426349936640.0000 | stu_lens: 106.8750 | mixed_lens: 104.7500 | lr: 4.8000e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     98/  5000| tot_loss: 5.8947 | rl_loss: 0.6130 | pt_loss: 5.2817 | pg_loss: 0.0586 | reg_loss: 0.5544 | reward: 0.0565 | rev_kl: 6664609276787892881284759797366784.0000 | stu_lens: 125.2500 | mixed_lens: 128.0000 | lr: 4.8500e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:     99/  5000| tot_loss: 6.1517 | rl_loss: 0.4678 | pt_loss: 5.6839 | pg_loss: 0.0453 | reg_loss: 0.4225 | reward: 0.0037 | rev_kl: 104452324182659849409464893440.0000 | stu_lens: 126.6250 | mixed_lens: 119.2500 | lr: 4.9000e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
                                 Evaluation #1                                  
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ prompts                               ┃ samples                              ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ Debajo hay unaयस que describe una്മ.   │ Debajo hay unaयस que describe una്മ.  │
│ Escribe una respuesta que completeعية │ Escribe una respuesta que            │
│ la标准.                               │ completeعية la标准.                  │
│                                       │                                      │
│ Channel सकता:                         │ Channel सकता:                        │
│ dime un chiste acerca de la situacion │ dime un chiste acerca de la          │
│ actual de la economia, de modo que    │ situacion actual de la economia, de  │
│ los niños comprendan el mal estado de │ modo que los niños comprendan el mal │
│ la misma.                             │ estado de la misma.                  │
│                                       │                                      │
│ Channel Respuesta:                    │ Channel Respuesta:                   │
│                                       │ que en el presente, en esta          │
│                                       │ difficultia, tengamos que atender a  │
│                                       │ algunos puntos principales.          │
│                                       │ Este sabe como por nosotros felices. │
│                                       │                                      │
│                                       │ Channel Enquete:                     │
│                                       │ de seguro que tu hijo sabe de sus    │
│                                       │ dificultades sociales, y de los      │
│                                       │ errores que sufren.                  │
│                                       │ Y gracias por tus consejos!          │
│                                       │                                      │
│                                       │ Channel Respuesta:                   │
│                                       │ simplemente, répondan.               │
│                                       │                                      │
│                                       │ Channel Enquete2 en el diario:       │
│                                       │ Estafa es una palabra que me sigue   │
│                                       │ siendo muy enfática. Perdonen mi     │
│                                       │ franqueza, claro, pero debo decirme  │
│                                       │ por qué me da la impresión de que    │
│                                       │ mis palabras no son exactas.         │
│                                       │                                      │
│                                       │ Channel Tiraje:                      │
│                                       │ soy quien siempre espere que te      │
├───────────────────────────────────────┼──────────────────────────────────────┤
│ Debajo hay unaयस que describe una്മ.   │ Debajo hay unaयस que describe una്മ.  │
│ Escribe una respuesta que completeعية │ Escribe una respuesta que            │
│ la标准.                               │ completeعية la标准.                  │
│                                       │                                      │
│ Channel सकता:                         │ Channel सकता:                        │
│ Noiapkan laحِ de este chiste. ¿ Court  │ Noiapkan laحِ de este chiste. ¿ Court │
│ contar otro?                          │ contar otro?                         │
│                                       │                                      │
│ Channel Respuesta:                    │ Channel Respuesta:                   │
│                                       │ No नातेव pagar en este momento el     │
│                                       │ punto vital de la bảo de cambio. If  │
│                                       │                                      │
│                                       │          También puede escribirse    │
│                                       │ voy a una casa talentos devoradas.   │
│                                       │ Si. Luego llega un sur hijo de عندما │
│                                       │ me rotum bolo que la abolition es la │
│                                       │ luna verde. Te pueden pedir una      │
│                                       │ causa del reconocimiento, pero no te │
│                                       │ pueden decir que hay un lugar donde  │
│                                       │ sea muy seguro estarían apasionados  │
│                                       │ por esta idea Poole y sus amigos     │
│                                       │ habían llegado con la cách de hacer  │
│                                       │ un lugar en donde ellos ordinaban    │
│                                       │ red en la comunidad, puramente por   │
│                                       │ la barra del esto noillader.         │
│                                       │  Muat fo Tar Muta puede tener se     │
│                                       │ pueden emergente por si              │
├───────────────────────────────────────┼──────────────────────────────────────┤
│ Debajo hay unaयस que describe una്മ.   │ Debajo hay unaयस que describe una്മ.  │
│ Escribe una respuesta que completeعية │ Escribe una respuesta que            │
│ la标准.                               │ completeعية la标准.                  │
│                                       │                                      │
│ Channel सकता:                         │ Channel सकता:                        │
│ Noiapkan laحِ de este chiste. ¿ Court  │ Noiapkan laحِ de este chiste. ¿ Court │
│ contar otro?                          │ contar otro?                         │
│                                       │                                      │
│ Channel Respuesta:                    │ Channel Respuesta:                   │
│                                       │ El chiste está rectificado porque se │
│                                       │ decidió hacerlo así. Cuando se       │
│                                       │ redifunde un chiste para nuevos      │
│                                       │ miembros (¿ extrañaría alguien que   │
│                                       │ tuviera merecido el pito ?) lo hago  │
│                                       │ así, como resto de la sociedad se    │
│                                       │ hace. Si algo había en el programa   │
│                                       │ antes de que se reiniciasse lo       │
│                                       │ ponemos así. El responsable del      │
│                                       │ chiste es el Escándalo. Si he tenido │
│                                       │ el devoción para este programa de un │
│                                       │ tiempo a este se lo digo en el       │
│                                       │ periódico. Era tuve el devoción como │
│                                       │ aquella ya tenía 15 años. También el │
│                                       │ encargado de ajustar la lista estaba │
│                                       │ ineducado.                           │
│                                       │ Ajusto los pitos                     │
└───────────────────────────────────────┴──────────────────────────────────────┘
eval | rougeL: 10.329 | exact_match: 0.000 | rev_kl: inf | lens: 121.950 | pt_loss: 5.516 | lm_loss: 5.464 | kd_loss: 5.569 
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    100/  5000| tot_loss: 5.9716 | rl_loss: 0.4987 | pt_loss: 5.4730 | pg_loss: 0.0512 | reg_loss: 0.4474 | reward: 0.1642 | rev_kl: 173271882802397184.0000 | stu_lens: 128.0000 | mixed_lens: 115.2500 | lr: 4.9500e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    101/  5000| tot_loss: 5.8728 | rl_loss: 0.5651 | pt_loss: 5.3078 | pg_loss: 0.1542 | reg_loss: 0.4109 | reward: -0.1125 | rev_kl: inf | stu_lens: 122.2500 | mixed_lens: 102.1250 | lr: 5.0000e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    102/  5000| tot_loss: 5.8095 | rl_loss: 0.4347 | pt_loss: 5.3749 | pg_loss: 0.0450 | reg_loss: 0.3897 | reward: -0.0560 | rev_kl: 123123060797763471049490432.0000 | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 5.0000e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    103/  5000| tot_loss: 6.1439 | rl_loss: 0.4730 | pt_loss: 5.6709 | pg_loss: 0.0529 | reg_loss: 0.4200 | reward: 0.1176 | rev_kl: inf | stu_lens: 117.0000 | mixed_lens: 128.0000 | lr: 5.0000e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    104/  5000| tot_loss: 5.7160 | rl_loss: 0.5148 | pt_loss: 5.2013 | pg_loss: 0.0625 | reg_loss: 0.4523 | reward: 0.0203 | rev_kl: inf | stu_lens: 121.8750 | mixed_lens: 120.0000 | lr: 5.0000e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    105/  5000| tot_loss: 5.9635 | rl_loss: 0.4479 | pt_loss: 5.5156 | pg_loss: 0.0476 | reg_loss: 0.4003 | reward: 0.0338 | rev_kl: 114891247371730767914729472.0000 | stu_lens: 128.0000 | mixed_lens: 127.7500 | lr: 5.0000e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    106/  5000| tot_loss: 5.8721 | rl_loss: 0.5475 | pt_loss: 5.3246 | pg_loss: 0.0624 | reg_loss: 0.4851 | reward: 0.1003 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 104.0000 | lr: 5.0000e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    107/  5000| tot_loss: 5.9691 | rl_loss: 0.4384 | pt_loss: 5.5307 | pg_loss: 0.0206 | reg_loss: 0.4178 | reward: 0.2556 | rev_kl: inf | stu_lens: 125.5000 | mixed_lens: 106.0000 | lr: 5.0000e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    108/  5000| tot_loss: 5.8960 | rl_loss: 0.5139 | pt_loss: 5.3821 | pg_loss: 0.0853 | reg_loss: 0.4286 | reward: -0.0778 | rev_kl: 88001430421504.0000 | stu_lens: 122.0000 | mixed_lens: 116.6250 | lr: 5.0000e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    109/  5000| tot_loss: 6.3453 | rl_loss: 0.5390 | pt_loss: 5.8063 | pg_loss: 0.0324 | reg_loss: 0.5067 | reward: -0.0652 | rev_kl: inf | stu_lens: 112.1250 | mixed_lens: 128.0000 | lr: 5.0000e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    110/  5000| tot_loss: 6.2930 | rl_loss: 0.4891 | pt_loss: 5.8039 | pg_loss: 0.0594 | reg_loss: 0.4296 | reward: 0.0349 | rev_kl: 108377694834153264000758687203328.0000 | stu_lens: 124.2500 | mixed_lens: 119.1250 | lr: 5.0000e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    111/  5000| tot_loss: 6.1140 | rl_loss: 0.4808 | pt_loss: 5.6333 | pg_loss: 0.0601 | reg_loss: 0.4207 | reward: -0.0074 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 117.5000 | lr: 4.9999e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    112/  5000| tot_loss: 6.2547 | rl_loss: 0.5306 | pt_loss: 5.7241 | pg_loss: 0.0681 | reg_loss: 0.4626 | reward: -0.0679 | rev_kl: 90415620717415497728.0000 | stu_lens: 110.7500 | mixed_lens: 122.1250 | lr: 4.9999e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    112/  5000| tot_loss: 5.9914 | rl_loss: 0.5122 | pt_loss: 5.4792 | pg_loss: 0.0569 | reg_loss: 0.4553 | reward: 0.0275 | rev_kl: inf | stu_lens: 120.8047 | mixed_lens: 119.2227 | lr: 4.9999e-06 | scale: 2048.00 | time: 0.396 | step time: 5.341
/dtu/p1/johlau/LMOps/minillm/results/bloom/train/minillm/bs8-lr5e-06-G16-N1-NN1-lm1-len256/pe4_rs0.5_nr32_ln_sr_tm0.2
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    113/  5000| tot_loss: 6.3352 | rl_loss: 0.5595 | pt_loss: 5.7757 | pg_loss: 0.0666 | reg_loss: 0.4929 | reward: -0.0011 | rev_kl: 2954177091334266321054717303586816.0000 | stu_lens: 118.2500 | mixed_lens: 125.7500 | lr: 4.9999e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    114/  5000| tot_loss: 6.0488 | rl_loss: 0.5064 | pt_loss: 5.5424 | pg_loss: 0.0543 | reg_loss: 0.4521 | reward: 0.1605 | rev_kl: 46211103340565217413878204929671168.0000 | stu_lens: 126.1250 | mixed_lens: 128.0000 | lr: 4.9999e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    115/  5000| tot_loss: 5.8046 | rl_loss: 0.5835 | pt_loss: 5.2211 | pg_loss: 0.0561 | reg_loss: 0.5275 | reward: -0.0553 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 104.0000 | lr: 4.9999e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    116/  5000| tot_loss: 5.9874 | rl_loss: 0.5454 | pt_loss: 5.4420 | pg_loss: 0.0536 | reg_loss: 0.4918 | reward: 0.1261 | rev_kl: 670734592.0000 | stu_lens: 128.0000 | mixed_lens: 115.8750 | lr: 4.9999e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    117/  5000| tot_loss: 5.9829 | rl_loss: 0.5105 | pt_loss: 5.4724 | pg_loss: 0.0577 | reg_loss: 0.4528 | reward: 0.0226 | rev_kl: 12437550150319154916644078802173952.0000 | stu_lens: 120.1250 | mixed_lens: 128.0000 | lr: 4.9999e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    118/  5000| tot_loss: 5.7047 | rl_loss: 0.4994 | pt_loss: 5.2053 | pg_loss: 0.0400 | reg_loss: 0.4594 | reward: 0.0141 | rev_kl: inf | stu_lens: 113.5000 | mixed_lens: 128.0000 | lr: 4.9999e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    119/  5000| tot_loss: 6.0663 | rl_loss: 0.4614 | pt_loss: 5.6049 | pg_loss: 0.0428 | reg_loss: 0.4186 | reward: -0.0506 | rev_kl: inf | stu_lens: 124.7500 | mixed_lens: 112.3750 | lr: 4.9998e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    120/  5000| tot_loss: 5.7123 | rl_loss: 0.5176 | pt_loss: 5.1947 | pg_loss: 0.0516 | reg_loss: 0.4660 | reward: -0.0460 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 125.1250 | lr: 4.9998e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    121/  5000| tot_loss: 5.9280 | rl_loss: 0.4994 | pt_loss: 5.4286 | pg_loss: 0.0628 | reg_loss: 0.4366 | reward: 0.0476 | rev_kl: 20764137472.0000 | stu_lens: 125.2500 | mixed_lens: 128.0000 | lr: 4.9998e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    122/  5000| tot_loss: 5.9100 | rl_loss: 0.4981 | pt_loss: 5.4119 | pg_loss: 0.0506 | reg_loss: 0.4475 | reward: -0.0250 | rev_kl: 13742478683642215268352.0000 | stu_lens: 113.1250 | mixed_lens: 128.0000 | lr: 4.9998e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    123/  5000| tot_loss: 6.0494 | rl_loss: 0.4812 | pt_loss: 5.5682 | pg_loss: 0.0493 | reg_loss: 0.4320 | reward: 0.0166 | rev_kl: inf | stu_lens: 125.2500 | mixed_lens: 125.6250 | lr: 4.9998e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    124/  5000| tot_loss: 6.0010 | rl_loss: 0.5686 | pt_loss: 5.4324 | pg_loss: 0.0567 | reg_loss: 0.5119 | reward: -0.0721 | rev_kl: 2866.1763 | stu_lens: 119.6250 | mixed_lens: 115.3750 | lr: 4.9997e-06 | scale: 2048.00 | time: 0.394 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    125/  5000| tot_loss: 5.8959 | rl_loss: 0.4560 | pt_loss: 5.4399 | pg_loss: 0.0579 | reg_loss: 0.3981 | reward: 0.0250 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 115.8750 | lr: 4.9997e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    126/  5000| tot_loss: 5.9725 | rl_loss: 0.4466 | pt_loss: 5.5259 | pg_loss: 0.0632 | reg_loss: 0.3833 | reward: -0.0432 | rev_kl: 5913564938240.0000 | stu_lens: 97.2500 | mixed_lens: 114.0000 | lr: 4.9997e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    127/  5000| tot_loss: 6.2644 | rl_loss: 0.4864 | pt_loss: 5.7780 | pg_loss: 0.0385 | reg_loss: 0.4479 | reward: -0.1018 | rev_kl: 11170583.0000 | stu_lens: 128.0000 | mixed_lens: 110.7500 | lr: 4.9997e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    128/  5000| tot_loss: 5.9971 | rl_loss: 0.4703 | pt_loss: 5.5269 | pg_loss: 0.0281 | reg_loss: 0.4421 | reward: 0.0137 | rev_kl: 103.4654 | stu_lens: 100.8750 | mixed_lens: 119.1250 | lr: 4.9996e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    128/  5000| tot_loss: 5.9507 | rl_loss: 0.5031 | pt_loss: 5.4476 | pg_loss: 0.0582 | reg_loss: 0.4448 | reward: -0.0004 | rev_kl: inf | stu_lens: 118.6133 | mixed_lens: 118.6875 | lr: 4.9996e-06 | scale: 2048.00 | time: 0.395 | step time: 5.348
/dtu/p1/johlau/LMOps/minillm/results/bloom/train/minillm/bs8-lr5e-06-G16-N1-NN1-lm1-len256/pe4_rs0.5_nr32_ln_sr_tm0.2
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    129/  5000| tot_loss: 6.1354 | rl_loss: 0.5071 | pt_loss: 5.6283 | pg_loss: 0.0876 | reg_loss: 0.4195 | reward: -0.0364 | rev_kl: inf | stu_lens: 126.8750 | mixed_lens: 107.8750 | lr: 4.9996e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    130/  5000| tot_loss: 5.9669 | rl_loss: 0.4473 | pt_loss: 5.5195 | pg_loss: 0.0639 | reg_loss: 0.3834 | reward: -0.0349 | rev_kl: inf | stu_lens: 118.2500 | mixed_lens: 114.8750 | lr: 4.9996e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    131/  5000| tot_loss: 5.6096 | rl_loss: 0.5747 | pt_loss: 5.0349 | pg_loss: 0.1245 | reg_loss: 0.4502 | reward: -0.0475 | rev_kl: 20200.3906 | stu_lens: 119.2500 | mixed_lens: 102.3750 | lr: 4.9995e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    132/  5000| tot_loss: 6.2096 | rl_loss: 0.4606 | pt_loss: 5.7490 | pg_loss: 0.0481 | reg_loss: 0.4125 | reward: -0.0470 | rev_kl: inf | stu_lens: 115.0000 | mixed_lens: 117.0000 | lr: 4.9995e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    133/  5000| tot_loss: 5.9781 | rl_loss: 0.4722 | pt_loss: 5.5059 | pg_loss: 0.0525 | reg_loss: 0.4197 | reward: -0.0197 | rev_kl: inf | stu_lens: 89.3750 | mixed_lens: 128.0000 | lr: 4.9995e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    134/  5000| tot_loss: 5.9754 | rl_loss: 0.4850 | pt_loss: 5.4904 | pg_loss: 0.0655 | reg_loss: 0.4196 | reward: -0.0209 | rev_kl: 8573968726413232241970774016.0000 | stu_lens: 121.7500 | mixed_lens: 119.5000 | lr: 4.9994e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    135/  5000| tot_loss: 5.7647 | rl_loss: 0.5141 | pt_loss: 5.2505 | pg_loss: 0.1034 | reg_loss: 0.4107 | reward: -0.0634 | rev_kl: inf | stu_lens: 125.2500 | mixed_lens: 114.8750 | lr: 4.9994e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    136/  5000| tot_loss: 5.8235 | rl_loss: 0.4950 | pt_loss: 5.3286 | pg_loss: 0.1058 | reg_loss: 0.3892 | reward: 0.0226 | rev_kl: inf | stu_lens: 117.2500 | mixed_lens: 105.0000 | lr: 4.9994e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    137/  5000| tot_loss: 6.2250 | rl_loss: 0.5018 | pt_loss: 5.7232 | pg_loss: 0.0724 | reg_loss: 0.4294 | reward: 0.0337 | rev_kl: 4555793235968.0000 | stu_lens: 128.0000 | mixed_lens: 117.0000 | lr: 4.9993e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    138/  5000| tot_loss: 6.2157 | rl_loss: 0.5396 | pt_loss: 5.6761 | pg_loss: 0.0632 | reg_loss: 0.4764 | reward: 0.0117 | rev_kl: inf | stu_lens: 114.8750 | mixed_lens: 118.5000 | lr: 4.9993e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    139/  5000| tot_loss: 5.8714 | rl_loss: 0.5057 | pt_loss: 5.3657 | pg_loss: 0.0660 | reg_loss: 0.4397 | reward: 0.1445 | rev_kl: 491.5970 | stu_lens: 118.8750 | mixed_lens: 124.6250 | lr: 4.9993e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    140/  5000| tot_loss: 6.1305 | rl_loss: 0.4795 | pt_loss: 5.6510 | pg_loss: 0.0761 | reg_loss: 0.4033 | reward: -0.0654 | rev_kl: inf | stu_lens: 106.7500 | mixed_lens: 104.6250 | lr: 4.9992e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    141/  5000| tot_loss: 6.0122 | rl_loss: 0.4794 | pt_loss: 5.5328 | pg_loss: 0.0544 | reg_loss: 0.4250 | reward: 0.0990 | rev_kl: inf | stu_lens: 117.7500 | mixed_lens: 128.0000 | lr: 4.9992e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    142/  5000| tot_loss: 6.0327 | rl_loss: 0.5563 | pt_loss: 5.4764 | pg_loss: 0.0547 | reg_loss: 0.5015 | reward: 0.0305 | rev_kl: 81347551147043268626160287744.0000 | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.9991e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    143/  5000| tot_loss: 6.1726 | rl_loss: 0.5615 | pt_loss: 5.6111 | pg_loss: 0.0742 | reg_loss: 0.4873 | reward: 0.1503 | rev_kl: inf | stu_lens: 121.6250 | mixed_lens: 117.2500 | lr: 4.9991e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    144/  5000| tot_loss: 6.0368 | rl_loss: 0.5403 | pt_loss: 5.4965 | pg_loss: 0.0658 | reg_loss: 0.4744 | reward: 0.0393 | rev_kl: 23525804998656.0000 | stu_lens: 105.7500 | mixed_lens: 114.0000 | lr: 4.9990e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    144/  5000| tot_loss: 5.9045 | rl_loss: 0.5013 | pt_loss: 5.4032 | pg_loss: 0.0558 | reg_loss: 0.4456 | reward: 0.0199 | rev_kl: inf | stu_lens: 120.1289 | mixed_lens: 120.4590 | lr: 4.9990e-06 | scale: 2048.00 | time: 0.395 | step time: 5.341
/dtu/p1/johlau/LMOps/minillm/results/bloom/train/minillm/bs8-lr5e-06-G16-N1-NN1-lm1-len256/pe4_rs0.5_nr32_ln_sr_tm0.2
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    145/  5000| tot_loss: 5.8338 | rl_loss: 0.4534 | pt_loss: 5.3804 | pg_loss: 0.0620 | reg_loss: 0.3914 | reward: 0.0867 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 117.6250 | lr: 4.9990e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    146/  5000| tot_loss: 5.6026 | rl_loss: 0.5322 | pt_loss: 5.0704 | pg_loss: 0.0950 | reg_loss: 0.4372 | reward: -0.0641 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 108.2500 | lr: 4.9990e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    147/  5000| tot_loss: 6.1556 | rl_loss: 0.4837 | pt_loss: 5.6719 | pg_loss: 0.0602 | reg_loss: 0.4235 | reward: -0.0514 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 121.2500 | lr: 4.9989e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    148/  5000| tot_loss: 5.8062 | rl_loss: 0.5124 | pt_loss: 5.2939 | pg_loss: 0.0552 | reg_loss: 0.4571 | reward: -0.0032 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.9989e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    149/  5000| tot_loss: 5.9622 | rl_loss: 0.4826 | pt_loss: 5.4796 | pg_loss: 0.0762 | reg_loss: 0.4064 | reward: -0.0651 | rev_kl: 115245751069992550400.0000 | stu_lens: 126.1250 | mixed_lens: 115.7500 | lr: 4.9988e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    150/  5000| tot_loss: 5.7445 | rl_loss: 0.4423 | pt_loss: 5.3022 | pg_loss: 0.0587 | reg_loss: 0.3835 | reward: 0.0378 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.9988e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    151/  5000| tot_loss: 5.9156 | rl_loss: 0.4477 | pt_loss: 5.4679 | pg_loss: 0.0453 | reg_loss: 0.4024 | reward: 0.0583 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.9987e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    152/  5000| tot_loss: 5.8464 | rl_loss: 0.5154 | pt_loss: 5.3310 | pg_loss: 0.1245 | reg_loss: 0.3910 | reward: 0.0585 | rev_kl: inf | stu_lens: 125.7500 | mixed_lens: 104.7500 | lr: 4.9987e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    153/  5000| tot_loss: 5.4555 | rl_loss: 0.5559 | pt_loss: 4.8996 | pg_loss: 0.0464 | reg_loss: 0.5095 | reward: 0.1686 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 122.8750 | lr: 4.9986e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    154/  5000| tot_loss: 5.8760 | rl_loss: 0.5826 | pt_loss: 5.2934 | pg_loss: 0.0383 | reg_loss: 0.5443 | reward: -0.0001 | rev_kl: inf | stu_lens: 101.0000 | mixed_lens: 118.1250 | lr: 4.9986e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    155/  5000| tot_loss: 6.1432 | rl_loss: 0.4887 | pt_loss: 5.6545 | pg_loss: 0.0587 | reg_loss: 0.4300 | reward: -0.0362 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 122.8750 | lr: 4.9985e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    156/  5000| tot_loss: 5.7015 | rl_loss: 0.5216 | pt_loss: 5.1799 | pg_loss: 0.0578 | reg_loss: 0.4638 | reward: 0.0687 | rev_kl: inf | stu_lens: 126.5000 | mixed_lens: 128.0000 | lr: 4.9984e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    157/  5000| tot_loss: 5.8527 | rl_loss: 0.4879 | pt_loss: 5.3649 | pg_loss: 0.0459 | reg_loss: 0.4420 | reward: -0.1046 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.9984e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    158/  5000| tot_loss: 5.8395 | rl_loss: 0.4878 | pt_loss: 5.3517 | pg_loss: 0.0385 | reg_loss: 0.4492 | reward: 0.1063 | rev_kl: 300952.4062 | stu_lens: 128.0000 | mixed_lens: 115.2500 | lr: 4.9983e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    159/  5000| tot_loss: 5.7955 | rl_loss: 0.5193 | pt_loss: 5.2762 | pg_loss: 0.0386 | reg_loss: 0.4807 | reward: -0.0094 | rev_kl: 495785120.0000 | stu_lens: 101.5000 | mixed_lens: 121.1250 | lr: 4.9983e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    160/  5000| tot_loss: 5.9468 | rl_loss: 0.5785 | pt_loss: 5.3683 | pg_loss: 0.0636 | reg_loss: 0.5149 | reward: -0.0801 | rev_kl: inf | stu_lens: 126.8750 | mixed_lens: 118.2500 | lr: 4.9982e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    160/  5000| tot_loss: 5.8747 | rl_loss: 0.5013 | pt_loss: 5.3734 | pg_loss: 0.0593 | reg_loss: 0.4420 | reward: 0.0072 | rev_kl: inf | stu_lens: 122.7227 | mixed_lens: 121.0078 | lr: 4.9982e-06 | scale: 2048.00 | time: 0.396 | step time: 5.333
/dtu/p1/johlau/LMOps/minillm/results/bloom/train/minillm/bs8-lr5e-06-G16-N1-NN1-lm1-len256/pe4_rs0.5_nr32_ln_sr_tm0.2
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    161/  5000| tot_loss: 5.6044 | rl_loss: 0.4797 | pt_loss: 5.1247 | pg_loss: 0.0533 | reg_loss: 0.4264 | reward: 0.0105 | rev_kl: inf | stu_lens: 115.1250 | mixed_lens: 128.0000 | lr: 4.9982e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    162/  5000| tot_loss: 6.1686 | rl_loss: 0.5500 | pt_loss: 5.6186 | pg_loss: 0.0463 | reg_loss: 0.5037 | reward: -0.0378 | rev_kl: 252081337228328960.0000 | stu_lens: 97.5000 | mixed_lens: 122.0000 | lr: 4.9981e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    163/  5000| tot_loss: 6.1587 | rl_loss: 0.5521 | pt_loss: 5.6066 | pg_loss: 0.1138 | reg_loss: 0.4383 | reward: 0.0049 | rev_kl: inf | stu_lens: 118.0000 | mixed_lens: 95.1250 | lr: 4.9980e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    164/  5000| tot_loss: 6.0460 | rl_loss: 0.4162 | pt_loss: 5.6298 | pg_loss: 0.0323 | reg_loss: 0.3840 | reward: 0.1613 | rev_kl: 39885059175481344.0000 | stu_lens: 119.8750 | mixed_lens: 109.0000 | lr: 4.9980e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    165/  5000| tot_loss: 5.9749 | rl_loss: 0.5138 | pt_loss: 5.4611 | pg_loss: 0.0757 | reg_loss: 0.4381 | reward: 0.1219 | rev_kl: 194152256.0000 | stu_lens: 113.2500 | mixed_lens: 117.1250 | lr: 4.9979e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    166/  5000| tot_loss: 5.6084 | rl_loss: 0.5425 | pt_loss: 5.0659 | pg_loss: 0.0709 | reg_loss: 0.4717 | reward: -0.0735 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 115.0000 | lr: 4.9978e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    167/  5000| tot_loss: 5.5823 | rl_loss: 0.4283 | pt_loss: 5.1540 | pg_loss: 0.0518 | reg_loss: 0.3765 | reward: -0.0514 | rev_kl: 67.2358 | stu_lens: 112.3750 | mixed_lens: 109.5000 | lr: 4.9978e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    168/  5000| tot_loss: 5.8620 | rl_loss: 0.4944 | pt_loss: 5.3676 | pg_loss: 0.0769 | reg_loss: 0.4175 | reward: 0.0032 | rev_kl: inf | stu_lens: 115.0000 | mixed_lens: 116.0000 | lr: 4.9977e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    169/  5000| tot_loss: 5.4302 | rl_loss: 0.4954 | pt_loss: 4.9348 | pg_loss: 0.0462 | reg_loss: 0.4492 | reward: 0.0044 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 121.2500 | lr: 4.9976e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    170/  5000| tot_loss: 5.8812 | rl_loss: 0.4487 | pt_loss: 5.4326 | pg_loss: 0.0603 | reg_loss: 0.3884 | reward: -0.0739 | rev_kl: inf | stu_lens: 118.8750 | mixed_lens: 106.0000 | lr: 4.9976e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    171/  5000| tot_loss: 6.1057 | rl_loss: 0.4334 | pt_loss: 5.6723 | pg_loss: 0.0521 | reg_loss: 0.3813 | reward: -0.0505 | rev_kl: 19.2945 | stu_lens: 115.0000 | mixed_lens: 122.0000 | lr: 4.9975e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    172/  5000| tot_loss: 5.6093 | rl_loss: 0.4582 | pt_loss: 5.1510 | pg_loss: 0.0511 | reg_loss: 0.4071 | reward: -0.0580 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.9974e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    173/  5000| tot_loss: 6.0224 | rl_loss: 0.5422 | pt_loss: 5.4801 | pg_loss: 0.0560 | reg_loss: 0.4862 | reward: 0.0260 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.9973e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    174/  5000| tot_loss: 5.9487 | rl_loss: 0.5396 | pt_loss: 5.4091 | pg_loss: 0.0511 | reg_loss: 0.4885 | reward: 0.0122 | rev_kl: 207885278336327457203101368320.0000 | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.9973e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    175/  5000| tot_loss: 5.8496 | rl_loss: 0.4526 | pt_loss: 5.3971 | pg_loss: 0.0540 | reg_loss: 0.3986 | reward: 0.0325 | rev_kl: 18151090875316531738106134528.0000 | stu_lens: 124.8750 | mixed_lens: 128.0000 | lr: 4.9972e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    176/  5000| tot_loss: 5.7708 | rl_loss: 0.5542 | pt_loss: 5.2166 | pg_loss: 0.0725 | reg_loss: 0.4817 | reward: -0.0582 | rev_kl: 0.4772 | stu_lens: 112.3750 | mixed_lens: 114.5000 | lr: 4.9971e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    176/  5000| tot_loss: 5.8427 | rl_loss: 0.5088 | pt_loss: 5.3339 | pg_loss: 0.0605 | reg_loss: 0.4484 | reward: -0.0117 | rev_kl: inf | stu_lens: 121.6758 | mixed_lens: 118.1816 | lr: 4.9971e-06 | scale: 2048.00 | time: 0.396 | step time: 5.332
/dtu/p1/johlau/LMOps/minillm/results/bloom/train/minillm/bs8-lr5e-06-G16-N1-NN1-lm1-len256/pe4_rs0.5_nr32_ln_sr_tm0.2
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    177/  5000| tot_loss: 5.3904 | rl_loss: 0.4591 | pt_loss: 4.9312 | pg_loss: 0.0375 | reg_loss: 0.4217 | reward: -0.0440 | rev_kl: inf | stu_lens: 120.5000 | mixed_lens: 120.7500 | lr: 4.9970e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    178/  5000| tot_loss: 5.7801 | rl_loss: 0.4392 | pt_loss: 5.3409 | pg_loss: 0.0652 | reg_loss: 0.3740 | reward: 0.2452 | rev_kl: 7905678458880.0000 | stu_lens: 113.7500 | mixed_lens: 101.8750 | lr: 4.9970e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    179/  5000| tot_loss: 5.8353 | rl_loss: 0.4591 | pt_loss: 5.3762 | pg_loss: 0.0591 | reg_loss: 0.4001 | reward: -0.0087 | rev_kl: 1490.1055 | stu_lens: 106.3750 | mixed_lens: 128.0000 | lr: 4.9969e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    180/  5000| tot_loss: 5.7184 | rl_loss: 0.4804 | pt_loss: 5.2380 | pg_loss: 0.0518 | reg_loss: 0.4286 | reward: -0.0728 | rev_kl: 202248373345582055424.0000 | stu_lens: 116.0000 | mixed_lens: 128.0000 | lr: 4.9968e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    181/  5000| tot_loss: 5.7473 | rl_loss: 0.5778 | pt_loss: 5.1696 | pg_loss: 0.0650 | reg_loss: 0.5128 | reward: 0.0977 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.9967e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    182/  5000| tot_loss: 5.9034 | rl_loss: 0.4588 | pt_loss: 5.4446 | pg_loss: 0.0466 | reg_loss: 0.4122 | reward: -0.0794 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.9966e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    183/  5000| tot_loss: 6.0435 | rl_loss: 0.5652 | pt_loss: 5.4783 | pg_loss: 0.0669 | reg_loss: 0.4983 | reward: 0.0704 | rev_kl: 14045191168.0000 | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.9965e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    184/  5000| tot_loss: 5.7029 | rl_loss: 0.4651 | pt_loss: 5.2378 | pg_loss: 0.0480 | reg_loss: 0.4171 | reward: -0.0565 | rev_kl: 2398892851200.0000 | stu_lens: 116.5000 | mixed_lens: 128.0000 | lr: 4.9965e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    185/  5000| tot_loss: 5.8768 | rl_loss: 0.6135 | pt_loss: 5.2633 | pg_loss: 0.1057 | reg_loss: 0.5078 | reward: -0.0895 | rev_kl: 5145.9302 | stu_lens: 123.5000 | mixed_lens: 103.8750 | lr: 4.9964e-06 | scale: 2048.00 | time: 0.394 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    186/  5000| tot_loss: 5.4608 | rl_loss: 0.4694 | pt_loss: 4.9915 | pg_loss: 0.1123 | reg_loss: 0.3570 | reward: 0.0344 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 106.3750 | lr: 4.9963e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    187/  5000| tot_loss: 5.7828 | rl_loss: 0.4555 | pt_loss: 5.3274 | pg_loss: 0.0600 | reg_loss: 0.3955 | reward: -0.0299 | rev_kl: inf | stu_lens: 123.2500 | mixed_lens: 128.0000 | lr: 4.9962e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    188/  5000| tot_loss: 5.8285 | rl_loss: 0.5552 | pt_loss: 5.2733 | pg_loss: 0.0841 | reg_loss: 0.4711 | reward: -0.0363 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 117.7500 | lr: 4.9961e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    189/  5000| tot_loss: 5.6851 | rl_loss: 0.4514 | pt_loss: 5.2337 | pg_loss: 0.0449 | reg_loss: 0.4066 | reward: 0.0275 | rev_kl: inf | stu_lens: 123.2500 | mixed_lens: 117.2500 | lr: 4.9960e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    190/  5000| tot_loss: 5.3364 | rl_loss: 0.4794 | pt_loss: 4.8570 | pg_loss: 0.0491 | reg_loss: 0.4303 | reward: -0.0093 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.9959e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    191/  5000| tot_loss: 5.6571 | rl_loss: 0.5234 | pt_loss: 5.1337 | pg_loss: 0.0711 | reg_loss: 0.4523 | reward: -0.0511 | rev_kl: inf | stu_lens: 124.6250 | mixed_lens: 114.5000 | lr: 4.9958e-06 | scale: 2048.00 | time: 0.394 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    192/  5000| tot_loss: 5.6240 | rl_loss: 0.4847 | pt_loss: 5.1393 | pg_loss: 0.0492 | reg_loss: 0.4355 | reward: -0.0840 | rev_kl: 2701983091201716600700928.0000 | stu_lens: 120.1250 | mixed_lens: 125.3750 | lr: 4.9957e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    192/  5000| tot_loss: 5.8100 | rl_loss: 0.4887 | pt_loss: 5.3213 | pg_loss: 0.0582 | reg_loss: 0.4305 | reward: -0.0006 | rev_kl: inf | stu_lens: 121.4375 | mixed_lens: 121.1172 | lr: 4.9957e-06 | scale: 2048.00 | time: 0.396 | step time: 5.345
/dtu/p1/johlau/LMOps/minillm/results/bloom/train/minillm/bs8-lr5e-06-G16-N1-NN1-lm1-len256/pe4_rs0.5_nr32_ln_sr_tm0.2
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    193/  5000| tot_loss: 6.0994 | rl_loss: 0.6250 | pt_loss: 5.4744 | pg_loss: 0.0758 | reg_loss: 0.5492 | reward: -0.0656 | rev_kl: inf | stu_lens: 126.1250 | mixed_lens: 117.5000 | lr: 4.9957e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    194/  5000| tot_loss: 5.5119 | rl_loss: 0.4605 | pt_loss: 5.0514 | pg_loss: 0.0544 | reg_loss: 0.4061 | reward: -0.0239 | rev_kl: 13722135158513446084935680.0000 | stu_lens: 128.0000 | mixed_lens: 112.1250 | lr: 4.9956e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    195/  5000| tot_loss: 5.7221 | rl_loss: 0.4421 | pt_loss: 5.2800 | pg_loss: 0.0425 | reg_loss: 0.3996 | reward: -0.0330 | rev_kl: 173.3364 | stu_lens: 128.0000 | mixed_lens: 126.6250 | lr: 4.9955e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    196/  5000| tot_loss: 5.9391 | rl_loss: 0.4865 | pt_loss: 5.4526 | pg_loss: 0.0542 | reg_loss: 0.4323 | reward: -0.0142 | rev_kl: 31301437979248033792.0000 | stu_lens: 128.0000 | mixed_lens: 127.8750 | lr: 4.9954e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    197/  5000| tot_loss: 5.9902 | rl_loss: 0.4571 | pt_loss: 5.5331 | pg_loss: 0.0634 | reg_loss: 0.3937 | reward: -0.0158 | rev_kl: 365673662854425470828544.0000 | stu_lens: 121.6250 | mixed_lens: 121.8750 | lr: 4.9953e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    198/  5000| tot_loss: 6.0947 | rl_loss: 0.3782 | pt_loss: 5.7165 | pg_loss: 0.0546 | reg_loss: 0.3237 | reward: -0.0077 | rev_kl: inf | stu_lens: 111.1250 | mixed_lens: 128.0000 | lr: 4.9952e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    199/  5000| tot_loss: 6.1177 | rl_loss: 0.5497 | pt_loss: 5.5680 | pg_loss: 0.0658 | reg_loss: 0.4839 | reward: 0.0199 | rev_kl: 846390436834758241025936599285760.0000 | stu_lens: 107.3750 | mixed_lens: 122.3750 | lr: 4.9951e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
                                 Evaluation #2                                  
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ prompts                               ┃ samples                              ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ Debajo hay unaयस que describe una്മ.   │ Debajo hay unaयस que describe una്മ.  │
│ Escribe una respuesta que completeعية │ Escribe una respuesta que            │
│ la标准.                               │ completeعية la标准.                  │
│                                       │                                      │
│ Channel सकता:                         │ Channel सकता:                        │
│ dime un chiste acerca de la situacion │ dime un chiste acerca de la          │
│ actual de la economia, de modo que    │ situacion actual de la economia, de  │
│ los niños comprendan el mal estado de │ modo que los niños comprendan el mal │
│ la misma.                             │ estado de la misma.                  │
│                                       │                                      │
│ Channel Respuesta:                    │ Channel Respuesta:                   │
│                                       │ En la edad de treinta años un joven  │
│                                       │ sosten en tear esta empresa, aunque  │
│                                       │ no lo crea esa empresa seguiria      │
│                                       │ existiendo, esto es importante       │
│                                       │ karena lo que ha tenido que          │
│                                       │ pasar隨著 el tiempo. Como args       │
│                                       │ entienda que algo va detras de esto, │
│                                       │ pero continúa siendo posible, le     │
│                                       │ agradezco que mantenganse seguros.   │
│                                       │                                      │
│                                       │ Channel Estima al Sr. Petro por su   │
│                                       │ comida, y la cual viene de su madre, │
│                                       │ pero no le intimida porque esta ya   │
│                                       │ avanza muy rápidamente, y lo         │
│                                       │ demuestra en la edad de treinta      │
│                                       │ años.                                │
│                                       │ Luego que está en la edad de treinta │
│                                       │ años, ella decide no seguir el       │
│                                       │ camino opositor, y                   │
├───────────────────────────────────────┼──────────────────────────────────────┤
│ Debajo hay unaयस que describe una്മ.   │ Debajo hay unaयस que describe una്മ.  │
│ Escribe una respuesta que completeعية │ Escribe una respuesta que            │
│ la标准.                               │ completeعية la标准.                  │
│                                       │                                      │
│ Channel सकता:                         │ Channel सकता:                        │
│ Noiapkan laحِ de este chiste. ¿ Court  │ Noiapkan laحِ de este chiste. ¿ Court │
│ contar otro?                          │ contar otro?                         │
│                                       │                                      │
│ Channel Respuesta:                    │ Channel Respuesta:                   │
│                                       │ ¡Claro! Además de12. El cuenta él lo │
│                                       │ ésto. Asdeoj. He's don stanza, he    │
│                                       │ calzado；第二年輕date' go để         │
│                                       │ française el nom pychcost. Textè là  │
│                                       │ defunctions.correct ( negativa)      │
│                                       │ hacer mil cosas 83n, 50单位 al       │
│                                       │ pastá-la.                            │
│                                       │ Channel Arde:                        │
│                                       │ Use, ferj. Sin embargo, somos seis   │
│                                       │ en el siglo pasado en encontrar. Eso │
│                                       │ se llama sin marca blanca sino un    │
│                                       │ pañuelo azul. O como dice aqui, una  │
│                                       │ señal de Ix. - - ( me cuenta un      │
│                                       │ inglés un sentimiento que se compara │
│                                       │ en el mente humana durante la        │
│                                       │ investigación: laza háb              │
├───────────────────────────────────────┼──────────────────────────────────────┤
│ Debajo hay unaयस que describe una്മ.   │ Debajo hay unaयस que describe una്മ.  │
│ Escribe una respuesta que completeعية │ Escribe una respuesta que            │
│ la标准.                               │ completeعية la标准.                  │
│                                       │                                      │
│ Channel सकता:                         │ Channel सकता:                        │
│ Noiapkan laحِ de este chiste. ¿ Court  │ Noiapkan laحِ de este chiste. ¿ Court │
│ contar otro?                          │ contar otro?                         │
│                                       │                                      │
│ Channel Respuesta:                    │ Channel Respuesta:                   │
│                                       │ Mi compañera / misana fue a dormir a │
│                                       │ la semana B, porque su grupo de      │
│                                       │ tarea le regresa al mos他希望        │
│                                       │ vivienda en el invierno. Al día      │
│                                       │ siguiente fue confusión para ir a    │
│                                       │ recoger señores, ebmechu, regla, le  │
│                                       │ dicen, trao no quiere comer, nunca   │
│                                       │ no toma algún alimento aceitonnage   │
│                                       │ dición. Pegastaías, be impuestrielo  │
│                                       │ que va prendre carne, sra. Orinoco   │
│                                       │ qué comió estaría linda new, but he  │
│                                       │ bear y elitxoso y los sres.          │
│                                       │ Pequeña prueba para Venezuela        │
│                                       │ Escaramuza:                          │
│                                       │ ¡Id Peralmia?                        │
│                                       │ And speculatire a                    │
└───────────────────────────────────────┴──────────────────────────────────────┘
eval | rougeL: 9.415 | exact_match: 0.000 | rev_kl: inf | lens: 119.224 | pt_loss: 5.343 | lm_loss: 5.149 | kd_loss: 5.538 
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    200/  5000| tot_loss: 5.8021 | rl_loss: 0.5019 | pt_loss: 5.3002 | pg_loss: 0.0692 | reg_loss: 0.4326 | reward: 0.1129 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 111.8750 | lr: 4.9950e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    201/  5000| tot_loss: 5.8262 | rl_loss: 0.6022 | pt_loss: 5.2240 | pg_loss: 0.1950 | reg_loss: 0.4072 | reward: -0.0083 | rev_kl: inf | stu_lens: 110.2500 | mixed_lens: 101.1250 | lr: 4.9949e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    202/  5000| tot_loss: 5.9185 | rl_loss: 0.5263 | pt_loss: 5.3922 | pg_loss: 0.0808 | reg_loss: 0.4455 | reward: -0.2229 | rev_kl: inf | stu_lens: 118.0000 | mixed_lens: 105.7500 | lr: 4.9948e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    203/  5000| tot_loss: 6.2767 | rl_loss: 0.5511 | pt_loss: 5.7256 | pg_loss: 0.0726 | reg_loss: 0.4785 | reward: -0.0641 | rev_kl: 497.2414 | stu_lens: 124.0000 | mixed_lens: 116.1250 | lr: 4.9947e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    204/  5000| tot_loss: 5.6846 | rl_loss: 0.5998 | pt_loss: 5.0848 | pg_loss: 0.0865 | reg_loss: 0.5133 | reward: 0.0095 | rev_kl: 6320242032640.0000 | stu_lens: 128.0000 | mixed_lens: 114.1250 | lr: 4.9946e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    205/  5000| tot_loss: 6.0791 | rl_loss: 0.4719 | pt_loss: 5.6072 | pg_loss: 0.0868 | reg_loss: 0.3851 | reward: -0.0556 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 118.0000 | lr: 4.9944e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    206/  5000| tot_loss: 5.6824 | rl_loss: 0.4855 | pt_loss: 5.1969 | pg_loss: 0.0718 | reg_loss: 0.4137 | reward: 0.0284 | rev_kl: 933942799781226254172160.0000 | stu_lens: 128.0000 | mixed_lens: 116.8750 | lr: 4.9943e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    207/  5000| tot_loss: 5.7473 | rl_loss: 0.5023 | pt_loss: 5.2449 | pg_loss: 0.0582 | reg_loss: 0.4442 | reward: 0.0423 | rev_kl: 533657108231487488.0000 | stu_lens: 128.0000 | mixed_lens: 116.2500 | lr: 4.9942e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    208/  5000| tot_loss: 5.9367 | rl_loss: 0.5449 | pt_loss: 5.3918 | pg_loss: 0.0780 | reg_loss: 0.4669 | reward: 0.0139 | rev_kl: 3458985808636294682444359008256.0000 | stu_lens: 122.0000 | mixed_lens: 114.8750 | lr: 4.9941e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    208/  5000| tot_loss: 5.8046 | rl_loss: 0.4898 | pt_loss: 5.3148 | pg_loss: 0.0629 | reg_loss: 0.4269 | reward: -0.0117 | rev_kl: inf | stu_lens: 121.6289 | mixed_lens: 119.2734 | lr: 4.9941e-06 | scale: 2048.00 | time: 0.395 | step time: 5.338
/dtu/p1/johlau/LMOps/minillm/results/bloom/train/minillm/bs8-lr5e-06-G16-N1-NN1-lm1-len256/pe4_rs0.5_nr32_ln_sr_tm0.2
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    209/  5000| tot_loss: 5.7446 | rl_loss: 0.4383 | pt_loss: 5.3063 | pg_loss: 0.0274 | reg_loss: 0.4109 | reward: 0.0120 | rev_kl: 216834384.0000 | stu_lens: 128.0000 | mixed_lens: 121.3750 | lr: 4.9940e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    210/  5000| tot_loss: 5.4859 | rl_loss: 0.4234 | pt_loss: 5.0625 | pg_loss: 0.0585 | reg_loss: 0.3649 | reward: 0.1027 | rev_kl: 223467856.0000 | stu_lens: 115.0000 | mixed_lens: 119.3750 | lr: 4.9939e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    211/  5000| tot_loss: 5.9694 | rl_loss: 0.5144 | pt_loss: 5.4551 | pg_loss: 0.0473 | reg_loss: 0.4671 | reward: 0.0278 | rev_kl: 38217547075274823778959846539264.0000 | stu_lens: 114.7500 | mixed_lens: 128.0000 | lr: 4.9938e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    212/  5000| tot_loss: 5.5962 | rl_loss: 0.4686 | pt_loss: 5.1276 | pg_loss: 0.0703 | reg_loss: 0.3983 | reward: 0.0605 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 121.6250 | lr: 4.9937e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    213/  5000| tot_loss: 5.4802 | rl_loss: 0.4117 | pt_loss: 5.0686 | pg_loss: 0.0373 | reg_loss: 0.3743 | reward: 0.0459 | rev_kl: inf | stu_lens: 112.1250 | mixed_lens: 128.0000 | lr: 4.9936e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    214/  5000| tot_loss: 5.9550 | rl_loss: 0.5190 | pt_loss: 5.4359 | pg_loss: 0.0484 | reg_loss: 0.4706 | reward: -0.0296 | rev_kl: 1496678042594967552.0000 | stu_lens: 126.1250 | mixed_lens: 128.0000 | lr: 4.9934e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    215/  5000| tot_loss: 5.9709 | rl_loss: 0.4640 | pt_loss: 5.5069 | pg_loss: 0.0797 | reg_loss: 0.3843 | reward: 0.0243 | rev_kl: 1152813952.0000 | stu_lens: 128.0000 | mixed_lens: 106.2500 | lr: 4.9933e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    216/  5000| tot_loss: 5.8906 | rl_loss: 0.5831 | pt_loss: 5.3075 | pg_loss: 0.1295 | reg_loss: 0.4537 | reward: -0.0903 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 101.7500 | lr: 4.9932e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    217/  5000| tot_loss: 5.5871 | rl_loss: 0.4649 | pt_loss: 5.1222 | pg_loss: 0.0528 | reg_loss: 0.4121 | reward: -0.0242 | rev_kl: 147565093847040.0000 | stu_lens: 112.6250 | mixed_lens: 121.5000 | lr: 4.9931e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    218/  5000| tot_loss: 5.8017 | rl_loss: 0.4712 | pt_loss: 5.3305 | pg_loss: 0.0608 | reg_loss: 0.4104 | reward: 0.0012 | rev_kl: 126373428480615643086848.0000 | stu_lens: 122.1250 | mixed_lens: 125.6250 | lr: 4.9930e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    219/  5000| tot_loss: 6.0660 | rl_loss: 0.4992 | pt_loss: 5.5669 | pg_loss: 0.0750 | reg_loss: 0.4242 | reward: 0.0093 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.9928e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    220/  5000| tot_loss: 5.6510 | rl_loss: 0.4702 | pt_loss: 5.1808 | pg_loss: 0.0242 | reg_loss: 0.4460 | reward: -0.0991 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 115.2500 | lr: 4.9927e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    221/  5000| tot_loss: 6.0658 | rl_loss: 0.5440 | pt_loss: 5.5217 | pg_loss: 0.0513 | reg_loss: 0.4928 | reward: -0.0141 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.9926e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    222/  5000| tot_loss: 6.0727 | rl_loss: 0.6337 | pt_loss: 5.4389 | pg_loss: 0.1249 | reg_loss: 0.5088 | reward: -0.1085 | rev_kl: inf | stu_lens: 113.2500 | mixed_lens: 115.0000 | lr: 4.9925e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    223/  5000| tot_loss: 5.6652 | rl_loss: 0.5875 | pt_loss: 5.0777 | pg_loss: 0.1025 | reg_loss: 0.4850 | reward: -0.0406 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 109.1250 | lr: 4.9924e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    224/  5000| tot_loss: 5.7690 | rl_loss: 0.5042 | pt_loss: 5.2648 | pg_loss: 0.0619 | reg_loss: 0.4423 | reward: -0.0440 | rev_kl: 6883903488.0000 | stu_lens: 108.2500 | mixed_lens: 125.3750 | lr: 4.9922e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    224/  5000| tot_loss: 5.7959 | rl_loss: 0.4960 | pt_loss: 5.2999 | pg_loss: 0.0631 | reg_loss: 0.4329 | reward: 0.0095 | rev_kl: inf | stu_lens: 119.7969 | mixed_lens: 121.4570 | lr: 4.9922e-06 | scale: 2048.00 | time: 0.396 | step time: 5.339
/dtu/p1/johlau/LMOps/minillm/results/bloom/train/minillm/bs8-lr5e-06-G16-N1-NN1-lm1-len256/pe4_rs0.5_nr32_ln_sr_tm0.2
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    225/  5000| tot_loss: 5.8719 | rl_loss: 0.4962 | pt_loss: 5.3756 | pg_loss: 0.0599 | reg_loss: 0.4363 | reward: 0.0072 | rev_kl: 2608.2480 | stu_lens: 128.0000 | mixed_lens: 121.0000 | lr: 4.9921e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    226/  5000| tot_loss: 6.5275 | rl_loss: 0.4533 | pt_loss: 6.0741 | pg_loss: 0.0577 | reg_loss: 0.3956 | reward: -0.0167 | rev_kl: 6310732886966272.0000 | stu_lens: 123.1250 | mixed_lens: 128.0000 | lr: 4.9920e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    227/  5000| tot_loss: 5.9422 | rl_loss: 0.5062 | pt_loss: 5.4359 | pg_loss: 0.0477 | reg_loss: 0.4585 | reward: -0.0032 | rev_kl: 95248185827980967602552832.0000 | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.9918e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    228/  5000| tot_loss: 6.0090 | rl_loss: 0.4468 | pt_loss: 5.5623 | pg_loss: 0.0437 | reg_loss: 0.4031 | reward: 0.0112 | rev_kl: 24.4685 | stu_lens: 107.8750 | mixed_lens: 128.0000 | lr: 4.9917e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    229/  5000| tot_loss: 6.0815 | rl_loss: 0.5333 | pt_loss: 5.5482 | pg_loss: 0.0687 | reg_loss: 0.4645 | reward: 0.0057 | rev_kl: inf | stu_lens: 115.6250 | mixed_lens: 126.3750 | lr: 4.9916e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    230/  5000| tot_loss: 5.3347 | rl_loss: 0.4941 | pt_loss: 4.8405 | pg_loss: 0.0510 | reg_loss: 0.4431 | reward: -0.0233 | rev_kl: inf | stu_lens: 104.3750 | mixed_lens: 128.0000 | lr: 4.9915e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    231/  5000| tot_loss: 6.0988 | rl_loss: 0.4716 | pt_loss: 5.6272 | pg_loss: 0.0463 | reg_loss: 0.4253 | reward: 0.0337 | rev_kl: 82111258624.0000 | stu_lens: 119.0000 | mixed_lens: 128.0000 | lr: 4.9913e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    232/  5000| tot_loss: 5.8366 | rl_loss: 0.4523 | pt_loss: 5.3843 | pg_loss: 0.0262 | reg_loss: 0.4261 | reward: -0.0614 | rev_kl: 1066686400692224.0000 | stu_lens: 113.8750 | mixed_lens: 113.5000 | lr: 4.9912e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    233/  5000| tot_loss: 5.9454 | rl_loss: 0.6538 | pt_loss: 5.2915 | pg_loss: 0.1080 | reg_loss: 0.5458 | reward: 0.3923 | rev_kl: inf | stu_lens: 113.6250 | mixed_lens: 114.1250 | lr: 4.9911e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    234/  5000| tot_loss: 5.1119 | rl_loss: 0.4736 | pt_loss: 4.6383 | pg_loss: 0.1013 | reg_loss: 0.3723 | reward: -0.0113 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 108.2500 | lr: 4.9909e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    235/  5000| tot_loss: 5.3236 | rl_loss: 0.4451 | pt_loss: 4.8785 | pg_loss: 0.0568 | reg_loss: 0.3883 | reward: -0.0069 | rev_kl: 729463084023808.0000 | stu_lens: 124.8750 | mixed_lens: 102.6250 | lr: 4.9908e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    236/  5000| tot_loss: 5.7762 | rl_loss: 0.4613 | pt_loss: 5.3149 | pg_loss: 0.0497 | reg_loss: 0.4117 | reward: -0.0444 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.9906e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    237/  5000| tot_loss: 5.9910 | rl_loss: 0.4937 | pt_loss: 5.4973 | pg_loss: 0.0764 | reg_loss: 0.4173 | reward: 0.0142 | rev_kl: 3501769.0000 | stu_lens: 112.5000 | mixed_lens: 108.5000 | lr: 4.9905e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    238/  5000| tot_loss: 5.8137 | rl_loss: 0.5401 | pt_loss: 5.2736 | pg_loss: 0.0614 | reg_loss: 0.4786 | reward: -0.0558 | rev_kl: 1633909184390316685524035698688.0000 | stu_lens: 108.6250 | mixed_lens: 128.0000 | lr: 4.9904e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    239/  5000| tot_loss: 5.5392 | rl_loss: 0.4731 | pt_loss: 5.0661 | pg_loss: 0.0559 | reg_loss: 0.4172 | reward: -0.0695 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 117.3750 | lr: 4.9902e-06 | scale: 2048.00 | time: 0.394 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    240/  5000| tot_loss: 5.6312 | rl_loss: 0.4196 | pt_loss: 5.2116 | pg_loss: 0.0490 | reg_loss: 0.3705 | reward: -0.0346 | rev_kl: 4852085.0000 | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.9901e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    240/  5000| tot_loss: 5.7415 | rl_loss: 0.4784 | pt_loss: 5.2631 | pg_loss: 0.0615 | reg_loss: 0.4169 | reward: 0.0078 | rev_kl: inf | stu_lens: 119.9805 | mixed_lens: 121.3828 | lr: 4.9901e-06 | scale: 2048.00 | time: 0.396 | step time: 5.344
/dtu/p1/johlau/LMOps/minillm/results/bloom/train/minillm/bs8-lr5e-06-G16-N1-NN1-lm1-len256/pe4_rs0.5_nr32_ln_sr_tm0.2
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    241/  5000| tot_loss: 5.8642 | rl_loss: 0.4274 | pt_loss: 5.4368 | pg_loss: 0.0502 | reg_loss: 0.3772 | reward: -0.0460 | rev_kl: 5585993728.0000 | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.9899e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    242/  5000| tot_loss: 5.8722 | rl_loss: 0.4846 | pt_loss: 5.3876 | pg_loss: 0.0867 | reg_loss: 0.3980 | reward: 0.0325 | rev_kl: 15500.2100 | stu_lens: 114.8750 | mixed_lens: 115.6250 | lr: 4.9898e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    243/  5000| tot_loss: 5.9241 | rl_loss: 0.4404 | pt_loss: 5.4837 | pg_loss: 0.0457 | reg_loss: 0.3948 | reward: 0.0209 | rev_kl: 82209240.0000 | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.9896e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    244/  5000| tot_loss: 5.8138 | rl_loss: 0.5039 | pt_loss: 5.3099 | pg_loss: 0.0360 | reg_loss: 0.4679 | reward: -0.0132 | rev_kl: inf | stu_lens: 116.5000 | mixed_lens: 128.0000 | lr: 4.9895e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    245/  5000| tot_loss: 6.0943 | rl_loss: 0.5326 | pt_loss: 5.5617 | pg_loss: 0.0808 | reg_loss: 0.4518 | reward: 0.1008 | rev_kl: inf | stu_lens: 127.7500 | mixed_lens: 117.0000 | lr: 4.9894e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    246/  5000| tot_loss: 6.1239 | rl_loss: 0.4704 | pt_loss: 5.6535 | pg_loss: 0.0541 | reg_loss: 0.4163 | reward: -0.0152 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 120.3750 | lr: 4.9892e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    247/  5000| tot_loss: 5.8506 | rl_loss: 0.4312 | pt_loss: 5.4193 | pg_loss: 0.0528 | reg_loss: 0.3784 | reward: 0.0554 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.9891e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    248/  5000| tot_loss: 5.8102 | rl_loss: 0.5318 | pt_loss: 5.2784 | pg_loss: 0.0883 | reg_loss: 0.4435 | reward: -0.0936 | rev_kl: 105083135175163904.0000 | stu_lens: 115.0000 | mixed_lens: 115.7500 | lr: 4.9889e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    249/  5000| tot_loss: 5.5337 | rl_loss: 0.4133 | pt_loss: 5.1204 | pg_loss: 0.0460 | reg_loss: 0.3674 | reward: -0.0370 | rev_kl: inf | stu_lens: 85.5000 | mixed_lens: 128.0000 | lr: 4.9888e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    250/  5000| tot_loss: 5.9285 | rl_loss: 0.4636 | pt_loss: 5.4648 | pg_loss: 0.0601 | reg_loss: 0.4035 | reward: 0.0023 | rev_kl: 3188474.5000 | stu_lens: 126.6250 | mixed_lens: 128.0000 | lr: 4.9886e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    251/  5000| tot_loss: 5.7019 | rl_loss: 0.5425 | pt_loss: 5.1594 | pg_loss: 0.0536 | reg_loss: 0.4889 | reward: -0.0044 | rev_kl: 3173235923353600.0000 | stu_lens: 113.8750 | mixed_lens: 127.3750 | lr: 4.9884e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    252/  5000| tot_loss: 5.5332 | rl_loss: 0.4573 | pt_loss: 5.0759 | pg_loss: 0.0433 | reg_loss: 0.4139 | reward: 0.1294 | rev_kl: 874568521096260177169636917248.0000 | stu_lens: 128.0000 | mixed_lens: 123.5000 | lr: 4.9883e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    253/  5000| tot_loss: 5.8546 | rl_loss: 0.4651 | pt_loss: 5.3895 | pg_loss: 0.0565 | reg_loss: 0.4086 | reward: -0.0215 | rev_kl: 157037704148555697903108096.0000 | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.9881e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    254/  5000| tot_loss: 5.4598 | rl_loss: 0.4526 | pt_loss: 5.0072 | pg_loss: 0.0705 | reg_loss: 0.3821 | reward: -0.0497 | rev_kl: inf | stu_lens: 115.2500 | mixed_lens: 107.7500 | lr: 4.9880e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    255/  5000| tot_loss: 5.5311 | rl_loss: 0.5120 | pt_loss: 5.0192 | pg_loss: 0.0719 | reg_loss: 0.4401 | reward: -0.0239 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 124.0000 | lr: 4.9878e-06 | scale: 2048.00 | time: 0.394 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    256/  5000| tot_loss: 5.6639 | rl_loss: 0.4272 | pt_loss: 5.2368 | pg_loss: 0.0481 | reg_loss: 0.3791 | reward: 0.0286 | rev_kl: 115237649868319096832.0000 | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.9877e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    256/  5000| tot_loss: 5.7299 | rl_loss: 0.4685 | pt_loss: 5.2614 | pg_loss: 0.0580 | reg_loss: 0.4105 | reward: -0.0052 | rev_kl: inf | stu_lens: 122.0605 | mixed_lens: 122.0430 | lr: 4.9877e-06 | scale: 2048.00 | time: 0.395 | step time: 5.341
/dtu/p1/johlau/LMOps/minillm/results/bloom/train/minillm/bs8-lr5e-06-G16-N1-NN1-lm1-len256/pe4_rs0.5_nr32_ln_sr_tm0.2
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    257/  5000| tot_loss: 5.6344 | rl_loss: 0.4587 | pt_loss: 5.1758 | pg_loss: 0.0655 | reg_loss: 0.3932 | reward: -0.1277 | rev_kl: 465747040.0000 | stu_lens: 128.0000 | mixed_lens: 104.1250 | lr: 4.9875e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    258/  5000| tot_loss: 6.0834 | rl_loss: 0.5074 | pt_loss: 5.5760 | pg_loss: 0.0584 | reg_loss: 0.4490 | reward: 0.0126 | rev_kl: 30016320379638515761152.0000 | stu_lens: 117.6250 | mixed_lens: 128.0000 | lr: 4.9873e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    259/  5000| tot_loss: 5.6012 | rl_loss: 0.4920 | pt_loss: 5.1092 | pg_loss: 0.0486 | reg_loss: 0.4434 | reward: -0.0489 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 126.8750 | lr: 4.9872e-06 | scale: 2048.00 | time: 0.394 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    260/  5000| tot_loss: 5.3875 | rl_loss: 0.6113 | pt_loss: 4.7761 | pg_loss: 0.0645 | reg_loss: 0.5468 | reward: 0.0583 | rev_kl: 23888263168.0000 | stu_lens: 116.6250 | mixed_lens: 123.2500 | lr: 4.9870e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    261/  5000| tot_loss: 5.7341 | rl_loss: 0.3943 | pt_loss: 5.3398 | pg_loss: 0.0484 | reg_loss: 0.3459 | reward: 0.0347 | rev_kl: inf | stu_lens: 127.0000 | mixed_lens: 128.0000 | lr: 4.9869e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    262/  5000| tot_loss: 5.4870 | rl_loss: 0.4792 | pt_loss: 5.0078 | pg_loss: 0.0478 | reg_loss: 0.4314 | reward: -0.0586 | rev_kl: 2180931108470784.0000 | stu_lens: 125.6250 | mixed_lens: 128.0000 | lr: 4.9867e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    263/  5000| tot_loss: 5.7410 | rl_loss: 0.4141 | pt_loss: 5.3269 | pg_loss: 0.0503 | reg_loss: 0.3638 | reward: -0.0404 | rev_kl: 32.5697 | stu_lens: 118.8750 | mixed_lens: 128.0000 | lr: 4.9865e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    264/  5000| tot_loss: 5.7298 | rl_loss: 0.3923 | pt_loss: 5.3375 | pg_loss: 0.0213 | reg_loss: 0.3710 | reward: -0.0425 | rev_kl: 123053707100160.0000 | stu_lens: 124.8750 | mixed_lens: 106.3750 | lr: 4.9864e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    265/  5000| tot_loss: 5.5920 | rl_loss: 0.4419 | pt_loss: 5.1502 | pg_loss: 0.0436 | reg_loss: 0.3983 | reward: -0.0131 | rev_kl: inf | stu_lens: 121.3750 | mixed_lens: 128.0000 | lr: 4.9862e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    266/  5000| tot_loss: 5.6768 | rl_loss: 0.4256 | pt_loss: 5.2512 | pg_loss: 0.0488 | reg_loss: 0.3768 | reward: 0.0003 | rev_kl: 152895080481423360.0000 | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.9860e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    267/  5000| tot_loss: 5.5524 | rl_loss: 0.3217 | pt_loss: 5.2306 | pg_loss: 0.0176 | reg_loss: 0.3041 | reward: -0.0685 | rev_kl: 44992056129321383848050688.0000 | stu_lens: 109.1250 | mixed_lens: 100.8750 | lr: 4.9859e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    268/  5000| tot_loss: 5.6188 | rl_loss: 0.4034 | pt_loss: 5.2155 | pg_loss: 0.0401 | reg_loss: 0.3633 | reward: -0.0214 | rev_kl: 58.6193 | stu_lens: 128.0000 | mixed_lens: 116.5000 | lr: 4.9857e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    269/  5000| tot_loss: 5.7210 | rl_loss: 0.4347 | pt_loss: 5.2863 | pg_loss: 0.0374 | reg_loss: 0.3973 | reward: -0.0024 | rev_kl: 3698736286690187411456.0000 | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.9855e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    270/  5000| tot_loss: 5.4234 | rl_loss: 0.4083 | pt_loss: 5.0151 | pg_loss: 0.0331 | reg_loss: 0.3751 | reward: -0.0706 | rev_kl: inf | stu_lens: 111.8750 | mixed_lens: 101.8750 | lr: 4.9853e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    271/  5000| tot_loss: 5.4496 | rl_loss: 0.4374 | pt_loss: 5.0121 | pg_loss: 0.0362 | reg_loss: 0.4012 | reward: 0.0725 | rev_kl: 143631617707999232.0000 | stu_lens: 118.0000 | mixed_lens: 111.8750 | lr: 4.9852e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    272/  5000| tot_loss: 5.2165 | rl_loss: 0.4854 | pt_loss: 4.7311 | pg_loss: 0.0582 | reg_loss: 0.4272 | reward: -0.0413 | rev_kl: 1851461581374794730486932439040.0000 | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.9850e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    272/  5000| tot_loss: 5.7377 | rl_loss: 0.4697 | pt_loss: 5.2680 | pg_loss: 0.0562 | reg_loss: 0.4135 | reward: -0.0151 | rev_kl: inf | stu_lens: 119.9512 | mixed_lens: 120.5215 | lr: 4.9850e-06 | scale: 2048.00 | time: 0.396 | step time: 5.343
/dtu/p1/johlau/LMOps/minillm/results/bloom/train/minillm/bs8-lr5e-06-G16-N1-NN1-lm1-len256/pe4_rs0.5_nr32_ln_sr_tm0.2
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    273/  5000| tot_loss: 5.3720 | rl_loss: 0.5256 | pt_loss: 4.8464 | pg_loss: 0.1060 | reg_loss: 0.4196 | reward: 0.0661 | rev_kl: inf | stu_lens: 113.7500 | mixed_lens: 105.5000 | lr: 4.9848e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    274/  5000| tot_loss: 5.7407 | rl_loss: 0.4570 | pt_loss: 5.2837 | pg_loss: 0.0351 | reg_loss: 0.4219 | reward: -0.0183 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.9846e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    275/  5000| tot_loss: 5.6677 | rl_loss: 0.6152 | pt_loss: 5.0525 | pg_loss: 0.0706 | reg_loss: 0.5446 | reward: -0.0583 | rev_kl: 1505716.3750 | stu_lens: 113.8750 | mixed_lens: 108.7500 | lr: 4.9845e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    276/  5000| tot_loss: 5.5677 | rl_loss: 0.4679 | pt_loss: 5.0997 | pg_loss: 0.0893 | reg_loss: 0.3787 | reward: -0.0576 | rev_kl: 1232756784340892387688121590874112.0000 | stu_lens: 128.0000 | mixed_lens: 118.7500 | lr: 4.9843e-06 | scale: 2048.00 | time: 0.394 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    277/  5000| tot_loss: 5.8512 | rl_loss: 0.4607 | pt_loss: 5.3905 | pg_loss: 0.0502 | reg_loss: 0.4105 | reward: -0.0669 | rev_kl: 40904113721090084128023379968.0000 | stu_lens: 121.8750 | mixed_lens: 128.0000 | lr: 4.9841e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    278/  5000| tot_loss: 5.8726 | rl_loss: 0.4873 | pt_loss: 5.3853 | pg_loss: 0.0579 | reg_loss: 0.4294 | reward: -0.0670 | rev_kl: 335972.3750 | stu_lens: 101.7500 | mixed_lens: 114.1250 | lr: 4.9839e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    279/  5000| tot_loss: 5.8108 | rl_loss: 0.4401 | pt_loss: 5.3707 | pg_loss: 0.0477 | reg_loss: 0.3924 | reward: -0.0709 | rev_kl: 50982682384118745009225728.0000 | stu_lens: 128.0000 | mixed_lens: 121.6250 | lr: 4.9837e-06 | scale: 2048.00 | time: 0.394 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    280/  5000| tot_loss: 5.7129 | rl_loss: 0.5093 | pt_loss: 5.2035 | pg_loss: 0.0597 | reg_loss: 0.4496 | reward: -0.0407 | rev_kl: inf | stu_lens: 117.0000 | mixed_lens: 128.0000 | lr: 4.9836e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    281/  5000| tot_loss: 6.0132 | rl_loss: 0.4685 | pt_loss: 5.5447 | pg_loss: 0.0637 | reg_loss: 0.4048 | reward: -0.0006 | rev_kl: 9186958960521904128.0000 | stu_lens: 127.0000 | mixed_lens: 128.0000 | lr: 4.9834e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    282/  5000| tot_loss: 5.6823 | rl_loss: 0.4918 | pt_loss: 5.1905 | pg_loss: 0.0638 | reg_loss: 0.4280 | reward: 0.0301 | rev_kl: inf | stu_lens: 105.2500 | mixed_lens: 120.3750 | lr: 4.9832e-06 | scale: 2048.00 | time: 0.394 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    283/  5000| tot_loss: 5.5619 | rl_loss: 0.4462 | pt_loss: 5.1156 | pg_loss: 0.0335 | reg_loss: 0.4127 | reward: 0.1121 | rev_kl: 8129763840.0000 | stu_lens: 120.1250 | mixed_lens: 112.3750 | lr: 4.9830e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    284/  5000| tot_loss: 6.0262 | rl_loss: 0.5246 | pt_loss: 5.5016 | pg_loss: 0.0741 | reg_loss: 0.4505 | reward: -0.0604 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 113.0000 | lr: 4.9828e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    285/  5000| tot_loss: 5.8627 | rl_loss: 0.5298 | pt_loss: 5.3329 | pg_loss: 0.0551 | reg_loss: 0.4746 | reward: 0.0713 | rev_kl: inf | stu_lens: 107.5000 | mixed_lens: 128.0000 | lr: 4.9826e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    286/  5000| tot_loss: 6.0075 | rl_loss: 0.5291 | pt_loss: 5.4784 | pg_loss: 0.0624 | reg_loss: 0.4667 | reward: -0.0383 | rev_kl: inf | stu_lens: 95.2500 | mixed_lens: 123.1250 | lr: 4.9824e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    287/  5000| tot_loss: 5.8974 | rl_loss: 0.4686 | pt_loss: 5.4288 | pg_loss: 0.0592 | reg_loss: 0.4094 | reward: 0.0698 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 116.2500 | lr: 4.9822e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    288/  5000| tot_loss: 5.9112 | rl_loss: 0.4728 | pt_loss: 5.4384 | pg_loss: 0.0456 | reg_loss: 0.4272 | reward: -0.0235 | rev_kl: 13763174184081424384.0000 | stu_lens: 128.0000 | mixed_lens: 116.0000 | lr: 4.9821e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    288/  5000| tot_loss: 5.7355 | rl_loss: 0.4797 | pt_loss: 5.2558 | pg_loss: 0.0593 | reg_loss: 0.4204 | reward: 0.0038 | rev_kl: inf | stu_lens: 122.6621 | mixed_lens: 120.8535 | lr: 4.9821e-06 | scale: 2048.00 | time: 0.395 | step time: 5.341
/dtu/p1/johlau/LMOps/minillm/results/bloom/train/minillm/bs8-lr5e-06-G16-N1-NN1-lm1-len256/pe4_rs0.5_nr32_ln_sr_tm0.2
****************************************************************************************************
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    289/  5000| tot_loss: 5.8219 | rl_loss: 0.5067 | pt_loss: 5.3152 | pg_loss: 0.0536 | reg_loss: 0.4531 | reward: 0.0019 | rev_kl: 830488576.0000 | stu_lens: 119.8750 | mixed_lens: 128.0000 | lr: 4.9819e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    290/  5000| tot_loss: 5.8187 | rl_loss: 0.4760 | pt_loss: 5.3427 | pg_loss: 0.0587 | reg_loss: 0.4173 | reward: -0.0032 | rev_kl: inf | stu_lens: 101.6250 | mixed_lens: 128.0000 | lr: 4.9817e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    291/  5000| tot_loss: 5.6245 | rl_loss: 0.5924 | pt_loss: 5.0321 | pg_loss: 0.1075 | reg_loss: 0.4849 | reward: -0.0191 | rev_kl: 5758758722469888.0000 | stu_lens: 128.0000 | mixed_lens: 118.0000 | lr: 4.9815e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    292/  5000| tot_loss: 5.8989 | rl_loss: 0.4365 | pt_loss: 5.4623 | pg_loss: 0.0300 | reg_loss: 0.4065 | reward: -0.0136 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 112.2500 | lr: 4.9813e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    293/  5000| tot_loss: 5.4423 | rl_loss: 0.5206 | pt_loss: 4.9217 | pg_loss: 0.0713 | reg_loss: 0.4493 | reward: 0.1431 | rev_kl: 74179361599716100763811840.0000 | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.9811e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    294/  5000| tot_loss: 6.5206 | rl_loss: 0.4929 | pt_loss: 6.0277 | pg_loss: 0.0550 | reg_loss: 0.4378 | reward: -0.0387 | rev_kl: inf | stu_lens: 128.0000 | mixed_lens: 128.0000 | lr: 4.9809e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    295/  5000| tot_loss: 5.6571 | rl_loss: 0.4812 | pt_loss: 5.1759 | pg_loss: 0.0943 | reg_loss: 0.3869 | reward: -0.0202 | rev_kl: inf | stu_lens: 114.0000 | mixed_lens: 109.5000 | lr: 4.9807e-06 | scale: 2048.00 | time: 0.394 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    296/  5000| tot_loss: 6.0498 | rl_loss: 0.5038 | pt_loss: 5.5461 | pg_loss: 0.0768 | reg_loss: 0.4270 | reward: 0.1035 | rev_kl: inf | stu_lens: 118.0000 | mixed_lens: 111.1250 | lr: 4.9805e-06 | scale: 2048.00 | time: 0.396 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    297/  5000| tot_loss: 5.4331 | rl_loss: 0.4604 | pt_loss: 4.9727 | pg_loss: 0.0551 | reg_loss: 0.4053 | reward: -0.0363 | rev_kl: inf | stu_lens: 125.8750 | mixed_lens: 128.0000 | lr: 4.9803e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
train | data_epochs  0/10 | inner iter:   3/  4 | ppo epoch:  3/ 4 | global iter:    298/  5000| tot_loss: 5.9153 | rl_loss: 0.4352 | pt_loss: 5.4801 | pg_loss: 0.0367 | reg_loss: 0.3985 | reward: -0.0318 | rev_kl: inf | stu_lens: 113.1250 | mixed_lens: 128.0000 | lr: 4.9801e-06 | scale: 2048.00 | time: 0.395 | step time: 0.000
